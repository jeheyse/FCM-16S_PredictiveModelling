---
title: <font size="6">Analysis</font>
output:
  html_document:
    code_folding: show
    highlight: haddock
    keep_md: yes
    theme: flatly
    toc: yes
    number_sections: true
    toc_float:
      collapsed: no
      smooth_scroll: yes
      toc_depth: 4
editor_options:
  chunk_output_type: console
bibliography: bibliography.bib
csl: CitationStyle.csl
---

<style>
#TOC {
  margin: 15px 0px 15px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}
.toc-content {
  padding-left: 20px;
  padding-right: 20px;
}
div.tocify {
  width: 20%;
  max-width: 700px;
  max-height: 85%;
}
  body {text-align: justify}
  .main-container {max-width: 2100px !important;}
  code.r{ font-size: 11px; }
  pre{ font-size: 15px }
  pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
</style>

```{r Setup, include = FALSE}
knitr::opts_chunk$set(eval = TRUE, 
                      echo = TRUE, 
                      cache = TRUE,
                      include = TRUE,
                      collapse = FALSE,
                      dependson = NULL,
                      warning = FALSE,
                      engine = "R",
                      error = TRUE,
                      fig.align = "center",
                      cache.lazy = FALSE)
```


```{r WorkingDirectory, echo = FALSE, message = FALSE}
setwd("/Projects2/Jasmine/FCM-16S_PredictiveModelling")
```

# Load libraries and functions

```{r LoadLibraries, message = FALSE, warning = FALSE}
# Packages
library("UBL")
library("Phenoflow")
library("plyr")
library("dplyr")
library("ggplot2")
library("gridExtra")
library("grid")
library("RColorBrewer")
library("grid")
library("tidyr")
library("reshape2")
library("gganimate")
library("gifski")
library("ellipse")
library("glmnet")
library("mboost")
library("openxlsx")
library("stabs")
library("stringr")
library("cowplot")
library("viridis")
library("SpiecEasi")
library("scales")   
library("ggplot2")  
library("plyr")     
library("dplyr")
library("tidyr")
library("data.table")
library("reshape2")
library("vegan")
library("phyloseq") 
library("ape")      
library("openxlsx") 
library("readxl")   
library("cowplot")
library("boot")
library("Biostrings")
library("htmltools")
library("CMETNGS")
library("VennDiagram")
library("adegenet")
library("ggtree")
library("stringr")
library("knitr")
library("stringdist")
library("DECIPHER")
library("dada2")
library("seqinr")
library("RColorBrewer")
library("ggalluvial")
library("ggfittext")
library("otu2ot")
library("DESeq2")
library("igraph")
library("UpSetR")
library("tidyverse")
library("caret")
library("glmnet")
library("randomForest")
library("DMwR")
library("stabs")
library("lars")
library("MultivariateRandomForest")
library("FactoMineR")
library("factoextra")
library("corrplot")
library("e1071")
library("caretEnsemble")
library("gbm")
library("fastAdaboost")
library("keras")
library("RMTL")
library("bst")
library("xgboost")
library("Cubist")
library("h2o")
library("kernlab")
library("performance")
library("pROC")
library("ggpubr")
library("ggcyto")
library("ggh4x")

set.seed(458)
```

```{r DefineColors, message = FALSE, warning = FALSE}
# Define colors for plotting
Colors <- c("#ff8b0f","#3a9679","#bc2a54", "#1e328a", "#edbe00", "#5f1280")
ColorBlocksFacet <- c("#e0e0e0")
Series16 <- c("#f5bdc5","#e65c6e", "#ba1822", "#750019", "#8f501b", "#bd7a28", "#f5af00", "#f2ff91", "#a1d179", "#53a358",  "#3a6e5b", "#3eb8a7", "#7581d1", "#091d9e", "#5c0778", "#a600a3")
SingleColor <- c("#3c4175")
SingleColor2 <- c("#5a7e48")

# Load convenience funtions
source("ConvenienceFunctions.R")
mapeexpSummary <- function (data, lev = NULL, model = NULL) {
  c(RMSE = sqrt(mean((data$obs - data$pred)^2)),
  Rsquared = summary(lm(pred ~ obs, data))$r.squared,
  MAE = mean(abs(data$obs - data$pred)),
  MAEL = mean(abs(boot::inv.logit(data$obs) - boot::inv.logit(data$pred))),
  RMSEL = sqrt(mean((boot::inv.logit(data$obs) - boot::inv.logit(data$pred))^2)),
  RsquaredL = summary(lm(boot::inv.logit(pred) ~ boot::inv.logit(obs), data))$r.squared)
  }
```

```{r Cores, message = FALSE, warning = FALSE}
# Make R use multiple cores
library(doParallel)
cl <- makeCluster(35, type = "PSOCK")
registerDoParallel(cl)
```

# Aquaculture dataset (main)

## Recreate sorting gates on FACSVerse data

### Load and process Influx data

```{r Influx_Load, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Load the FCS files of the Influx
Datapath <- c("./Data/Aquaculture/FCM/Influx/")
fcsfiles <- list.files(path = Datapath, recursive = TRUE, pattern = ".fcs", full.names = TRUE)
flowDataInflux <- flowCore::read.flowSet(files = fcsfiles, pattern = ".fcs")

# Remove all variables that are no longer needed
remove(Datapath, fcsfiles)
```

```{r Influx_transform, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Select phenotypic features of interest and transform parameters
flowData_transformedInflux <- flowCore::transform(flowDataInflux,
                                      `PMT 2` = log10(`PMT 2`), 
                                      `PMT 3` = log10(`PMT 3`))
flowData_transformedInflux <- flowData_transformedInflux[,c("PMT 2", "PMT 3")]

# Remove all variables that are no longer needed
remove(flowDataInflux)
```

```{r Influx_Gatecheck, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Bacterial population
sqrcut1 <- log10(sinh(matrix(c(1.5, 5, 7, 9.8, 9.8, 1.5,
                    2.9, 2.9, 4.25, 8, 10, 10),
                    ncol = 2,
                    nrow = 6)))  
sqrcut1[!is.finite(sqrcut1)] <- 0
colnames(sqrcut1) <- c("PMT 2", "PMT 3")
polyGate_sort <- polygonGate(.gate = sqrcut1, filterId = "Total Cells")

# Gating quality check
print(xyplot(`PMT 3` ~ `PMT 2`, data = flowData_transformedInflux[11], 
              filter = polyGate_sort,
              scales = list(y = list(limits = c(0,4.1)),
                            x = list(limits = c(0.2,4.1))),
              axis = axis.default, 
              xbin = 300,
              nbin = 125, 
              par.strip.text = list(col = "black", font = 3, cex = 0.75), 
              smooth = FALSE,
              par.settings = my.settings,
              yscale.components = yscale.components.log10,
              xscale.components = xscale.components.log10)) 


# Remove all variables that are no longer needed
remove(sqrcut1)
```

```{r Influx_Gating, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Count number of events inside this gate
CellCount <- flowCore::filter(flowData_transformedInflux, polyGate_sort) 
CellCount <- toTable(summary(CellCount))
CellCount <- CellCount$true
# Apply gate 
flowData_transformedInflux <- Subset(flowData_transformedInflux, polyGate_sort)

# Remove all variables that are no longer needed
remove(polyGate_sort)
```

```{r Influx_Gates, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Define gates for sorting
param_sort <- c("PMT 2", "PMT 3")
sqrcut1 <- log10(sinh(matrix(c(6.2,7.6,7.6,6.2,
            6.6,6.6,8.4,8.4),
            ncol = 2,
            nrow = 4)))
sqrcut1[!is.finite(sqrcut1)] <- 0
colnames(sqrcut1) <- param_sort
pGs_1 <- polygonGate(.gate = sqrcut1)

sqrcut1 <- log10(sinh(matrix(c(6,7.5,7.5,6,
            5.9,5.9,6.6,6.6),
            ncol = 2,
            nrow = 4)))
colnames(sqrcut1) <- param_sort
pGs_2 <- polygonGate(.gate = sqrcut1)

sqrcut1 <- log10(sinh(matrix(c(4,5.9,5.9,4,
            6.1,6.1,7,7),
            ncol = 2,
            nrow = 4)))
colnames(sqrcut1) <- param_sort
pGs_3 <- polygonGate(.gate = sqrcut1)

sqrcut1 <- log10(sinh(matrix(c(3.8,6.7,6.7,3.8,
            4.5,4.5,5.9,5.9),
            ncol = 2,
            nrow = 4)))
colnames(sqrcut1) <- param_sort
pGs_4 <- polygonGate(.gate = sqrcut1)

sqrcut1 <- log10(sinh(matrix(c(5, 6, 6,5,
          3.8,3.8,4.3,4.3),
          ncol = 2,
          nrow = 4)))
colnames(sqrcut1) <- param_sort
pGs_5 <- polygonGate(.gate = sqrcut1)

sqrcut1 <- log10(sinh(matrix(c(1.2, 3.25, 3.25,1.2,
            4,4,2.8,2.8),
            ncol = 2,
            nrow = 4)))
colnames(sqrcut1) <- param_sort
pGs_6 <- polygonGate(.gate = sqrcut1)


# All filters Influx
filtersallInflux <- list(filters(list(pGs_1, pGs_2, pGs_3, pGs_4, pGs_5)))
```

```{r Influx_fractions, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Count number of cells in subpopulation 1
Population1Count <- flowCore::filter(flowData_transformedInflux, pGs_1) 
Population1Count <- toTable(summary(Population1Count))
Population1Count <- Population1Count$true
Population1Fraction <- Population1Count/CellCount
# Count number of cells in subpopulation 2
Population2Count <- flowCore::filter(flowData_transformedInflux, pGs_2) 
Population2Count <- toTable(summary(Population2Count))
Population2Count <- Population2Count$true
Population2Fraction <- Population2Count/CellCount
# Count number of cells in subpopulation 3
Population3Count <- flowCore::filter(flowData_transformedInflux, pGs_3) 
Population3Count <- toTable(summary(Population3Count))
Population3Count <- Population3Count$true
Population3Fraction <- Population3Count/CellCount
# Count number of cells in subpopulation 4
Population4Count <- flowCore::filter(flowData_transformedInflux, pGs_4) 
Population4Count <- toTable(summary(Population4Count))
Population4Count <- Population4Count$true
Population4Fraction <- Population4Count/CellCount
# Count number of cells in subpopulation 5
Population5Count <- flowCore::filter(flowData_transformedInflux, pGs_5) 
Population5Count <- toTable(summary(Population5Count))
Population5Count <- Population5Count$true
Population5Fraction <- Population5Count/CellCount
# Count number of cells in subpopulation 6
Population6Count <- flowCore::filter(flowData_transformedInflux, pGs_6) 
Population6Count <- toTable(summary(Population6Count))
Population6Count <- Population6Count$true
Population6Fraction <- Population6Count/CellCount
# Store fractions in a dataframe
Fractions <- cbind.data.frame(sampleNames(flowData_transformedInflux), Population1Fraction, Population2Fraction, Population3Fraction, Population4Fraction, Population5Fraction, Population6Fraction)
colnames(Fractions)[1] <- "FileName"
FractionsInflux <- Fractions

# Remove all variables that are no longer needed
remove(CellCount, param_sort, sqrcut1, Population1Count, Population2Count, Population3Count, Population4Count, Population5Count, Population6Count, Population1Fraction, Population2Fraction, Population3Fraction, Population4Fraction, Population5Fraction, Population6Fraction, Fractions, pGs_1, pGs_2, pGs_3, pGs_4, pGs_5, pGs_6)
```

### Load and process FACS data

```{r FACS_Preprocess, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Find corresponding FACSVerse filenames (NOTE: the influx data 'A' and 'B' pooled)
SampleNamesSorting <- read.csv(file = "Metadata/SampleNamesInfluxData.csv", sep = ";") # contains labels of the samples that were measured on the influx
SampleNamesFACS <- readxl::read_excel("./Metadata/FACS-LABELS.xlsx")
SampleNamesFACS <- data.frame(SampleNamesFACS, do.call(rbind, strsplit(SampleNamesFACS$Sample_names, split = "_")))
# Combine the FACS and Influx names of the corresponding samples
SampleNamesSorting <- left_join(SampleNamesSorting, SampleNamesFACS[c("FACS_names", "Sample_names", "X1")], by = c("SampleName" = "X1"))
# For 1 sample there is no matching FACS file, remove this
SampleNamesSorting <- SampleNamesSorting[!is.na(SampleNamesSorting$FACS_names),]
# Uploaded FACSVerse files
filenames <- paste("./Data/Aquaculture/FCM/FACSVerse/", SampleNamesSorting$FACS_names, sep = "")
flowDataFACS <- read.flowSet(files = unique(filenames), pattern = ".fcs") 

# Transform the data
flowdataFACS_transformed <- transform(flowDataFACS,
                                   `FSC-H` = asinh(`FSC-H`),
                                    `SSC-H` = asinh(`SSC-H`),
                                    `FITC-H` = asinh(`FITC-H`),
                                    `PE-H` = asinh(`PE-H`),
                                    `PerCP-Cy5.5-H` = asinh(`PerCP-Cy5.5-H`),
                                    `PE-Cy7-H` = asinh(`PE-Cy7-H`),
                                    `APC-H` = asinh(`APC-H`),
                                    `V450-H` = asinh(`V450-H`),
                                    `V500-H` = asinh(`V500-H`))
# Make a gate
sqrcut1 <- matrix(c(6.8,6.9,12.7,12.7,
                    2.8,4,11,2.8),
                  ncol = 2, 
                  nrow = 4)
colnames(sqrcut1) <- c("FITC-H","PerCP-Cy5.5-H")
polyGate1 <- polygonGate(.gate = sqrcut1, filterId = "Total Cells")
# Plot the gate
xyplot(`PerCP-Cy5.5-H` ~ `FITC-H`, data = flowdataFACS_transformed[7],
              filter = polyGate1,
              scales = list(y = list(limits = c(2,12)),
                            x = list(limits = c(6,13.2))),
              axis = axis.default,
              xbin = 300,
              nbin = 125,
              par.settings = my.settings,
              smooth = FALSE)
# Count number of events inside this gate
CellCount <- flowCore::filter(flowdataFACS_transformed, polyGate1) 
CellCount <- toTable(summary(CellCount))
CellCount <- CellCount$true
# Apply gate 
flowdataFACS_transformed <- Subset(flowdataFACS_transformed, polyGate1)
```

```{r FACS_Gates, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
param_sort <- c("SSC-H", "FITC-H")

sqrcut1 <- matrix(c(7.8,9.8,9.8,7.8,
            10.6,10.6,12,12),
            ncol = 2,
            nrow = 4)
colnames(sqrcut1) <- param_sort
pGs_1 <- polygonGate(.gate = sqrcut1)

sqrcut1 <- matrix(c(7.2,9.8,9.8,7.2,
            9.9,9.9,10.5,10.5),
            ncol = 2,
            nrow = 4)
colnames(sqrcut1) <- param_sort
pGs_2 <- polygonGate(.gate = sqrcut1)

sqrcut1 <- matrix(c(7.2,6,6,7.2,
            10,10,10.8,10.8),
            ncol = 2,
            nrow = 4)
colnames(sqrcut1) <- param_sort
pGs_3 <- polygonGate(.gate = sqrcut1)

sqrcut1 <- matrix(c(7.2,5,5,8.5,8.5,7.2,
             10,10,8.6,8.6,9.9,9.9),
             ncol = 2, 
             nrow = 6)
colnames(sqrcut1) <- param_sort
pGs_4 <- polygonGate(.gate = sqrcut1)

sqrcut1 <- matrix(c(6,7,7,6,
            7.5,7.5,8.5,8.5),
            ncol = 2,
            nrow = 4)
colnames(sqrcut1) <- param_sort
pGs_5 <- polygonGate(.gate = sqrcut1)

sqrcut1 <- matrix(c(2.8,4.5,4.5,2.8,
            7.6,7.6,8.7,8.7),
            ncol = 2,
            nrow = 4)
colnames(sqrcut1) <- param_sort
pGs_6 <- polygonGate(.gate = sqrcut1)

# All filters Verse
filtersallVerse <- list(filters(list(pGs_1, pGs_2, pGs_3, pGs_4, pGs_5)))
```

```{r InSilicoSortedPopulations, echo=FALSE, fig.height=8, fig.width=12, message=FALSE, warning=FALSE, cache=FALSE, dev=c("png"), dpi=500}
Metadata <- read.xlsx(xlsxFile = "Metadata/MetadataSequencing.xlsx")
# Make the in silico sorted populations so they can also be used to train/verify the model predictions
MetadataSortedSamples <- Metadata[Metadata$WholeCommunityOrSorted == "Sorted" & !(Metadata$SampleIdentifierFCM %in% c("Sheath", "Chelex")),]
MetadataSortedSamples <- MetadataSortedSamples[c("SampleIdentifierFCM", "Population")]
# Initialise empty flow frame to store the sorted populations
flowData_transformed_InSilico <- new('flowSet')
# Initialise metadata dataframe
MetadataInSilico <- NULL
# Check for every sample which populations were sorted out and make the fcs-file for the corresponding in silico sorted population
MetadataSortedSamples <- MetadataSortedSamples[!MetadataSortedSamples$Population == "Inv",]
MetadataSortedSamples <- MetadataSortedSamples[!MetadataSortedSamples$Population == 6,]
for (i in unique(MetadataSortedSamples$SampleIdentifierFCM)){
  # Get the name of the fcs-file from the FACS that corresponds with this
  SelectedSample <- gsub("A/B", "A", i)
  SelectedSampleName <- SampleNamesSorting$FACS_names[SampleNamesSorting$SampleName == SelectedSample]
  flowData_transformed <- flowdataFACS_transformed[SelectedSampleName[1]]
  # Get the metadata that correspond to this sample
  SelectedMetadata <- MetadataSortedSamples[MetadataSortedSamples$SampleIdentifierFCM == i,]
  for (j in 1:dim(SelectedMetadata)[1]){
      # Get the population
      Population <- SelectedMetadata$Population[j]
      # 
      if (Population == "1"){
        flowData_transformedGated <- Subset(flowData_transformed, pGs_1)
      } else if (Population == "2"){
        flowData_transformedGated <- Subset(flowData_transformed, pGs_2)  
      } else if (Population == "3"){
        flowData_transformedGated <- Subset(flowData_transformed, pGs_3)  
      } else if (Population == "4"){
        flowData_transformedGated <- Subset(flowData_transformed, pGs_4)
      } else if (Population %in% c("5", "5b")){
        flowData_transformedGated <- Subset(flowData_transformed, pGs_5)
      } else if (Population == "Cells"){
        flowData_transformedGated <- flowData_transformed
      } 
      ReplacementFileName <- paste(SelectedSample, "_", Population, ".fcs", sep = "")
      # Store the data of the sorted population
      sampleNames(flowData_transformedGated) <- ReplacementFileName
      flowData_transformed_InSilico <- rbind2(flowData_transformed_InSilico, flowData_transformedGated)
      # Store metadata
      MetadataInSilicoSample <- cbind.data.frame(ReplacementFileName, Population, SelectedSample)
      MetadataInSilico <- rbind(MetadataInSilico, MetadataInSilicoSample)
    }
}
# Save the in silico sorted samples
saveRDS(flowData_transformed_InSilico, file = "Data/Aquaculture/FCM/Sorted.rds")
# Save the metadata file
colnames(MetadataInSilico) <- c("Filename", "Population", "Sample")
write.csv(MetadataInSilico, file = "Metadata/MetadataInSilicoSortedFCS.csv")
```

```{r FACS_fractions, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Count number of cells in subpopulation 1
Population1Count <- flowCore::filter(flowdataFACS_transformed, pGs_1) 
Population1Count <- toTable(summary(Population1Count))
Population1Count <- Population1Count$true
Population1Fraction <- Population1Count/CellCount
# Count number of cells in subpopulation 2
Population2Count <- flowCore::filter(flowdataFACS_transformed, pGs_2) 
Population2Count <- toTable(summary(Population2Count))
Population2Count <- Population2Count$true
Population2Fraction <- Population2Count/CellCount
# Count number of cells in subpopulation 3
Population3Count <- flowCore::filter(flowdataFACS_transformed, pGs_3) 
Population3Count <- toTable(summary(Population3Count))
Population3Count <- Population3Count$true
Population3Fraction <- Population3Count/CellCount
# Count number of cells in subpopulation 4
Population4Count <- flowCore::filter(flowdataFACS_transformed, pGs_4) 
Population4Count <- toTable(summary(Population4Count))
Population4Count <- Population4Count$true
Population4Fraction <- Population4Count/CellCount
# Count number of cells in subpopulation 5
Population5Count <- flowCore::filter(flowdataFACS_transformed, pGs_5) 
Population5Count <- toTable(summary(Population5Count))
Population5Count <- Population5Count$true
Population5Fraction <- Population5Count/CellCount
# Count number of cells in subpopulation 6
Population6Count <- flowCore::filter(flowdataFACS_transformed, pGs_6) 
Population6Count <- toTable(summary(Population6Count))
Population6Count <- Population6Count$true
Population6Fraction <- Population6Count/CellCount
# Store fractions in a dataframe
Fractions <- cbind.data.frame(sampleNames(flowdataFACS_transformed), Population1Fraction, Population2Fraction, Population3Fraction, Population4Fraction, Population5Fraction, Population6Fraction)
colnames(Fractions)[1] <- "FileName"
FractionsVerse <- Fractions

# Remove all variables that are no longer needed
remove(CellCount, param_sort, sqrcut1, Population1Count, Population2Count, Population3Count, Population4Count, Population5Count, Population6Count, Population1Fraction, Population2Fraction, Population3Fraction, Population4Fraction, Population5Fraction, Population6Fraction, Fractions)
```

### Compare gating

```{r CompareGates_PlotFACSInflux, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Plot
for (i in 1:length(flowdataFACS_transformed)){
  names(filtersallVerse) <- flowCore::sampleNames(flowdataFACS_transformed[SampleNamesSorting$FACS_names[i]])
  FACS <- xyplot(`FITC-H` ~ `SSC-H`, data = flowdataFACS_transformed[SampleNamesSorting$FACS_names[i]],
              filter = filtersallVerse,
              scales = list(y = list(limits = c(7.5,12.5)),
                            x = list(limits = c(2.5,10))),
              axis = axis.default,
              strip = FALSE,
              xbin = 300,
              nbin = 200,
              par.settings = my.settings,
              smooth = FALSE)
  names(filtersallInflux) <- flowCore::sampleNames(flowData_transformedInflux[SampleNamesSorting$FileName[i]])
  Influx <- xyplot(`PMT 3` ~ `PMT 2`, data = flowData_transformedInflux[SampleNamesSorting$FileName[i]], 
              filter = filtersallInflux,
              scales = list(y = list(limits = c(0.9,3.6)),
                            x = list(limits = c(0.1,3.4))),
              axis = axis.default, 
              strip = FALSE,
              xbin = 300,
              nbin = 200, 
              par.strip.text = list(col = "black", font = 3, cex = 0.75), 
              smooth = FALSE,
              par.settings = my.settings,
              yscale.components = yscale.components.log10,
              xscale.components = xscale.components.log10)
  Combined <- c(FACS, Influx)
  # png(paste("Figures/Gates_InfluxFacs/Gates-", i,".png", sep = ""), width = 8, height = 4, res = 500, units = "in")
  # print(Combined)
  # dev.off()
}
```

```{r CompareGates_PlotFACSInflux, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Plot example for paper
    # Normalise FACS
    summary <- fsApply(x = flowdataFACS_transformed, FUN = function(x) apply(x, 2, max), use.exprs = TRUE)
    maxval <- max(summary[,"FITC-H"])
    mytrans <- function(x) x/maxval
    flowdataFACS_transformed <- transform(flowdataFACS_transformed,
                                      `FITC-H` = mytrans(`FITC-H`),
                                      `PerCP-Cy5.5-H` = mytrans(`PerCP-Cy5.5-H`), 
                                      `SSC-H` = mytrans(`SSC-H`),
                                      `FSC-H` = mytrans(`FSC-H`),
                                      `PE-H` = mytrans(`PE-H`),
                                      `PE-Cy7-H` = mytrans(`PE-Cy7-H`), 
                                      `APC-H` = mytrans(`APC-H`), 
                                      `V450-H` = mytrans(`V450-H`),
                                      `V500-H` = mytrans(`V500-H`))
    
    # Normalise FACS gates
    param_sort <- c("SSC-H", "FITC-H")
    
    sqrcut1 <- mytrans(matrix(c(7.8,9.8,9.8,7.8,10.6,10.6,12,12), ncol = 2, nrow = 4))
    colnames(sqrcut1) <- param_sort
    pGs_1 <- polygonGate(.gate = sqrcut1)
    
    sqrcut1 <- mytrans(matrix(c(7.2,9.8,9.8,7.2,9.9,9.9,10.5,10.5), ncol = 2, nrow = 4))
    colnames(sqrcut1) <- param_sort
    pGs_2 <- polygonGate(.gate = sqrcut1)
    
    sqrcut1 <- mytrans(matrix(c(7.2,6,6,7.2,10,10,10.8,10.8), ncol = 2, nrow = 4))
    colnames(sqrcut1) <- param_sort
    pGs_3 <- polygonGate(.gate = sqrcut1)
    
    sqrcut1 <- mytrans(matrix(c(7.2,5,5,8.5,8.5,7.2,10,10,8.6,8.6,9.9,9.9), ncol = 2, nrow = 6))
    colnames(sqrcut1) <- param_sort
    pGs_4 <- polygonGate(.gate = sqrcut1)
    
    sqrcut1 <- mytrans(matrix(c(6,7,7,6,7.5,7.5,8.5,8.5), ncol = 2, nrow = 4))
    colnames(sqrcut1) <- param_sort
    pGs_5 <- polygonGate(.gate = sqrcut1)
    
    sqrcut1 <- mytrans(matrix(c(2.8,4.5,4.5,2.8,7.6,7.6,8.7,8.7), ncol = 2, nrow = 4))
    colnames(sqrcut1) <- param_sort
    pGs_6 <- polygonGate(.gate = sqrcut1)
    
    # All filters Verse
    filtersallVerse <- list(filters(list(pGs_1, pGs_2, pGs_3, pGs_4, pGs_5)))
    
    
    
    
    # Transformation influx
    # Normalise
    summary <- fsApply(x = flowData_transformedInflux, FUN = function(x) apply(x, 2, max), use.exprs = TRUE)
    maxval <- max(summary[,"PMT 3"])
    mytrans <- function(x) x/maxval
    flowData_transformedInflux <- transform(flowData_transformedInflux,
                                      `PMT 3` = mytrans(`PMT 3`),
                                      `PMT 2` = mytrans(`PMT 2`))
    
    # Define gates for sorting
    param_sort <- c("PMT 2", "PMT 3")
    sqrcut1 <- mytrans(log10(sinh(matrix(c(6.2,7.6,7.6,6.2,6.6,6.6,8.4,8.4), ncol = 2, nrow = 4))))
    sqrcut1[!is.finite(sqrcut1)] <- 0
    colnames(sqrcut1) <- param_sort
    pGs_1 <- polygonGate(.gate = sqrcut1)
    
    sqrcut1 <- mytrans(log10(sinh(matrix(c(6,7.5,7.5,6,5.9,5.9,6.6,6.6), ncol = 2, nrow = 4))))
    colnames(sqrcut1) <- param_sort
    pGs_2 <- polygonGate(.gate = sqrcut1)
    
    sqrcut1 <- mytrans(log10(sinh(matrix(c(4,5.9,5.9,4, 6.1,6.1,7,7), ncol = 2, nrow = 4))))
    colnames(sqrcut1) <- param_sort
    pGs_3 <- polygonGate(.gate = sqrcut1)
    
    sqrcut1 <- mytrans(log10(sinh(matrix(c(3.8,6.7,6.7,3.8,4.5,4.5,5.9,5.9), ncol = 2, nrow = 4))))
    colnames(sqrcut1) <- param_sort
    pGs_4 <- polygonGate(.gate = sqrcut1)
    
    sqrcut1 <- mytrans(log10(sinh(matrix(c(5, 6, 6,5,3.8,3.8,4.3,4.3),ncol = 2,nrow = 4))))
    colnames(sqrcut1) <- param_sort
    pGs_5 <- polygonGate(.gate = sqrcut1)
    
    sqrcut1 <- mytrans(log10(sinh(matrix(c(1.2, 3.25, 3.25,1.2,4,4,2.8,2.8), ncol = 2,nrow = 4))))
    colnames(sqrcut1) <- param_sort
    pGs_6 <- polygonGate(.gate = sqrcut1)
    
    # All filters Influx
    filtersallInflux <- list(filters(list(pGs_1, pGs_2, pGs_3, pGs_4, pGs_5)))
```

```{r CompareGates_PlotFACSInflux, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Szlzct sample for plotting
i = 14
# i = 10 #31

names(filtersallVerse) <- flowCore::sampleNames(flowdataFACS_transformed[SampleNamesSorting$FACS_names[i]])
FACS <- xyplot(`FITC-H` ~ `SSC-H`, data = flowdataFACS_transformed[SampleNamesSorting$FACS_names[i]],
              filter = filtersallVerse,
              scales = list(y = list(limits = c(0.55,1)),
                            x = list(limits = c(0.3,0.85))),
              # scales = list(y = list(limits = c(0.65,0.95)),
              #               x = list(limits = c(0.35,0.8))),
              axis = axis.default,
              xlab = list(label = "Side scatter"),
              ylab = list(label = "SYBR Green I fluorescence"),
              strip = FALSE,
              xbin = 350,
              nbin = 350,
              par.settings = my.settings,
              smooth = FALSE)
FACS


names(filtersallInflux) <- flowCore::sampleNames(flowData_transformedInflux[SampleNamesSorting$FileName[i]])
Influx <- xyplot(`PMT 3` ~ `PMT 2`, data = flowData_transformedInflux[SampleNamesSorting$FileName[i]], 
              filter = filtersallInflux,
              scales = list(y = list(limits = c(0.25,0.9)),
                            x = list(limits = c(0.2,0.85))),
              # scales = list(y = list(limits = c(0.39 ,0.85)),
              #               x = list(limits = c(0.25,0.85))),
              axis = axis.default,
              xlab = list(label = "Side scatter"),
              ylab = list(label = "SYBR Green I fluorescence"),
              strip = FALSE,
              xbin = 300,
              nbin = 300, 
              par.strip.text = list(col = "black", font = 3, cex = 0.75), 
              smooth = FALSE,
              par.settings = my.settings)

Influx

g1 <- plot_grid(Influx, FACS, labels = c("A", "B"), ncol = 2, nrow = 1, scale = 1)
g1

# ggsave(file = "Figures/FACSvsInflux.png", width = 8, height = 4.5, dpi = 500, units = "in", g1)
```

```{r CompareGates_CorrelationFACSInflux, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Fractions
AllFractions <- FractionsInflux
colnames(AllFractions)[2:7] <- c("1", "2", "3", "4", "5", "6")
AllFractions <- left_join(AllFractions, SampleNamesSorting[c("FileName", "SampleName")], by = c("FileName"))
AllFractions$SampleName <- as.character(gsub("B", "A/B", AllFractions$SampleName))
AllFractions$SampleName <- as.character(gsub("A", "A/B", AllFractions$SampleName))
# Upload metadata sequencing samples
MetadataIllumina <- read.xlsx(xlsxFile = "Metadata/MetadataIllumina.xlsx")
MetadataIllumina <- MetadataIllumina[MetadataIllumina$Population %in% c("1","2","3","4","5"),]
# Get fractions of the samples that were sorted
FractionsSorted <- NULL
for (i in unique(MetadataIllumina$Population)){
  MetadataIlluminaPop <- MetadataIllumina[MetadataIllumina$Population == i,]
  for (j in 1:dim(MetadataIlluminaPop)[1]){
    # Get fraction
    SelectedFraction <- AllFractions[AllFractions$SampleName == MetadataIlluminaPop$SampleIdentifierFCM[j], i]
    # Save in a new dataframe 
    FractionsSorted <- rbind.data.frame(FractionsSorted, cbind.data.frame(i, MetadataIlluminaPop$SampleIdentifierFCM[j], SelectedFraction))
  }
}
colnames(FractionsSorted) <- c("population", "sample", "fraction")
write.csv(FractionsSorted, file = "Results/FractionsSorted.csv")
```

```{r CompareGates_CorrelationFACSInflux, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Fractions of the subpopulations based on the FACSVerse data
FractionsVerse <- melt(FractionsVerse)
FractionsVerse <- left_join(FractionsVerse, SampleNamesSorting[c("SampleName", "FACS_names")], by = c("FileName" = "FACS_names"))
# Fractions of the subpopulations based on the Influx data
FractionsInflux <- melt(FractionsInflux)
FractionsInflux <- left_join(FractionsInflux, SampleNamesSorting[c("FileName", "SampleName")], by = c("FileName" = "FileName"))
# Combine datasets
Fractions <- left_join(FractionsVerse[c("variable", "value", "SampleName")], FractionsInflux[c("variable", "value", "SampleName")], by = c("SampleName" = "SampleName", "variable" = "variable"))
colnames(Fractions) <- c("Population", "FractionVerse", "SampleName", "FractionInflux")

# Plot
Fractions <- Fractions[!Fractions$Population == "Population6Fraction",]
PopulationColors <- c("#82487d", "#edd958", "#3c4175", "#60be8f", "#6c72dd")
# Fit linear model
LM_Fractions <- lm(FractionVerse ~ FractionInflux, data = Fractions) 
# Plot relation between cell counts of all samples together
p_CorrFractions <- Fractions %>%
                       ggplot(data = ., aes(x = 100*FractionVerse, y = 100*FractionInflux)) +
                       geom_point(shape = 21, size = 3, alpha = 1, aes(fill = Population)) +
                       scale_fill_manual("", values = PopulationColors, labels = c("SC 1","SC 2","SC 3","SC 4","SC 5")) +
                       labs(fill = "", x = "Relative abundance on FACSVerse (%)", y = "Relative abundance on Influx (%)") +
                       guides(color = FALSE) +
                       geom_abline(intercept = 0, slope = 1) +
                       coord_fixed() +
                       theme_cowplot() +
                       theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet)) + 
                       annotate(geom = "text", x = 50, y = 10, label = paste0("Adj.R.sq. = ", format(summary(LM_Fractions)$r.squared, digits = 2), "\nCp = ", format(cor((Fractions$FractionVerse), (Fractions$FractionInflux), use = "pairwise.complete.obs"), digits = 2)))
```

```{r CompareGates_CorrelationFACSInflux, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
g1 <- plot_grid(Influx, FACS, labels = c("A", "B"), ncol = 2, nrow = 1, scale = 1)
g2 <- plot_grid(g1, p_CorrFractions, labels = c("", "C"), ncol = 1, nrow = 2, scale = 1)
ggsave(file = "Figures/SORTING-IllustrationGateAndCorrelation.png", width = 8, height = 8, dpi = 500, units = "in", g2)

# Remove all variables that are no longer needed
remove(p_CorrFractions, LM_Fractions, FractionsInflux, FractionsVerse, Combined, FACS, filtersallVerse, filtersallInflux, flowData_transformedInflux, flowDataFACS, polyGate1, Influx, filenames, Fractions, i, g1, g2, AllFractions, flowdataFACS_transformed, FractionsSorted, MetadataIllumina, MetadataIlluminaPop, pGs_1, pGs_2, pGs_3, pGs_4, pGs_5, pGs_6, SampleNamesFACS, SampleNamesSorting, sqrcut1, summary, j, maxval, param_sort, SelectedFraction, flowdataFACS_transformed, flowData_transformed_InSilico, flowData_transformedGated, Metadata, MetadataInSilicoSample, MetadataSortedSamples, SelectedMetadata, Population, ReplacementFileName, MetadataInSilico, flowData_transformed, SelectedSample, SelectedSampleName)
```

## Evaluate sorting results and extra control samples

### Processing Illumina data

```{r UploadMetadata, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Upload metadata
Metadata <- read.xlsx(xlsxFile = "Metadata/MetadataIllumina.xlsx")
rownames(Metadata) <- Metadata$Identifier
ReadQuality <- read.xlsx(xlsxFile = "Metadata/QCInfoBaseClear.xlsx")
# Add the readquality info to the metadata
Metadata <- left_join(Metadata, ReadQuality, by = c("Identifier" = "Samplename"))
remove(ReadQuality)
# Split the sample-identifiers
Metadata <- cbind(Metadata, do.call(rbind, strsplit(as.character(Metadata$SampleIdentifierFCM), split = ".", fixed = TRUE)))
colnames(Metadata)[12:15] <- c("Tank", "Day", "Timepoint", "Feeding_status")
Metadata$Day <- as.numeric(gsub("D", "", Metadata$Day))
```

```{r LoadInfoFromSummaries, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# file direcrory
fldr <-  "Data/Aquaculture/Illumina/"
# Load info from the summary-files
filelist <- list.files(fldr)
crfn <- grep(".*contigs.report", filelist, value = TRUE)
fn <- sub(".contigs.report", "", crfn)
ini <- data.table::fread(paste(fldr, "/", crfn, sep = ""), header = TRUE)
csum <- data.table::fread(paste(fldr, "/", fn, ".trim.contigs.summary", sep = ""), header = TRUE)
firsttrimsum <- data.table::fread(paste(fldr, "/", fn, ".trim.contigs.good.summary", sep = ""), header = TRUE)
uniquesum <- data.table::fread(paste(fldr, "/", fn, ".trim.contigs.good.unique.summary", sep = ""), header = TRUE)
postalnsum <- data.table::fread(paste(fldr, "/", fn, ".trim.contigs.good.unique.good.filter.summary", sep = ""), header = TRUE)
preclussum <- data.table::fread(paste(fldr, "/", fn, ".trim.contigs.good.unique.good.filter.unique.precluster.summary", sep = ""), header = TRUE)
postuchimeclasssum <- data.table::fread(paste(fldr, "/", fn, ".trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.summary", sep = ""), header = TRUE)

# Remove all variables that will not be used further
remove(filelist, crfn, ini)
```

```{r LoadMothurResults, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Load taxonomy from Mothur output files
otutaxonomy <- data.table::fread(paste(fldr, "/", fn, ".trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.opti_mcc.0.03.cons.taxonomy", sep = ""), header = TRUE)
taxonomy.spl <- preformattax(otutaxonomy)
taxonomy.np <- taxonomy.spl %>% dplyr::select(-dplyr::contains("Prob"))

# Load the shared file for getting the OTU abundances per sample
shared <- data.table::fread(paste(fldr, "/", fn, ".trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.opti_mcc.shared", sep = ""), header = TRUE)
shared <- as.data.frame(shared)
desgroups <- shared$Group # the samplenames
shared.x <- shared[, 4:ncol(shared)] # only the OTU info
rownames(shared.x) <- desgroups
shared.t <- as.data.frame(t(shared.x))

# Removal of singletons from the OTU table and the taxonomy results (singletons = OTU's that only occur once over the entire dataset)
shared.t.ns <- shared.t[which(rowSums(shared.t)!=1),]
taxonomy.np.ns <- taxonomy.np[which(rownames(taxonomy.np) %in% rownames(shared.t.ns)),]

# Save the OTU table (with and without singletons) in an excel sheet
tmp.otu <- cbind(rownames(shared.t), shared.t)
colnames(tmp.otu) <- c("OTU", colnames(shared.t))
tmp.otu.ns <- cbind(rownames(shared.t.ns), shared.t.ns)
colnames(tmp.otu.ns) <- c("OTU", colnames(shared.t.ns))

# Remove all variables that will not be used further
remove(fldr, fn, otutaxonomy, taxonomy.spl, taxonomy.np, shared, desgroups, shared.x, shared.t, tmp.otu, tmp.otu.ns)
```

```{r LoadMothurResults, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# # Load the Accuri C6+ data
# Counts <- read.csv("Results/DYNAMICS-OffSite-AccuriC6Plus-Counting.csv")
# Counts <- Counts[c("Sample", "BacterialDensity")]
# Counts$Sample <- gsub("Artemia", "Art", Counts$Sample)
# # Sample names are not perfectly matching: "Artemia" --> "Art"
# Metadata <- left_join(Metadata, Counts, by = c("SampleIdentifierFCM" = "Sample"))
# 
# # Remove all variables that will not be used further
# remove(Counts)
```

```{r CommunitiesTanks_RelAbundanceOnlyNotCrashed, echo = TRUE, dpi = 800, out.width = "90%", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold", eval = TRUE}
# Make phyloseq object from the data
otumat.ns <- as.matrix(shared.t.ns[Metadata$Identifier])
taxmat.ns <- as.matrix(taxonomy.np.ns)
info <- Metadata[Metadata$Identifier %in% colnames(otumat.ns),]
OTU <- otu_table(otumat.ns, taxa_are_rows = TRUE)
TAX <- tax_table(taxmat.ns)
INFO <- sample_data(info)
rownames(INFO) <- INFO$Identifier
physeqobj <- phyloseq(OTU, TAX, INFO)

# Do the scaling
physeqobj <- scale_reads(physeqobj, n = 20000)

# Save the scaled data as the otu-table
shared.t.ns.old <- shared.t.ns # Keep this to check later which OTU's were not used (needed in the community assembly part)
shared.t.ns <- as.data.frame(otu_table(physeqobj))
taxonomy.np.ns <- as.data.frame(physeqobj@tax_table@.Data)

# Save the OTU table (with and without singletons) in an excel sheet
tmp.otu.ns <- cbind(rownames(shared.t.ns), shared.t.ns)
colnames(tmp.otu.ns) <- c("OTU", colnames(shared.t.ns))

# Remove all variables that will not be used further
remove(OTU, TAX, INFO, info, physeqobj, otumat.ns, taxmat.ns, IdentifierControlSamples)
```

### Evaluate control samples

#### Chelex vs. Zymo

```{r ChelexVsZymo_Mock, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
# Upload the real composition of the Zymo mock
MockComposition <- read.xlsx(xlsxFile = "Metadata/Mock_ZRC190811.xlsx")
MockComposition$Group <- "Mock"
colnames(MockComposition) <- c("Genus", "Species", "RelativePercentage", "Group")
# Get samples to compare zymo and chelex extractions (M4, M3, T4, T1, T5, T2, T6, T3)
shared.controls <- shared.t.ns[c("M4", "M3")]
# Generate matrix with both abundance and taxonomy info in order to be able to select the names of the top 10 genera
df.all <- cbind.data.frame(taxonomy.np.ns, shared.t.ns[c("M4", "M3")], rowSums(shared.controls))
colnames(df.all)[dim(df.all)[2]] <- "Summed"
Aggregated <- aggregate(df.all$Summed, by = list(Category = df.all[,"Genus"]), FUN = sum) # Aggregate at the genus level
Top <- Aggregated$Category[order(Aggregated$x, decreasing = TRUE)][1:8]
# All genera that do not belong to the top genera should be collapsed into 1 class called "Other"
df.all$Genus <- as.character(df.all$Genus)
df.all$Genus[!(df.all$Genus %in% Top)] <- "Other"
# # Add the real mock composition to the table
Aggregated <- ddply(df.all, .(Genus), numcolwise(sum))
df.tmp <- left_join(Aggregated[c("Genus", "M4", "M3")], MockComposition[c("Genus", "RelativePercentage")], by = c("Genus"))
colnames(df.tmp) <- c("Genus", "Zymo", "Chelex", "Theoretical")
# Phyloseq
SubsetOTU       <- otu_table(as.matrix(df.tmp[c("Zymo", "Chelex", "Theoretical")]), taxa_are_rows = TRUE)
SubsetTAX       <- tax_table(as.matrix(df.tmp["Genus"]))
Subsetphyseqobj <- phyloseq(SubsetOTU, SubsetTAX)
Subsetphyseqobj <- Subsetphyseqobj %>%
                    tax_glom(taxrank = "Genus") %>%
                    transform_sample_counts(function(x) {x/sum(x)}) %>% # Transform to relative abundances
                    psmelt()
Subsetphyseqobj$Genus <- as.factor(Subsetphyseqobj$Genus)
p_comp_mock <- Subsetphyseqobj %>%
                  dplyr::mutate(Sample = factor(Sample, levels = c("Zymo", "Chelex", "Theoretical"))) %>% 
                  dplyr::mutate(Genus = factor(Genus, levels = c("Other", levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) %>% 
                  ggplot(data = ., aes_string(x = "Sample", y = "Abundance", fill = "Genus")) + 
                  geom_bar(stat = "identity", colour = "black") +
                  scale_fill_manual(values = c(ColorBlocksFacet, brewer.pal(8,"Spectral")), labels = c("Other", make.italic(levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) +
                  scale_x_discrete("") +
                  theme(axis.title.x = element_blank()) + 
                  guides(fill = guide_legend(reverse = TRUE, keywidth = 1, keyheight = 1)) +
                  ylab("Relative Abundance") +
                  theme_cowplot() +
                  theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), legend.text.align = 0) 
print(p_comp_mock)

# Remove all variables that will not be used further
remove(p_comp_mock, Aggregated, df.all, shared.controls, Subsetphyseqobj, df.tmp, SubsetOTU, SubsetTAX, Top)
```

```{r ChelexVsZymo_Tank, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
# Get samples to compare zymo and chelex extractions (M4, M3, T4, T1, T5, T2, T6, T3)
shared.controls <- shared.t.ns[c("T5", "T2")]
# Generate matrix with both abundance and taxonomy info in order to be able to select the names of the top 10 genera
df.all <- cbind.data.frame(taxonomy.np.ns, shared.t.ns[c("T5", "T2")], rowSums(shared.controls))
colnames(df.all)[dim(df.all)[2]] <- "Summed"
Aggregated <- aggregate(df.all$Summed, by = list(Category = df.all[,"Genus"]), FUN = sum) # Aggregate at the genus level
Top <- Aggregated$Category[order(Aggregated$x, decreasing = TRUE)][1:16]
# All genera that do not belong to the top genera should be collapsed into 1 class called "Other"
df.all$Genus <- as.character(df.all$Genus)
df.all$Genus[!(df.all$Genus %in% Top)] <- "Other"
# Subset to top instances
SubsetOTU       <- otu_table(as.matrix(shared.controls), taxa_are_rows = TRUE)
SubsetTAX       <- tax_table(as.matrix(df.all[colnames(taxonomy.np.ns)]))
Subsetphyseqobj <- phyloseq(SubsetOTU, SubsetTAX)
# Plot
Subsetphyseqobj <- Subsetphyseqobj %>%
                    transform_sample_counts(function(x) {x/sum(x)}) %>% # Transform to relative abundances
                    psmelt()
Subsetphyseqobj$Genus <- as.factor(Subsetphyseqobj$Genus)
p_comp_tank <- Subsetphyseqobj %>%
                  dplyr::mutate(Sample = factor(Sample, levels = c("T5", "T2"))) %>% 
                  dplyr::mutate(Genus = factor(Genus, levels = c("Other", levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) %>% 
                  ggplot(data = ., aes(x = Sample, y = 100*Abundance, fill = Genus)) + 
                  geom_bar(stat = "identity", colour = "black") +
                  scale_fill_manual(values = c(ColorBlocksFacet, Series16), labels = c("Other", make.italic(levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) +
                  scale_x_discrete("", labels = c("Zymo", "Chelex")) +
                  theme(axis.title.x = element_blank()) + 
                  guides(fill = guide_legend(reverse = TRUE, keywidth = 1, keyheight = 1, ncol = 1, title.position = "top")) +
                  ylab("Relative abundance (%)") +
                  theme_cowplot() +
                  theme(legend.text.align = 0, legend.position = "bottom", plot.margin = unit(x = c(-1, 0, 0.5, 0), units = "cm"))
print(p_comp_tank)

# Calculate average abundances of OTUs unique to one of the two extractions
shared.controls <- shared.t.ns[c("T5", "T2")]
shared.controls <- sweep(shared.controls, 2, colSums(shared.controls), `/`)
shared.controls$RowSums <- rowSums(shared.controls > 0)
shared.controls <- shared.controls[shared.controls$RowSums == 1,] # Uniquely detected

100*mean(as.matrix(shared.controls[c("T5", "T2")]))
100*median(as.matrix(shared.controls[c("T5", "T2")]))
```

```{r ChelexVsZymo_ALgae, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
# Get samples to compare zymo and chelex extractions (M4, M3, T4, T1, T5, T2, T6, T3)
shared.controls <- shared.t.ns[c("T6", "T3")]
# Generate matrix with both abundance and taxonomy info in order to be able to select the names of the top 10 genera
df.all <- cbind.data.frame(taxonomy.np.ns, shared.t.ns[c("T6", "T3")], rowSums(shared.controls))
colnames(df.all)[dim(df.all)[2]] <- "Summed"
Aggregated <- aggregate(df.all$Summed, by = list(Category = df.all[,"Genus"]), FUN = sum) # Aggregate at the genus level
Top <- Aggregated$Category[order(Aggregated$x, decreasing = TRUE)][1:16]
# All genera that do not belong to the top genera should be collapsed into 1 class called "Other"
df.all$Genus <- as.character(df.all$Genus)
df.all$Genus[!(df.all$Genus %in% Top)] <- "Other"
# Subset to top instances
SubsetOTU       <- otu_table(as.matrix(shared.controls), taxa_are_rows = TRUE)
SubsetTAX       <- tax_table(as.matrix(df.all[colnames(taxonomy.np.ns)]))
Subsetphyseqobj <- phyloseq(SubsetOTU, SubsetTAX)
# Plot
Subsetphyseqobj <- Subsetphyseqobj %>%
                    transform_sample_counts(function(x) {x/sum(x)}) %>% # Transform to relative abundances
                    psmelt()
Subsetphyseqobj$Genus <- as.factor(Subsetphyseqobj$Genus)
p_comp_alg <- Subsetphyseqobj %>%
                  dplyr::mutate(Sample = factor(Sample, levels = c("T6", "T3"))) %>% 
                  dplyr::mutate(Genus = factor(Genus, levels = c("Other", levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) %>% 
                  ggplot(data = ., aes(x = Sample, y = 100*Abundance, fill = Genus)) + 
                  geom_bar(stat = "identity", colour = "black") +
                  scale_fill_manual(values = c(ColorBlocksFacet, Series16), labels = c("Other", make.italic(levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) +
                  scale_x_discrete("", labels = c("Zymo", "Chelex")) +
                  theme(axis.title.x = element_blank()) + 
                  guides(fill = guide_legend(reverse = TRUE, keywidth = 1, keyheight = 1, ncol = 1, title.position = "top")) +
                  ylab("Relative abundance (%)") +
                  theme_cowplot() +
                  theme(legend.text.align = 0, legend.position = "bottom", plot.margin = unit(x = c(-1, 0, 0.5, 0), units = "cm"))
print(p_comp_alg)

# Calculate average abundances of OTUs unique to one of the two extractions
shared.controls <- shared.t.ns[c("T6", "T3")]
shared.controls <- sweep(shared.controls, 2, colSums(shared.controls), `/`)
shared.controls$RowSums <- rowSums(shared.controls > 0)
shared.controls <- shared.controls[shared.controls$RowSums == 1,] # Uniquely detected

100*mean(as.matrix(shared.controls[c("T6", "T3")]))
100*median(as.matrix(shared.controls[c("T6", "T3")]))

```

```{r ChelexVsZymo_Artemia, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
# Get samples to compare zymo and chelex extractions (M4, M3, T4, T1, T5, T2, T6, T3)
shared.controls <- shared.t.ns[c("T4", "T1")]
# Generate matrix with both abundance and taxonomy info in order to be able to select the names of the top 10 genera
df.all <- cbind.data.frame(taxonomy.np.ns, shared.t.ns[c("T4", "T1")], rowSums(shared.controls))
colnames(df.all)[dim(df.all)[2]] <- "Summed"
Aggregated <- aggregate(df.all$Summed, by = list(Category = df.all[,"Genus"]), FUN = sum) # Aggregate at the genus level
Top <- Aggregated$Category[order(Aggregated$x, decreasing = TRUE)][1:16]
# All genera that do not belong to the top genera should be collapsed into 1 class called "Other"
df.all$Genus <- as.character(df.all$Genus)
df.all$Genus[!(df.all$Genus %in% Top)] <- "Other"
# Subset to top instances
SubsetOTU       <- otu_table(as.matrix(shared.controls), taxa_are_rows = TRUE)
SubsetTAX       <- tax_table(as.matrix(df.all[colnames(taxonomy.np.ns)]))
Subsetphyseqobj <- phyloseq(SubsetOTU, SubsetTAX)
# Plot
Subsetphyseqobj <- Subsetphyseqobj %>%
                    transform_sample_counts(function(x) {x/sum(x)}) %>% # Transform to relative abundances
                    psmelt()
Subsetphyseqobj$Genus <- as.factor(Subsetphyseqobj$Genus)
p_comp_art <- Subsetphyseqobj %>%
                  dplyr::mutate(Sample = factor(Sample, levels = c("T4", "T1"))) %>% 
                  dplyr::mutate(Genus = factor(Genus, levels = c("Other", levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) %>% 
                  ggplot(data = ., aes(x = Sample, y = 100*Abundance, fill = Genus)) +  
                  geom_bar(stat = "identity", colour = "black") +
                  scale_fill_manual(values = c(ColorBlocksFacet, Series16), labels = c("Other", make.italic(levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) +
                  scale_x_discrete("", labels = c("Zymo", "Chelex")) +
                  theme(axis.title.x = element_blank()) + 
                  guides(fill = guide_legend(reverse = TRUE, keywidth = 1, keyheight = 1, ncol = 1, title.position = "top")) +
                  ylab("Relative abundance (%)") +
                  theme_cowplot() +
                  theme(legend.text.align = 0, legend.position = "bottom", plot.margin = unit(x = c(-1, 0, 0.5, 0), units = "cm"))
p_comp_art


# Calculate average abundances of OTUs unique to one of the two extractions
shared.controls <- shared.t.ns[c("T4", "T1")]
shared.controls <- sweep(shared.controls, 2, colSums(shared.controls), `/`)
shared.controls$RowSums <- rowSums(shared.controls > 0)
shared.controls <- shared.controls[shared.controls$RowSums == 1,] # Uniquely detected

100*mean(as.matrix(shared.controls[c("T4", "T1")]))
100*median(as.matrix(shared.controls[c("T4", "T1")]))
```

#### Effect of dilution on the occurence of noise

```{r ChelexVsZymo_DilutionMock, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
# Get samples to compare dilution series of the zymo and chelex extractions
shared.controls <- shared.t.ns[c("250", "251", "252", "253", "254", "255", "Z", "256", "257", "258", "259", "260", "261", "262")]
# Generate matrix with both abundance and taxonomy info in order to be able to select the names of the top 10 genera
df.all <- cbind.data.frame(taxonomy.np.ns, shared.t.ns[c("250", "251", "252", "253", "254", "255", "Z", "256", "257", "258", "259", "260", "261", "262")], rowSums(shared.controls))
colnames(df.all)[dim(df.all)[2]] <- "Summed"
Aggregated <- aggregate(df.all$Summed, by = list(Category = df.all[,"Genus"]), FUN = sum) # Aggregate at the genus level
Top <- Aggregated$Category[order(Aggregated$x, decreasing = TRUE)][1:8]
# All genera that do not belong to the top genera should be collapsed into 1 class called "Other"
df.all$Genus <- as.character(df.all$Genus)
df.all$Genus[!(df.all$Genus %in% Top)] <- "Other"
# Add the real mock composition to the table
Aggregated <- ddply(df.all, .(Genus), numcolwise(sum))
df.tmp <- left_join(Aggregated[c("Genus", "250", "251", "252", "253", "254", "255", "Z", "256", "257", "258", "259", "260", "261", "262")], MockComposition[c("Genus", "RelativePercentage")], by = c("Genus"))
colnames(df.tmp) <- c("Genus", "Zymo8", "Zymo7", "Zymo6", "Zymo5", "Zymo4", "Zymo3", "Zymo0", "Chelex8", "Chelex7", "Chelex6", "Chelex5", "Chelex4", "Chelex3", "Chelex0", "Theoretical")
# Phyloseq object
SubsetOTU <- otu_table(as.matrix(df.tmp[c("Zymo8", "Zymo7", "Zymo6", "Zymo5", "Zymo4", "Zymo3", "Zymo0", "Chelex8", "Chelex7", "Chelex6", "Chelex5", "Chelex4", "Chelex3", "Chelex0", "Theoretical")]), taxa_are_rows = TRUE)
SubsetTAX <- tax_table(as.matrix(df.tmp["Genus"]))
Subsetphyseqobj <- phyloseq(SubsetOTU, SubsetTAX)
Subsetphyseqobj <- Subsetphyseqobj %>%
                    tax_glom(taxrank = "Genus") %>%
                    transform_sample_counts(function(x) {x/sum(x)}) %>% # Transform to relative abundances
                    psmelt()
Subsetphyseqobj$Genus <- as.factor(Subsetphyseqobj$Genus)
p_comp_mock <- Subsetphyseqobj %>%
                  dplyr::mutate(Sample = factor(Sample, levels = c("Zymo8", "Zymo7", "Zymo6", "Zymo5", "Zymo4", "Zymo3", "Zymo0", "Chelex8", "Chelex7", "Chelex6", "Chelex5", "Chelex4", "Chelex3", "Chelex0", "Theoretical"))) %>% 
                  dplyr::mutate(Genus = factor(Genus, levels = c("Other", levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) %>% 
                  ggplot(data = ., aes(x = Sample, y = 100*Abundance, fill = Genus)) + 
                  geom_bar(stat = "identity", colour = "black") + 
                  scale_fill_manual(values = c(ColorBlocksFacet, Series16[9:16]), labels = c("Other", make.italic(levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) +
                  scale_x_discrete("", labels = c(expression(atop("Zymo", paste("10"^"8"))),expression(atop("Zymo", paste("10"^"7"))), expression(atop("Zymo", paste("10"^"6"))), expression(atop("Zymo", paste("10"^"5"))), expression(atop("Zymo", paste("10"^"4"))), expression(atop("Zymo", paste("10"^"3"))), expression(atop("Zymo", paste("Blank"))), expression(atop("Chelex", paste("10"^"8"))), expression(atop("Chelex", paste("10"^"7"))), expression(atop("Chelex", paste("10"^"6"))), expression(atop("Chelex", paste("10"^"5"))), expression(atop("Chelex", paste("10"^"4"))), expression(atop("Chelex", paste("10"^"3"))), expression(atop("Chelex", paste("Blank"))), "Theoretical")) +
                  guides(fill = guide_legend(reverse = TRUE, keywidth = 1, keyheight = 1)) +
                  ylab("Relative abundance (%)") +
                  theme_cowplot() +
                  theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), legend.text.align = 0, axis.title.x = element_blank()) 
print(p_comp_mock)
```

#### Combined plot Illumina controls for extraction biases

```{r Controls_SortingBuffer, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
# Combine plots
g <- plot_grid(p_comp_tank, p_comp_alg, p_comp_art, labels = c("B", "C", "D"), ncol = 3, nrow = 1, rel_widths = c(1, 1, 1), scale = 0.9)
g <- plot_grid(p_comp_mock, g, labels = c("A", ""), ncol = 1, nrow = 2,  rel_heights = c(1,2.5))
ggsave(file = "Figures/QC-SeqControlsExtraction.png", width = 13, height = 13, dpi = 300, units = "in", g)
```

#### Chelex

```{r Controls_SortingBuffer, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
# Get samples of the sorting buffers
shared.controls <- shared.t.ns[Metadata$Identifier[Metadata$SampleIdentifierFCM  == "Chelex"]]
# Generate matrix with both abundance and taxonomy info in order to be able to select the names of the top 10 genera
df.all <- cbind.data.frame(taxonomy.np.ns, shared.t.ns[Metadata$Identifier[Metadata$SampleIdentifierFCM  == "Chelex"]], rowSums(shared.controls))
colnames(df.all)[dim(df.all)[2]] <- "Summed"
Aggregated <- aggregate(df.all$Summed, by = list(Category = df.all[,"Genus"]), FUN = sum) # Aggregate at the genus level
Top <- Aggregated$Category[order(Aggregated$x, decreasing = TRUE)][1:16]
# All genera that do not belong to the top genera should be collapsed into 1 class called "Other"
df.all$Genus <- as.character(df.all$Genus)
df.all$Genus[!(df.all$Genus %in% Top)] <- "Other"
# Subset to top instances
SubsetOTU       <- otu_table(as.matrix(shared.controls), taxa_are_rows = TRUE)
SubsetTAX       <- tax_table(as.matrix(df.all[colnames(taxonomy.np.ns)]))
Subsetphyseqobj <- phyloseq(SubsetOTU, SubsetTAX)
# Plot
Subsetphyseqobj <- Subsetphyseqobj %>%
                    transform_sample_counts(function(x) {x/sum(x)}) %>% # Transform to relative abundances
                    psmelt()
Subsetphyseqobj$Genus <- as.factor(Subsetphyseqobj$Genus)
p_chelex <- Subsetphyseqobj %>%
                  # dplyr::mutate(Sample = factor(Sample, levels = c("148", "167", "178", "198", "202", "217", "223", "230", "239"))) %>% 
                  dplyr::mutate(Genus = factor(Genus, levels = c("Other", levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) %>% 
                  ggplot(data = ., aes(x = Sample, y = 100*Abundance, fill = Genus)) + 
                  geom_bar(stat = "identity", colour = "black") +
                  scale_fill_manual(values = c(ColorBlocksFacet, Series16), labels = c("Other", make.italic(levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) +
                  scale_x_discrete(labels = c("1", "2", "3")) + 
                  theme(axis.title.x = element_blank()) + 
                  guides(fill = guide_legend(reverse = TRUE, keywidth = 1, keyheight = 1)) +
                  ylab("Relative abundance (%)") +
                  xlab("") +
                  theme_cowplot() +
                  theme(legend.text.align = 0)
print(p_chelex)
```

#### Sorting buffer

```{r Controls_SortingBuffer, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
# Get samples of the sorting buffers
shared.controls <- shared.t.ns[c("148", "167", "178", "198", "202", "217", "223", "230", "239")]
# Generate matrix with both abundance and taxonomy info in order to be able to select the names of the top 10 genera
df.all <- cbind.data.frame(taxonomy.np.ns, shared.t.ns[c("148", "167", "178", "198", "202", "217", "223", "230", "239")], rowSums(shared.controls))
colnames(df.all)[dim(df.all)[2]] <- "Summed"
Aggregated <- aggregate(df.all$Summed, by = list(Category = df.all[,"Genus"]), FUN = sum) # Aggregate at the genus level
Top <- Aggregated$Category[order(Aggregated$x, decreasing = TRUE)][1:16]
# All genera that do not belong to the top genera should be collapsed into 1 class called "Other"
df.all$Genus <- as.character(df.all$Genus)
df.all$Genus[!(df.all$Genus %in% Top)] <- "Other"
# Subset to top instances
SubsetOTU       <- otu_table(as.matrix(shared.controls), taxa_are_rows = TRUE)
SubsetTAX       <- tax_table(as.matrix(df.all[colnames(taxonomy.np.ns)]))
Subsetphyseqobj <- phyloseq(SubsetOTU, SubsetTAX)
# Plot
Subsetphyseqobj <- Subsetphyseqobj %>%
                    transform_sample_counts(function(x) {x/sum(x)}) %>% # Transform to relative abundances
                    psmelt()
Subsetphyseqobj$Genus <- as.factor(Subsetphyseqobj$Genus)
p_sortingbuffer <- Subsetphyseqobj %>%
                  dplyr::mutate(Sample = factor(Sample, levels = c("148", "167", "178", "198", "202", "217", "223", "230", "239"))) %>% 
                  dplyr::mutate(Genus = factor(Genus, levels = c("Other", levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) %>% 
                  ggplot(data = ., aes(x = Sample, y = 100*Abundance, fill = Genus)) + 
                  geom_bar(stat = "identity", colour = "black") +
                  scale_fill_manual(values = c(ColorBlocksFacet, Series16), labels = c("Other", make.italic(levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) +
                  scale_x_discrete(labels = c("1", "2", "3", "4", "5", "6", "7", "8", "9")) + 
                  guides(fill = guide_legend(reverse = TRUE, keywidth = 1, keyheight = 1)) +
                  ylab("Relative abundance (%)") +
                  theme_cowplot() +
                  theme(legend.text.align = 0, axis.title.x = element_blank())
print(p_sortingbuffer)
```

#### Combined plot Illumina controls for sorting

```{r Controls_SortingBuffer, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
#
Metadata$ExtraColumn <- Metadata$SampleIdentifierFCM
Metadata$ExtraColumn[!Metadata$ExtraColumn %in% c("Chelex", "Sheath", "TestSample")] <- "Samples"
Metadata$Population[is.na(Metadata$Population)] <- "all"

tt <- Metadata %>%
                  dplyr::mutate(ExtraColumn = factor(ExtraColumn, levels = c("Samples", "Sheath", "Chelex"))) %>%
                  dplyr::filter(ExtraColumn %in% c("Chelex", "Sheath", "Samples")) %>% 
                  dplyr::filter(Population != c("6"))

p_readssorting <- Metadata %>%
                  dplyr::mutate(ExtraColumn = factor(ExtraColumn, levels = c("Samples", "Sheath", "Chelex"))) %>%
                  dplyr::filter(ExtraColumn %in% c("Chelex", "Sheath", "Samples")) %>% 
                  dplyr::filter(Population != c("6")) %>% 
                  ggplot(data = ., aes(x = ExtraColumn, y = Numberofreads)) +
                  geom_boxplot(fill = ColorBlocksFacet) +
                  theme(axis.title.x = element_blank()) +
                  guides(fill = guide_legend(reverse = TRUE, keywidth = 1, keyheight = 1)) +
                  ylab("Number of reads") +
                  xlab("") +
                  theme_cowplot() +
                  theme(legend.text.align = 0, panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
print(p_readssorting)

# Combine plots
g <- plot_grid(p_readssorting, p_chelex, labels = c("A", "B"), ncol = 2, nrow = 1, rel_widths = c(1,2))
g <- plot_grid(g, p_sortingbuffer, labels = c("", "C"), ncol = 1, nrow = 2)
ggsave(file = "Figures/QC-SeqControlsSorting.png", width = 11, height = 9, dpi = 300, units = "in", g)
```

### Rearing water communities and sorting samples

#### Rearing water composition

```{r CommunitiesTanks_RelAbundanceOnlyNotCrashed, echo = TRUE, dpi = 800, out.width = "90%", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold", eval = TRUE}
InfoTanks <- Metadata[Metadata$WholeCommunityOrSorted == "Whole community" & Metadata$Tank %in% c("T1", "T2", "T3", "T4", "T5") & Metadata$Feeding_status == "B",]
InfoSorted <- Metadata[Metadata$Population %in% c("1", "2", "3", "4", "5"),]
InfoCombined <- rbind.data.frame(InfoTanks, InfoSorted)

# Select the samples of the water in the rearing tanks
Identifiers <- InfoCombined$Identifier
Info <- Metadata[Metadata$Identifier %in% Identifiers,]
rownames(Info) <- Info$Identifier
# Get samples from the rearing water
shared.selection <- shared.t.ns[Identifiers]
# Generate matrix with both abundance and taxonomy info in order to be able to select the names of the top 10 genera
df.all <- cbind.data.frame(taxonomy.np.ns, shared.selection, rowSums(shared.selection))
colnames(df.all)[dim(df.all)[2]] <- "Summed"
Aggregated <- aggregate(df.all$Summed, by = list(Category = df.all[,"Genus"]), FUN = sum) # Aggregate at the genus level
Top <- Aggregated$Category[order(Aggregated$x, decreasing = TRUE)][1:16]
# All genera that do not belong to the top genera should be collapsed into 1 class called "Other"
df.all$Genus <- as.character(df.all$Genus)
df.all$Genus[!(df.all$Genus %in% Top)] <- "Other"
# Subset to top instances
SubsetOTU <- otu_table(as.matrix(shared.selection), taxa_are_rows = TRUE)
SubsetTAX <- tax_table(as.matrix(df.all[colnames(taxonomy.np.ns)]))
SubsetINFO <- sample_data(Info)
rownames(SubsetINFO) <- SubsetINFO$Identifier
Subsetphyseqobj <- phyloseq(SubsetOTU, SubsetTAX, SubsetINFO)
Subsetphyseqobj <- Subsetphyseqobj %>%
                      transform_sample_counts(function(x) {x/sum(x)}) %>% # Transform to relative abundances
                      psmelt()
Subsetphyseqobj$Genus <- as.factor(Subsetphyseqobj$Genus)

# Plot composition in the tanks
p_tanks_rel <- Subsetphyseqobj %>%
                      dplyr::filter(WholeCommunityOrSorted == "Whole community") %>% 
                      dplyr::mutate(Sample = factor(Sample, levels = Info$Identifiers)) %>% 
                      dplyr::mutate(Genus = factor(Genus, levels = c("Other", levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) %>% 
                      ggplot(data = ., aes(x = Day, y = 100*Abundance, fill = Genus)) + 
                      geom_bar(stat = "identity", color = "black") + 
                      scale_fill_manual(values = c(ColorBlocksFacet, Series16), labels = c("Other", make.italic(levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"])), name = "Genus   ") +
                      facet_grid(Tank ~ .) +
                      guides(fill = guide_legend(reverse = TRUE, keywidth = 1, keyheight = 1, nrow = 5)) +
                      ylab("Relative abundance (%)") +
                      xlab("Time (d)") +
                      theme_cowplot() +
                      theme(legend.text.align = 0, legend.position = "bottom")
print(p_tanks_rel)

# Plot composition in the sorted samples
Subsetphyseqobj$Genus <- as.factor(Subsetphyseqobj$Genus)
Subsetphyseqobj$Day <- as.factor(Subsetphyseqobj$Day)
Subsetphyseqobj$Population <- paste("Pop", Subsetphyseqobj$Population)
Subsetphyseqobj$Population[Subsetphyseqobj$Population == "Pop 3"] <- "3"
Subsetphyseqobj$Population[Subsetphyseqobj$Population == "Pop 2"] <- "SC 2"
Subsetphyseqobj$Population[Subsetphyseqobj$Population == "Pop 1"] <- "SC 1"
Subsetphyseqobj$Population[Subsetphyseqobj$Population == "Pop 4"] <- "SC 4"
Subsetphyseqobj$Population[Subsetphyseqobj$Population == "Pop 5"] <- "SC 5"

p_sortedpopulation <- Subsetphyseqobj %>%
                      dplyr::filter(WholeCommunityOrSorted == "Sorted") %>% 
                      dplyr::mutate(Genus = factor(Genus, levels = c("Other", levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) %>%
                      dplyr::mutate(Population = factor(Population, levels = c("SC 1", "SC 2", "3", "SC 4", "SC 5"))) %>%
                      ggplot(data = ., aes(x = Day, y = 100*Abundance, fill = Genus)) + 
                      geom_bar(stat = "identity", colour = "black") + 
                      scale_fill_manual(values = c(ColorBlocksFacet, Series16), labels = c("Other", make.italic(levels(Subsetphyseqobj$Genus)[!levels(Subsetphyseqobj$Genus) == "Other"]))) +
                      facet_nested(. ~ Population + Tank, scales = "free_x", space = "free") +
                      labs(x = "", y = "Relative abundance (%)") +
                      guides(fill = guide_legend(reverse = TRUE, keywidth = 1, keyheight = 1)) +
                      theme_cowplot() +
                      theme(legend.text.align = 0, legend.position = "none")
print(p_sortedpopulation)

# Combined plot
g1 <- plot_grid(p_sortedpopulation, p_tanks_rel, labels = c("A", "B"), rel_heights = c(1.7, 5),ncol = 1, nrow = 2, scale = 1)
ggsave(file = "Figures/AQUACULTURE-Rearingwater-WholeAndSorted.png", width = 12, height = 15, dpi = 500, units = "in", g1)

# Remove all variables that will not be used further
remove(Identifiers, shared.selection, df.all, SubsetINFO, SubsetOTU, SubsetTAX, Top, Aggregated, InfoTanks)
```

#### Alpha diversity metrics sorted populations

```{r AlphaDiversityMetrics, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
# Phyloseq
SubsetOTU       <- otu_table(as.matrix(shared.t.ns), taxa_are_rows = TRUE)
SubsetTAX       <- tax_table(as.matrix(taxonomy.np.ns))
rownames(Metadata) <- Metadata$Identifier
SubsetINFO      <- sample_data(Metadata)
Subsetphyseqobj <- phyloseq(SubsetOTU, SubsetTAX, SubsetINFO)

# Alpha diversity metrics
AlphaEstimates <- estimate_richness(Subsetphyseqobj, split = TRUE, measures = NULL)
AlphaEstimates$ID <- gsub("X", "", rownames(AlphaEstimates))
AlphaEstimates <- left_join(AlphaEstimates, Metadata, by = c("ID" = "Identifier"))

# Subset to sorted samples
AlphaEstimatesSorted <- AlphaEstimates[AlphaEstimates$WholeCommunityOrSorted == "Sorted",]
AlphaEstimatesSorted <- AlphaEstimatesSorted[AlphaEstimatesSorted$Population %in% c("1", "2", "3", "4", "5", "5b", "Cells"),]
AlphaEstimatesSorted$Population[AlphaEstimatesSorted$Population == "1"] <- "SC 1"
AlphaEstimatesSorted$Population[AlphaEstimatesSorted$Population == "2"] <- "SC 2"
AlphaEstimatesSorted$Population[AlphaEstimatesSorted$Population == "3"] <- "SC 3"
AlphaEstimatesSorted$Population[AlphaEstimatesSorted$Population == "4"] <- "SC 4"
AlphaEstimatesSorted$Population[AlphaEstimatesSorted$Population == "5"] <- "SC 5"
AlphaEstimatesSorted$Population[AlphaEstimatesSorted$Population == "5b"] <- "SC 5"
AlphaEstimatesSorted$Population[AlphaEstimatesSorted$Population == "Cells"] <- "Community"


# Plot
PopulationColors <- c(ColorBlocksFacet, "#82487d", "#edd958", "#3c4175", "#60be8f", "#6c72dd")
p_alpha_sorted <- AlphaEstimatesSorted %>%
                  ggplot(data = ., aes(x = Population, y = Observed, fill = Population)) + 
                  geom_boxplot() +
                  scale_fill_manual(values = PopulationColors) + 
                  guides(fill = guide_legend(reverse = TRUE, keywidth = 1, keyheight = 1)) +
                  ylab("Observed richness") +
                  xlab("") +
                  theme_cowplot() +
                  theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), legend.position = "none")

# Statistical test
Comparisons <- list(c("Community", "SC 1"), 
                    c("Community", "SC 2"),
                    c("Community", "SC 4"),
                    c("Community", "SC 5"))
p_alpha_sorted <- p_alpha_sorted + stat_compare_means(comparisons = Comparisons, 
                                    tip.length = 0.01,
                                    label.y = c(500, 450, 400, 350),
                                    method = "wilcox.test", 
                                    label = "p.format",
                                    method.args = list(alternative = "greater"),
                                    size = 3)
p_alpha_sorted
```

#### Beta diversity

```{r AlphaDiversityMetrics, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
# Calculate Bray-Curtis dissimilarities and run a PCoA on all the samples
Bray <- vegan::vegdist(t(shared.t.ns)[AlphaEstimatesSorted$ID,], method = "bray", binary = FALSE)
PCoARes <- stats::cmdscale(Bray, k = 2, eig = TRUE, add = TRUE)
var <- base::format(round(vegan::eigenvals(PCoARes)/sum(vegan::eigenvals(PCoARes))*100,1), nsmall = 1)
# Add metadata for plotting
PCoARes <- data.frame(PCoARes$points)
PCoARes$Identifier <- rownames(PCoARes)
PCoARes <- dplyr::left_join(PCoARes, AlphaEstimatesSorted, by = c("Identifier" = "ID"))

# Plot the ordination
p_beta_all <- PCoARes %>%
                 ggplot(data = ., aes(x = X1, y = X2, fill = Population)) +
                 geom_point(alpha = 1, size = 3 , shape = 21, color = "black") +
                 scale_fill_manual(values = PopulationColors) +
                 guides(fill = guide_legend(override.aes = list(shape = 21, size = 4))) +
                 # facet_grid(. ~ Day) + 
                 labs(x = paste0("PCoA axis 1 (",var[1], "%)"), y = paste0("PCoA axis 2 (",var[2], "%)")) +
                 coord_fixed() +
                 theme_cowplot() +
                 theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
print(p_beta_all)
# png("Figures/DYNAMICS-All-Beta.png", width = 7, height = 5, res = 500, units = "in")
# print(p_beta_all)
# dev.off()

# PERMANOVA
  # Selection
  MetadataSelection <- Metadata[Metadata$Population %in% c("Cells", "1"),]
  # Checking the homogeneity condition
  dist <- vegdist(t(shared.t.ns[MetadataSelection$Identifier]))
  anova(betadisper(dist, MetadataSelection$Population))
  # Run permanova
  permanova <- vegan::adonis(t(shared.t.ns[MetadataSelection$Identifier]) ~ MetadataSelection$Population, permutations = 999, method = "bray")
  permanova

  # Selection
  MetadataSelection <- Metadata[Metadata$Population %in% c("Cells", "2"),]
  # Checking the homogeneity condition
  dist <- vegdist(t(shared.t.ns[MetadataSelection$Identifier]))
  anova(betadisper(dist, MetadataSelection$Population))
  # Run permanova
  permanova <- vegan::adonis(t(shared.t.ns[MetadataSelection$Identifier]) ~ MetadataSelection$Population, permutations = 999, method = "bray")
  permanova

  # Selection
  MetadataSelection <- Metadata[Metadata$Population %in% c("Cells", "4"),]
  # Checking the homogeneity condition
  dist <- vegdist(t(shared.t.ns[MetadataSelection$Identifier]))
  anova(betadisper(dist, MetadataSelection$Population))
  # Run permanova
  permanova <- vegan::adonis(t(shared.t.ns[MetadataSelection$Identifier]) ~ MetadataSelection$Population, permutations = 999, method = "bray")
  permanova

  # Selection
  MetadataSelection <- Metadata[Metadata$Population %in% c("Cells", "5"),]
  # Checking the homogeneity condition
  dist <- vegdist(t(shared.t.ns[MetadataSelection$Identifier]))
  anova(betadisper(dist, MetadataSelection$Population))

  # Selection
  MetadataSelection <- Metadata[Metadata$Population %in% c("1", "2"),]
  # Checking the homogeneity condition
  dist <- vegdist(t(shared.t.ns[MetadataSelection$Identifier]))
  anova(betadisper(dist, MetadataSelection$Population))
  # Run permanova
  permanova <- vegan::adonis(t(shared.t.ns[MetadataSelection$Identifier]) ~ MetadataSelection$Population, permutations = 999, method = "bray")
  permanova

  # Selection
  MetadataSelection <- Metadata[Metadata$Population %in% c("1", "4"),]
  # Checking the homogeneity condition
  dist <- vegdist(t(shared.t.ns[MetadataSelection$Identifier]))
  anova(betadisper(dist, MetadataSelection$Population))
  # Run permanova
  permanova <- vegan::adonis(t(shared.t.ns[MetadataSelection$Identifier]) ~ MetadataSelection$Population, permutations = 999, method = "bray")
  permanova  
  
  # Selection
  MetadataSelection <- Metadata[Metadata$Population %in% c("1", "5"),]
  # Checking the homogeneity condition
  dist <- vegdist(t(shared.t.ns[MetadataSelection$Identifier]))
  anova(betadisper(dist, MetadataSelection$Population))

  # Selection
  MetadataSelection <- Metadata[Metadata$Population %in% c("2", "4"),]
  # Checking the homogeneity condition
  dist <- vegdist(t(shared.t.ns[MetadataSelection$Identifier]))
  anova(betadisper(dist, MetadataSelection$Population))
  # Run permanova
  permanova <- vegan::adonis(t(shared.t.ns[MetadataSelection$Identifier]) ~ MetadataSelection$Population, permutations = 999, method = "bray")
  permanova    
  
  # Selection
  MetadataSelection <- Metadata[Metadata$Population %in% c("2", "5"),]
  # Checking the homogeneity condition
  dist <- vegdist(t(shared.t.ns[MetadataSelection$Identifier]))
  anova(betadisper(dist, MetadataSelection$Population))
  # Run permanova
  permanova <- vegan::adonis(t(shared.t.ns[MetadataSelection$Identifier]) ~ MetadataSelection$Population, permutations = 999, method = "bray")
  permanova   
  
  # Selection
  MetadataSelection <- Metadata[Metadata$Population %in% c("4", "5"),]
  # Checking the homogeneity condition
  dist <- vegdist(t(shared.t.ns[MetadataSelection$Identifier]))
  anova(betadisper(dist, MetadataSelection$Population))
  # Run permanova
  permanova <- vegan::adonis(t(shared.t.ns[MetadataSelection$Identifier]) ~ MetadataSelection$Population, permutations = 999, method = "bray")
  permanova   
```

#### Upset graph populations

```{r UpsetRGraphPopulations, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
# Get identifiers of the sorted samples (without chelex and sheath samples)
Identifiers <- Metadata$Identifier[Metadata$WholeCommunityOrSorted == "Sorted" & !(Metadata$Tank %in% c("Chelex", "Sheath")) & Metadata$Population %in% c("1", "2", "3", "4", "5")] # NOT 6 because no amplicon!
metadatasorted <- Metadata[Metadata$Identifier %in% Identifiers,]
otutablesorted <- shared.t.ns[Identifiers]
# Combine all the samples per population and convert it in absence(0)/presence(1) data
PopulationCompositions <- data.frame(matrix(ncol = 0, nrow = dim(shared.t.ns)[1]))
for (i in 1:length(unique(metadatasorted$Population))){
  Selected <- unique(metadatasorted$Population)[i]
  IdentifiersSelected <- metadatasorted$Identifier[metadatasorted$Population == Selected]
  otutableSelected <- otutablesorted[IdentifiersSelected]
  otutableSelected$Sum <- rowSums(otutableSelected)
  # otutableSelected$Sum[otutableSelected$Sum < 1] <- 0 # Every OTU with less than 10 reads can be ignored (find a better criterium later)
  SumSelectedPopulation <- otutableSelected$Sum > 0
  PopulationCompositions <- cbind.data.frame(PopulationCompositions, SumSelectedPopulation)
  colnames(PopulationCompositions)[i] <- paste(Selected)
}
NumberOfOTUs <- dim(PopulationCompositions)[1]

# Make an input for the upset function: list per population
listpops <- list(pop1 = paste("OTU", 1:NumberOfOTUs, sep = "")[PopulationCompositions$`1`],
                 pop2 = paste("OTU", 1:NumberOfOTUs, sep = "")[PopulationCompositions$`2`],
                 pop3 = paste("OTU", 1:NumberOfOTUs, sep = "")[PopulationCompositions$`3`],
                 pop4 = paste("OTU", 1:NumberOfOTUs, sep = "")[PopulationCompositions$`4`],
                 pop5 = paste("OTU", 1:NumberOfOTUs, sep = "")[PopulationCompositions$`5`])

Intersections <- make_comb_mat(listpops, mode = "intersect")

expressionInput <- c( Pop1 = 532,
                      Pop2 = 682,
                      Pop3 = 93,
                      Pop4 = 759,
                      Pop5 = 79,
                      `Pop1&Pop2` = 321,
                      `Pop1&Pop3` = 65,
                      `Pop1&Pop4` = 274,
                      `Pop1&Pop5` = 43,
                      `Pop2&Pop3` = 69,
                      `Pop2&Pop4` = 352,
                      `Pop2&Pop5` = 52,
                      `Pop3&Pop4` = 66,
                      `Pop3&Pop5` = 13,
                      `Pop4&Pop5` = 53)

# expressionInput <- c(Pop1 = 186, 
#                      Pop2 = 271, 
#                      Pop3 = 21, 
#                      Pop4 = 327, 
#                      Pop5 = 32, 
#                      `Pop1&Pop2` = 147, 
#                      `Pop1&Pop3` = 17, 
#                      `Pop1&Pop4` = 120, 
#                      `Pop1&Pop5` = 15, 
#                      `Pop2&Pop3` = 19, 
#                      `Pop2&Pop4` = 182, 
#                      `Pop2&Pop5` = 20,
#                      `Pop3&Pop4` = 18, 
#                      `Pop3&Pop5` = 5,
#                      `Pop4&Pop5` = 24)

UpSetData <- fromExpression(expressionInput)
colnames(UpSetData) <- c("SC 1", "SC 2", "SC 3", "SC 4", "SC 5")
PopulationColors <- c("#82487d", "#edd958", "#3c4175", "#60be8f", "#6c72dd")
metadataUpSetData <- as.data.frame(cbind(names(UpSetData), c("x1", "x2", "x3", "x4", "x5") ))
colnames(metadataUpSetData) <- c("sets", "dummy")
p_UpSet <- upset(UpSetData,
                 group.by = "sets",
                 sets = c("SC 1", "SC 2", "SC 3", "SC 4", "SC 5"), 
                 mainbar.y.label = "Number of OTU's",
                 sets.x.label = "Number of OTU's", 
                 empty.intersections = TRUE,
                 text.scale = c(1.5, 1.5, 1.5, 1.5, 1.5, 1.2),
                 cutoff = 4,
                 main.bar.color = c("#60be8f", "black", "black", "black", "#edd958", "black", "black", "black", "#82487d", "black", "black", "black", "#6c72dd", "black", "black", "black", "#3c4175", "black", "black","black"),
                 matrix.color = "black", 
                 set.metadata = list(data = metadataUpSetData, plots = list(list(type = "matrix_rows", column = "dummy", colors = c(x1 = "#82487d", x2 = "#edd958", x3 = "#3c4175", x4 = "#60be8f", x5 = "#6c72dd"), alpha = 0.3)
                 )))
p_UpSet
```

```{r SortedAbundances, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, results = 'hide', fig.show = "hold"}
FractionsSorted <- read.csv(file = "Results/FractionsSorted.csv")
FractionsSorted$population <- as.factor(FractionsSorted$population)
p_fractions_violin <- FractionsSorted %>%
                      ggplot(data = ., aes(x = population, y = 100*fraction, fill = population)) +
                      geom_boxplot() +
                      scale_fill_manual(values = PopulationColors) +
                      theme_cowplot() +
                      theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1)) +
                      guides(fill = FALSE) +
                      scale_x_discrete(labels = c("SC 1","SC 2","SC 3","SC 4","SC 5")) +
                      labs(y = "Abundance in the community (%)", x = "")
print(p_fractions_violin)
```

#### Assembled plot

```{r FPcorSeq, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Reformat the upset graph to something that can be combined in a plotgrid
p1 <- ggdraw(p_UpSet$Main_bar) + theme(plot.margin = unit(c(0, 0, 0.1, 0.1), "cm")) 
p2 <- ggdraw(p_UpSet$Sizes) + theme(plot.margin = unit(c(0, 1, 0, 0), "cm"))
p3 <- ggdraw(p_UpSet$Matrix) + theme(plot.margin = unit(c(0, 0, 0, -0.4), "cm"))

# expressionInput <- c(Pop1 = 186, 
#                      `Pop1&Pop2` = 147, 
#                      `Pop1&Pop3` = 17, 
#                      `Pop1&Pop4` = 120, 
#                      `Pop1&Pop5` = 15,
#                      Pop2 = 271, 
#                      `Pop2&Pop1` = 147, 
#                      `Pop2&Pop3` = 19, 
#                      `Pop2&Pop4` = 182, 
#                      `Pop2&Pop5` = 20,
#                      Pop3 = 21, 
#                      `Pop3&Pop1` = 17, 
#                      `Pop3&Pop2` = 19, 
#                      `Pop3&Pop4` = 18, 
#                      `Pop3&Pop5` = 5,
#                      Pop4 = 327, 
#                      `Pop4&Pop1` = 120, 
#                      `Pop4&Pop2` = 182, 
#                      `Pop4&Pop3` = 18, 
#                      `Pop4&Pop5` = 24,
#                      Pop5 = 32, 
#                      `Pop5&Pop1` = 15,
#                      `Pop5&Pop2` = 20,
#                      `Pop5&Pop3` = 5,
#                      `Pop5&Pop4` = 24)

expressionInput <- c(Pop1 = 532, 
                     `Pop1&Pop2` = 321, 
                     `Pop1&Pop3` = 65, 
                     `Pop1&Pop4` = 274, 
                     `Pop1&Pop5` = 43,
                     Pop2 = 682, 
                     `Pop2&Pop1` = 321, 
                     `Pop2&Pop3` = 69, 
                     `Pop2&Pop4` = 352, 
                     `Pop2&Pop5` = 52,
                     Pop3 = 93, 
                     `Pop3&Pop1` = 65, 
                     `Pop3&Pop2` = 69, 
                     `Pop3&Pop4` = 66, 
                     `Pop3&Pop5` = 13,
                     Pop4 = 759, 
                     `Pop4&Pop1` = 274, 
                     `Pop4&Pop2` = 352, 
                     `Pop4&Pop3` = 66, 
                     `Pop4&Pop5` = 53,
                     Pop5 = 79, 
                     `Pop5&Pop1` = 43,
                     `Pop5&Pop2` = 52,
                     `Pop5&Pop3` = 13,
                     `Pop5&Pop4` = 53)

# expressionInput <- c( Pop1 = 532,
#                       Pop2 = 682,
#                       Pop3 = 93,
#                       Pop4 = 759,
#                       Pop5 = 79,
#                       `Pop1&Pop2` = 321,
#                       `Pop1&Pop3` = 65,
                      # `Pop1&Pop4` = 274,
                      # `Pop1&Pop5` = 43,
                      # `Pop2&Pop3` = 69,
                      # `Pop2&Pop4` = 352,
                      # # `Pop2&Pop5` = 52,
                      # `Pop3&Pop4` = 66,
                      # `Pop3&Pop5` = 13,
                      # `Pop4&Pop5` = 53)

df <- cbind.data.frame(expressionInput, names(expressionInput))
colnames(df) <- c("Nr", "Xaxis")
p1b <- df %>%
         # dplyr::filter(Xaxis %in% c("Pop4", "Pop4&Pop2", "Pop4&Pop1", "Pop4&Pop5", "Pop2", "Pop2&Pop4", "Pop2&Pop1", "Pop2&Pop5", "Pop1", "Pop1&Pop2", "Pop1&Pop4", "Pop1&Pop3", "Pop5", "Pop5&Pop4", "Pop5&Pop2", "Pop5&Pop1", "Pop3", "Pop3&Pop2", "Pop3&Pop4", "Pop3&Pop1")) %>%
         # dplyr::mutate(Xaxis = factor(Xaxis, levels = c("Pop4", "Pop4&Pop2", "Pop4&Pop1", "Pop4&Pop5", "Pop2", "Pop2&Pop4", "Pop2&Pop1", "Pop2&Pop5", "Pop1", "Pop1&Pop2", "Pop1&Pop4", "Pop1&Pop3", "Pop5", "Pop5&Pop4", "Pop5&Pop2", "Pop5&Pop1", "Pop3", "Pop3&Pop2", "Pop3&Pop4", "Pop3&Pop1"))) %>%
           dplyr::filter(Xaxis %in% c("Pop4", "Pop4&Pop2", "Pop4&Pop1", "Pop4&Pop3", "Pop2", "Pop2&Pop4", "Pop2&Pop1", "Pop2&Pop3", "Pop1", "Pop1&Pop2", "Pop1&Pop4", "Pop1&Pop3", "Pop3", "Pop3&Pop2", "Pop3&Pop4", "Pop3&Pop1", "Pop5", "Pop5&Pop4", "Pop5&Pop2", "Pop5&Pop1")) %>%
         dplyr::mutate(Xaxis = factor(Xaxis, levels = c("Pop4", "Pop4&Pop2", "Pop4&Pop1", "Pop4&Pop3", "Pop2", "Pop2&Pop4", "Pop2&Pop1", "Pop2&Pop3", "Pop1", "Pop1&Pop2", "Pop1&Pop4", "Pop1&Pop3", "Pop3", "Pop3&Pop2", "Pop3&Pop4", "Pop3&Pop1", "Pop5", "Pop5&Pop4", "Pop5&Pop2", "Pop5&Pop1"))) %>%
         ggplot(data = ., aes(x = Xaxis, y = Nr, fill = Xaxis)) +
         geom_bar(stat = "identity", colour = "black", width = .6) +
         # scale_fill_manual(values = c("#60be8f", ColorBlocksFacet, ColorBlocksFacet, ColorBlocksFacet, "#edd958", ColorBlocksFacet, ColorBlocksFacet, ColorBlocksFacet, "#82487d", ColorBlocksFacet, ColorBlocksFacet, ColorBlocksFacet, "#6c72dd", ColorBlocksFacet, ColorBlocksFacet, ColorBlocksFacet, "#3c4175", ColorBlocksFacet, ColorBlocksFacet, ColorBlocksFacet)) +
          scale_fill_manual(values = c("#60be8f", ColorBlocksFacet, ColorBlocksFacet, ColorBlocksFacet, "#edd958", ColorBlocksFacet, ColorBlocksFacet, ColorBlocksFacet, "#82487d", ColorBlocksFacet, ColorBlocksFacet, ColorBlocksFacet, "#3c4175", ColorBlocksFacet, ColorBlocksFacet, ColorBlocksFacet, "#6c72dd", ColorBlocksFacet, ColorBlocksFacet, ColorBlocksFacet)) +
         labs(x = "", y = "Number of OTUs") +
         geom_text(aes(y = Nr, label = format(round(as.numeric(Nr), 1), big.mark = ",")), vjust = -0.25, color = "black", size = 3, position = position_dodge(width = 1)) +
         scale_x_discrete(expand = expansion(mult = c(0.05, 0.055))) +
         scale_y_continuous(expand = expansion(mult = c(0, 0.05))) +
         # guides(fill = "") +
         theme_cowplot() +
         theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "none", axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())
print(p1b)

p_UpSetCowplotRight <- cowplot::plot_grid(p1b, p3, 
                                      nrow = 2,
                                      rel_heights = c(3,1.5))
p_UpSetCowplotRight
```

```{r UploadMetadata, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Make a summary plot for the sorted populations
g1 <- plot_grid(p_fractions_violin, p_alpha_sorted, labels = c("A", "B"), rel_widths = c(1, 1.2), ncol = 2, nrow = 1, scale = 0.9)
g1
g2 <- plot_grid(g1, p_UpSetCowplotRight, labels = c("", "C"), ncol = 1, rel_heights = c(0.85, 1), nrow = 2, scale = 1)
g2
ggsave(file = "Figures/AQUACULTURE-SummaryTaxonomySorting.png", width = 10, height = 8, dpi = 500, units = "in", g2)

# Remove all variables that are no longer needed
remove(AlphaEstimates, AlphaEstimatesSorted, cl, Comparisons, csum, df, df.tmp, firsttrimsum, FractionsSorted, g, g1, g2, InfoCombined, Info, InfoSorted, listpops, Metadata, MetadataSelection, metadatasorted, metadataUpSetData, MockComposition, otutableSelected, otutablesorted, p_alpha_sorted, p_beta_all, p_chelex , p_comp_alg, p_comp_art, p_comp_mock, p_comp_tank, p_fractions_violin, p_readssorting, p_sortedpopulation, p_sortingbuffer, p_tanks_rel, p_UpSet, p_UpSetCowplotRight, p1, p1b, p2, p3, PCoARes, permanova, PopulationCompositions, postalnsum, postuchimeclasssum, preclussum, shared.controls, shared.t.ns, shared.t.ns.old, SubsetINFO, Subsetphyseqobj, taxonomy.np.ns, tmp.otu.ns, tt, uniquesum, UpSetData, Bray, dist, expressionInput, i, Identifier, Identifiers, IdentifiersSelected, NumberOfOTUs, Selected, SubsetOTU, SubsetTAX, SumSelectedPopulation, var)
```

## Predictive modelling

### Upload and process Illumina data

```{r UploadMetadata, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Upload metadata
Metadata <- read.xlsx(xlsxFile = "Metadata/MetadataSequencing.xlsx")
ReadQuality <- read.xlsx(xlsxFile = "Metadata/QCInfoBaseClear.xlsx")
# Add the readquality info to the metadata
Metadata <- left_join(Metadata, ReadQuality, by = c("Identifier" = "Samplename"))
# Split the sample-identifiers
Metadata <- cbind(Metadata, do.call(rbind, strsplit(as.character(Metadata$SampleIdentifierFCM), split = ".", fixed = TRUE)))
colnames(Metadata)[12:15] <- c("Tank", "Day", "Timepoint", "Feeding_status")
Metadata$Day <- as.numeric(gsub("D", "", Metadata$Day))
# Remove variables that are no longer needed
remove(ReadQuality)
```

```{r LoadInfoFromSummaries, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", fig.asp = 0.5, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
## Upload the classification results
# file direcrory
fldr <- "Data/Aquaculture/Illumina/"
# Load info from the summary-files
filelist <- list.files(fldr)
crfn <- grep(".*contigs.report", filelist, value = TRUE)
fn <- sub(".contigs.report", "", crfn)
ini <- data.table::fread(paste(fldr, "/", crfn, sep = ""), header = TRUE)

# Remove all variables that will not be used further
remove(filelist, crfn, ini)
```

```{r LoadMothurResults, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = TRUE}
# Load taxonomy from Mothur output files
otutaxonomy <- data.table::fread(paste(fldr, "/", fn, ".trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.opti_mcc.0.03.cons.taxonomy", sep = ""), header = TRUE)
taxonomy.spl <- preformattax(otutaxonomy)
taxonomy.np <- taxonomy.spl %>% dplyr::select(-dplyr::contains("Prob"))

# Load the shared file for getting the OTU abundances per sample
shared <- data.table::fread(paste(fldr, "/", fn, ".trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.opti_mcc.shared", sep = ""), header = TRUE)
shared <- as.data.frame(shared)
desgroups <- shared$Group # the samplenames
shared.x <- shared[, 4:ncol(shared)] # only the OTU info
rownames(shared.x) <- desgroups
shared.t <- as.data.frame(t(shared.x))

# Removal of singletons from the OTU table and the taxonomy results (singletons = OTU's that only occur once over the entire dataset)
shared.t.ns <- shared.t[which(rowSums(shared.t)!=1),]
taxonomy.np.ns <- taxonomy.np[which(rownames(taxonomy.np) %in% rownames(shared.t.ns)),]

# Save the OTU table (with and without singletons) in an excel sheet
tmp.otu <- cbind(rownames(shared.t), shared.t)
colnames(tmp.otu) <- c("OTU", colnames(shared.t))
tmp.otu.ns <- cbind(rownames(shared.t.ns), shared.t.ns)
colnames(tmp.otu.ns) <- c("OTU", colnames(shared.t.ns))

# Remove all variables that will not be used further
remove(fldr, fn, otutaxonomy, taxonomy.spl, taxonomy.np, shared, desgroups, shared.x, shared.t, tmp.otu, tmp.otu.ns)
```

```{r Scaling, echo = TRUE, dpi = 800, out.width = "70%", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = TRUE, results = "hide"}
## Scaling
# Make phyloseq object from the data without all the control samples (don't take into account their reads for scaling)
IdentifierControlSamples <- c("250", "251", "252", "253", "254", "255", "Z")
otumat.ns <- as.matrix(shared.t.ns[Metadata$Identifier[!Metadata$Identifier %in% IdentifierControlSamples]])
taxmat.ns <- as.matrix(taxonomy.np.ns)
info <- Metadata[Metadata$Identifier %in% colnames(otumat.ns),]
OTU <- otu_table(otumat.ns, taxa_are_rows = TRUE)
TAX <- tax_table(taxmat.ns)
INFO <- sample_data(info)
rownames(INFO) <- INFO$Identifier
physeqobj <- phyloseq(OTU, TAX, INFO)

# Do the scaling
sample_sums(physeqobj)
physeqobj <- scale_reads(physeqobj, n = 20000)
sample_sums(physeqobj)

# Save the scaled data as the otu-table
shared.t.ns.old <- shared.t.ns # Keep this to check later
shared.t.ns <- as.data.frame(otu_table(physeqobj))
taxonomy.np.ns <- as.data.frame(physeqobj@tax_table@.Data)
```

```{r LoadMothurResults, echo = TRUE, dpi = 800, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
## Upload cell densities to calculate absolute taxon abundances
# Load the Accuri C6+ data
Counts <- read.csv("Metadata/CellCounts.csv")
Counts <- Counts[c("Sample", "BacterialDensity")]
Counts$Sample <- gsub("Artemia", "Art", Counts$Sample)
# Sample names are not perfectly matching: "Artemia" --> "Art"
Metadata <- left_join(Metadata, Counts, by = c("SampleIdentifierFCM" = "Sample"))

# Remove all variables that will not be used further
remove(Counts)
```

```{r Preprocess, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
## Remove non-abundant OTUs that will not be detected by the FCM
# Get all samples for which we have FCM data (no controls)
Identifiers <- Metadata$Identifier[Metadata$WholeCommunityOrSorted %in% c("Whole community", "Sorted")]
Info <- Metadata[Metadata$Identifier %in% Identifiers,]
rownames(Info) <- Info$Identifier
shared.selection <- shared.t.ns[Identifiers]
# Calculate all absolute abundances
SubsetOTU <- otu_table(as.matrix(shared.selection), taxa_are_rows = TRUE)
SubsetTAX <- tax_table(as.matrix(taxonomy.np.ns))
SubsetINFO <- sample_data(Info)
Subsetphyseqobj <- phyloseq(SubsetOTU, SubsetTAX, SubsetINFO)
Subsetphyseqobj <- Subsetphyseqobj %>%
                      transform_sample_counts(function(x) {x/sum(x)}) %>%
                      psmelt()
Subsetphyseqobj$BacterialDensity[Subsetphyseqobj$WholeCommunityOrSorted == "Sorted"] <- 10^6
Subsetphyseqobj$AbsoluteAbundance <- Subsetphyseqobj$Abundance*Subsetphyseqobj$BacterialDensity

# Remove variables that are no longer needed
# remove(Info, shared.selection, SubsetOTU, SubsetTAX, SubsetINFO, SubsetData, p_AbundanceDistribution_all, p_AbundanceDistribution_NoZero)
```

```{r Preprocess, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Preprocessing: only populations with at least 10^3 in the sample will be clearly distinghuishable as a cell population (put the relative abundance column to 0 because this is the input for the model)
Subsetphyseqobj$Abundance[Subsetphyseqobj$AbsoluteAbundance < 10^3] <- 0
# Get pre-processed OTU-table to recalculate relative abundances
OTUPreprocessed <- Subsetphyseqobj[c("OTU", "Sample", "Abundance")]
OTUPreprocessed <- dcast(OTUPreprocessed, OTU ~ Sample)
# Remove OTUs that are never above the abundance threshold
OTUPreprocessed <- OTUPreprocessed[!rowSums(OTUPreprocessed[Identifiers]) == 0,]
# Recalculate the new relative abundances
OTUPreprocessed[Identifiers] <- sweep(OTUPreprocessed[Identifiers], 2, colSums(OTUPreprocessed[Identifiers]), `/`)

# Inspect OTU distributions (including or excluding sorting samples)
OTUPreprocessedMelted <- melt(OTUPreprocessed, id.vars = "OTU")
p_OTUdistribution1 <- OTUPreprocessedMelted %>%
                        dplyr::filter(OTU %in% unique(OTUPreprocessedMelted$OTU)[1:50]) %>%
                        # dplyr::filter(variable %in% NonSorted) %>%
                        ggplot(data = ., aes(x = OTU, y = 100*value)) +
                        geom_boxplot(fill = "#82487d") +
                        labs(y = "Relative abundance (%)", x = "") +
                        guides(fill = guide_legend(override.aes = list(shape = 21))) +
                        scale_y_continuous(limits = c(0,100)) +
                        annotate("segment", x = -Inf, xend = Inf, y = -Inf, yend = -Inf) +
                        annotate("segment", x = -Inf, xend = -Inf, y = -Inf, yend = Inf) +
                        theme_cowplot() +
                        theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 90, vjust = 0.5))
print(p_OTUdistribution1)
```

### Upload and process FCM data

```{r Preprocess_FACS, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Read metadata 
MetadataFCM <- readxl::read_excel("./Metadata/FACS-LABELS.xlsx")
MetadataFCM <- data.frame(MetadataFCM, do.call(rbind, strsplit(MetadataFCM$Sample_names, split = "_")))
# Upload the fcs-files for which we have the corresponding OTU-tables available
IdentifiersFCM <- Metadata$SampleIdentifierFCM[Metadata$Identifier %in% Identifiers]
fcsfiles <- MetadataFCM$FACS_names[MetadataFCM$X1 %in% IdentifiersFCM]
fcsfiles <- paste("./Data/Aquaculture/FCM/FACSVerse/", fcsfiles, sep = "")
flowData <- flowCore::read.flowSet(files = fcsfiles, transformation = FALSE, pattern = ".fcs", ignore.text.offset = TRUE, emptyValue = FALSE)

# Select phenotypic features of interest and transform parameters
flowData_transformed <- transform(flowData,
                                  `FSC-H` = asinh(`FSC-H`), 
                                  `SSC-H` = asinh(`SSC-H`), 
                                  `FITC-H` = asinh(`FITC-H`), 
                                  `PE-H` = asinh(`PE-H`),
                                  `PerCP-Cy5.5-H` = asinh(`PerCP-Cy5.5-H`), 
                                  `PE-Cy7-H` = asinh(`PE-Cy7-H`), 
                                  `APC-H` = asinh(`APC-H`), 
                                  `V450-H` = asinh(`V450-H`),
                                  `V500-H` = asinh(`V500-H`))
param <- c("FITC-H", "SSC-H", "FSC-H")
remove(flowData)

# Gate
sqrcut1 <- matrix(c(6.8,6.9,12.7,12.7,
                    2.8,4,11,2.8),
                  ncol = 2, 
                  nrow = 4)
colnames(sqrcut1) <- c("FITC-H","PerCP-Cy5.5-H")
polyGate1 <- polygonGate(.gate = sqrcut1, filterId = "Total Cells")

# Add the sorted samples (this object was created in the code above, where the FACS data was processed)
SortedFlowSet <- readRDS(file = "Data/Aquaculture/FCM/Sorted.rds")
flowData_transformed <- rbind2(flowData_transformed, SortedFlowSet)

# Plot the gate
xyplot(`PerCP-Cy5.5-H` ~ `FITC-H`, data = flowData_transformed[98], 
              filter = polyGate1,
              scales = list(y = list(limits = c(2,12)),
                            x = list(limits = c(6,13.2))),
              axis = axis.default,
              xbin = 300,
              nbin = 125,
              par.settings = my.settings,
              smooth = FALSE)

# Apply the gate
flowData_transformed <- Subset(flowData_transformed, polyGate1)

# Count the number of cells and subsample so all of them are at the same number for fair comparison of samples
NumberOfCells <- flowCore::fsApply(x = flowData_transformed, FUN = function(x) nrow(x), use.exprs = TRUE)
flowData_transformed10000H <- flowData_transformed[which(NumberOfCells > 10000)]
flowData_transformed10000H <- FCS_resample(flowData_transformed10000H, sample = 10000)
NumberOfCells10000H <- flowCore::fsApply(x = flowData_transformed10000H, FUN = function(x) nrow(x), use.exprs = TRUE)
flowData_transformed10000B <- flowData_transformed[which(NumberOfCells > 5000 & NumberOfCells < 10000)]
NumberOfCells10000B <- flowCore::fsApply(x = flowData_transformed10000B, FUN = function(x) nrow(x), use.exprs = TRUE)
flowData_transformed <- rbind2(flowData_transformed10000H, flowData_transformed10000B)

# Remove variables that are no longer needed
remove(sqrcut1, polyGate1, SortedFlowSet, fcsfiles)
```

```{r Preprocessing_GMM, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Normalise
summary <- fsApply(x = flowData_transformed, FUN = function(x) apply(x, 2, max), use.exprs = TRUE)
maxval <- max(summary[,"FITC-H"])
mytrans <- function(x) x/maxval
flowData_transformed <- transform(flowData_transformed,
                                  `FITC-H` = mytrans(`FITC-H`),
                                  `PerCP-Cy5.5-H` = mytrans(`PerCP-Cy5.5-H`), 
                                  `SSC-H` = mytrans(`SSC-H`),
                                  `FSC-H` = mytrans(`FSC-H`),
                                  `PE-H` = mytrans(`PE-H`),
                                  `PE-Cy7-H` = mytrans(`PE-Cy7-H`), 
                                  `APC-H` = mytrans(`APC-H`), 
                                  `V450-H` = mytrans(`V450-H`),
                                  `V500-H` = mytrans(`V500-H`))
# Parameters to take into account for the model
paramGMM <- c("FITC-H", "FSC-H", "SSC-H", "PerCP-Cy5.5-H")
# # Subsample to lower sample size to make the training faster
# flowData_transformed <- FCS_resample(flowData_transformed, replace = TRUE, sample = 1000)
# fcs_x <- flowData_transformed[, paramGMM]
# fcs_x <- Phenoflow::FCS_pool(fcs_x, stub = "*")
# fcs_x <- fcs_x[, paramGMM] # The FCS_pool makes an extra column called "Original" which we don't need
# # Check different number of clusters and optimise based on the BIC criterion
# gmm_clust <- Mclust(data = exprs(fcs_x[[1]]), G = seq(from = 10, to = 150, by = 5))
# saveRDS(object = gmm_clust, file = "Results/GMMFits/GMMs_4param_10to150per5.rds")
gmm_clust <- readRDS(file = "Results/GMMFits/GMMs_4param_10to150per5.rds")


# Plot the BIC values for the different models to see the optimization
NoClusters <- dimnames(gmm_clust$BIC)[[1]]
BICValues <- data.frame(as.matrix(gmm_clust$BIC)[1:length(NoClusters),])
BICValues$NoClusters <- rownames(BICValues)
BICValues <- reshape2::melt(BICValues, id.vars = "NoClusters")
colnames(BICValues) <- c("NoClusters", "ModelType", "BIC")
BICValues$NoClusters <- as.numeric(BICValues$NoClusters)
BICValues <- BICValues[!is.na(BICValues$BIC),] # remove the NA values
BICValues$ModelType <- droplevels(BICValues$ModelType, except = unique(BICValues$ModelType))# remove levels that are not being used
p_bic <- BICValues %>% 
          ggplot(data = ., aes(x = NoClusters, y = BIC)) +
          geom_line(alpha = 1, aes(color = ModelType), show.legend = F) +
          geom_point(shape = 21, size = 2, alpha = 1, aes(fill = ModelType)) +
          labs(x = "Number of clusters", y = "BIC", fill = "Model type") +
          theme_cowplot() +
          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
print(p_bic)


# Make pooled sample to visualse GMMs
Pooled <- FCS_pool(flowData_transformed["sample_005_20190902_103515.fcs"], stub = "_")
# Pooled <- FCS_resample(Pooled, replace = TRUE, sample = 10000)
Pooled <- Pooled[, paramGMM]
grid <- Pooled[[1]]@exprs
pred <- predict(object = gmm_clust, newdata = grid)
# store in a data frame
dfGMMViz <- as.data.frame(cbind(grid, pred$classification))
colnames(dfGMMViz) <- c("FITC-H", "FSC-H", "SSC-H", "PerCP-Cy5.5-H", "GMM_Nr") #c("FITC-H", "SSC-H", "SSC-H", "GMM_Nr")
dfGMMViz$GMM_Nr <- as.factor(dfGMMViz$GMM_Nr)
dfGMMViz$`SSC-H` <- as.numeric(paste(dfGMMViz$`SSC-H`))
dfGMMViz$`FITC-H` <- as.numeric(paste(dfGMMViz$`FITC-H`))
# PLot the GMM
p_GMMgrid <- dfGMMViz %>%
             dplyr::filter(GMM_Nr %in% 1:30) %>%
              ggplot(data = .) + 
              geom_point(alpha = 0.5, shape = 21, aes(y = `FITC-H`, x = `SSC-H`, fill = GMM_Nr)) +
              scale_x_continuous(limits = c(0.35, 0.85)) +
              scale_y_continuous(limits = c(0.6, 0.95)) +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
print(p_GMMgrid)


# Apply GMM mask to the data
NumberOfClusters <- gmm_clust$G
params_gmm <- colnames(gmm_clust$data)
flowData_transformed <- flowData_transformed[, params_gmm] # subset to the relevant parameters
GMMOut <- data.frame(matrix(nrow = NumberOfClusters+1, ncol = length(flowData_transformed))) # Initialize a df to store the results of the predictions
rownames(GMMOut) <- c(1:NumberOfClusters, "(Other)")
for (i in 1:length(flowData_transformed)){
    RawData <- flowData_transformed[[i]]@exprs
    GMMPred <- predict(gmm_clust, RawData)
    GMMPred <- as.factor(GMMPred$classification)
    Summary <- summary(GMMPred)
    Summary <- Summary[rownames(GMMOut)] # Reorganise to the same order as the df that was initialised above
    GMMOut[,i] <- Summary
}
# Replace the NA values by 0
GMMOut[is.na(GMMOut)] <- 0
rownames(GMMOut) <- c(paste("GMM", 1:NumberOfClusters, sep = ""), "Other")
colnames(GMMOut) <- sampleNames(flowData_transformed)
# Normalise the GMM abundances to sum = 1
GMMOut <- sweep(GMMOut, 2, colSums(GMMOut), `/`)
GMMOut <- t(GMMOut)
GMMOut <- as.data.frame(GMMOut)
GMMOut$Names <- rownames(GMMOut)

# Remove all variables that are no longer needed
remove(BICValues, dfGMMViz, flowData_transformed10000B, flowData_transformed10000H, grid, NumberOfCells, NumberOfCells10000B, NumberOfCells10000H, info, Info, INFO, my.settings, Pooled, pred, RawData, p_bic, p_GMMgrid, OTUPreprocessedMelted, p_OTUdistribution1, physeqobj, shared.selection, taxmat.ns, summary, otumat.ns, SubsetINFO, i, GMMPred, NoClusters, NumberOfClusters, params_gmm, IdentifierControlSamples, OTU, param, SubsetOTU, SubsetTAX, Summary, TAX)
```

### Combine Illumina and FCM data

```{r MatchFCMAndIlluminaData, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Match the Illumina and FCM-metadata
MetadataIllumina <- Metadata[Metadata$Identifier %in% Identifiers,]
MetadataIllumina <- MetadataIllumina[c("SampleIdentifierFCM", "Identifier", "Population")]
MetadataFCM <- MetadataFCM[MetadataFCM$X1 %in% IdentifiersFCM,] # For the community samples
MetadataFCM <- MetadataFCM[c("FACS_names", "X1")]
IdentifiersBoth <- left_join(MetadataFCM, MetadataIllumina, by = c("X1" = "SampleIdentifierFCM"))

# Get IDs of non-sorted samples
NonSorted <- IdentifiersBoth$Identifier

# Add the metadata of the in silico sorted populations
MetadataSorted <- read.csv(file = "Metadata/MetadataInSilicoSortedFCS.csv", sep = ",")
MetadataSorted$Sample <- gsub("A", "A/B", MetadataSorted$Sample)
MetadataSorted$Population <- as.character(MetadataSorted$Population)
IdentifiersBothII <- left_join(MetadataSorted, MetadataIllumina[MetadataIllumina$SampleIdentifierFCM %in% MetadataSorted$Sample,], by = c("Sample" = "SampleIdentifierFCM", "Population" = "Population"))
IdentifiersBothII <- IdentifiersBothII[c("Filename", "Population", "Sample", "Identifier")]
colnames(IdentifiersBothII) <- c("FACS_names", "Population", "X1", "Identifier")
IdentifiersBothII <- IdentifiersBothII[colnames(IdentifiersBoth)]
IdentifiersBoth <- rbind(IdentifiersBoth, IdentifiersBothII)

# Remove variables that are no longer needed
remove(MetadataIllumina, MetadataSorted, IdentifiersBothII, Identifiers, IdentifiersFCM, MetadataFCM)
```

### Train models for top 50 OTUs

#### Replicates over the different tanks

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
PerformancePerFold_ALL_IS <- NULL
PerformancePerFold_NS_IS <- NULL
PredictionsPerFold_ALL_IS <- NULL
PredictionsPerFold_NS_IS <- NULL
PerformanceDataset_ALL_IS <- NULL
PerformanceDataset_NS_IS <- NULL

for (i in 1:50){

  # Select OTU of interest
  OTUOfInterest <- OTUPreprocessed$OTU[i]
  OTUAbundances <- OTUPreprocessed[OTUPreprocessed$OTU == OTUOfInterest,]
  OTUAbundances <- cbind.data.frame(names(OTUAbundances), as.numeric(paste(OTUAbundances)))[-1,]
  colnames(OTUAbundances) <- c("ID", "Abundance")

  # Combine the features and measured variables
  Dataset <- left_join(GMMOut, IdentifiersBoth, by = c("Names" = "FACS_names"))
  Dataset <- left_join(Dataset, OTUAbundances, by = c("Identifier" = "ID"))
  Dataset <- Dataset[!is.na(Dataset$Identifier),]
  rownames(Dataset) <- Dataset$Identifier
  Dataset <- Dataset[, -which(names(Dataset) %in% c("Names", "Identifier", "X1", "Population", "BacterialDensity"))]
  Dataset <- Dataset[!is.na(Dataset$Abundance),]
  
  if(sum(Dataset$Abundance > 0.01) > 3){ # Extra check for missing OTUs in a subset of the data

      # Centered log ratio transform
      Dataset <- cbind.data.frame(compositions::clr(Dataset[,!names(Dataset) == "Abundance"]), Dataset$Abundance)
      colnames(Dataset)[dim(Dataset)[2]] <- "Abundance"

      # Save dataset to reload it later
      DatasetFull <- Dataset

      # Model
      for (rep in 1:3){
      AllPredictions <- NULL
      AllPredictionsReg <- NULL
      ClassificationProbabilities <- NULL
      # Split data into folds
      NumberOfFolds <- 5
      Set1 <- 1
      Set2 <- 2
      Set3 <- 3
      Set4 <- 4
      Set5 <- 5
      Sets <- c("Set1", "Set2", "Set3", "Set4", "Set5")
      for (k in 1:(floor(dim(Dataset)[1]/NumberOfFolds)-1)){
        # Get indices
        Set1 <- c(Set1, k*NumberOfFolds)
        Set2 <- c(Set2, (k*NumberOfFolds)+1)
        Set3 <- c(Set3, (k*NumberOfFolds)+2)
        Set4 <- c(Set4, (k*NumberOfFolds)+3)
        Set5 <- c(Set5, (k*NumberOfFolds)+4)
      }
      if(max(Set5) < dim(Dataset)[1]){
        NUmberLeft <- dim(Dataset)[1] - max(Set5)
        for (l in 1:NUmberLeft){
          assign(Sets[l], c(get(Sets[l]), max(Set5) + l))
        }
      }
      if(rep %in% c(2,3)){
        NumberOfSwitches <- round(length(Set5)/3)
        for (pos in 1:NumberOfSwitches){
          Set1[rep*pos] <- Set2[rep*pos]
          Set2[rep*pos] <- Set3[rep*pos]
          Set3[rep*pos] <- Set4[rep*pos]
          Set4[rep*pos] <- Set5[rep*pos]
          Set5[rep*pos] <- Set1[rep*pos]
        }
      }
      # If one of the sets had an element less it might have generated NA
      Set1 <- Set1[!is.na(Set1)]
      Set2 <- Set2[!is.na(Set2)]
      Set3 <- Set3[!is.na(Set3)]
      Set4 <- Set4[!is.na(Set4)]
      Set5 <- Set5[!is.na(Set5)]
      # Combine in a list
      Folds <- list(Fold1 = Set1, Fold2 = Set2, Fold3 = Set3, Fold4 = Set4, Fold5 = Set5)
      
      # Train and evaluate
      for (fold in 1:length(Folds)){
            Dataset <- DatasetFull
            GMMNames <- colnames(Dataset)[!colnames(Dataset) == "Abundance"]

            # Selected fold
            Testindices <- Folds[[fold]]
            train3 <- Dataset[-Testindices, ]
            test3 <- Dataset[Testindices, ]

            # Transformation --> ensure predictions are in the 0-1 range to allow logit transformation later
            minvalue <- min(train3$Abundance[train3$Abundance > 0])

            # Get number of samples with low abundance (i.e. < 0.01) and high abundance (i.e. > 0.01)
            Below1 <- train3[train3$Abundance < 0.01,]
            Over1 <- train3[train3$Abundance >= 0.01,]

            #
            TotalNew <- 500
            NumberOfBelow1 <- dim(Below1)[1]
            NumberOfOver1 <- dim(Over1)[1]
            NumberOfOver1ToMake <- round(NumberOfBelow1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
            NumberOfBelow1ToMake <- round(NumberOfOver1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
            if(NumberOfOver1ToMake < TotalNew/2) NumberOfOver1ToMake <- TotalNew/2
            if(NumberOfBelow1ToMake < TotalNew/2) NumberOfBelow1ToMake <- TotalNew/2
            if(dim(Below1)[1] == 1){
              NumberOfBelow1ToMake <- 0
              NumberOfOver1ToMake <- TotalNew
            }

            # Max random variation (1000x smaller than the smallest value)
            RandValPredictorVals <- colMins(as.matrix(abs(train3[, !names(train3) == "Abundance"])))/100
            RandValOutput <- min(abs(train3$Abundance[train3$Abundance > 0]))/100
            RandGMMVals <- NULL
            RandAbundVals <- NULL

            # Fake zero's
            InSilicoBelow1 <- NULL
            for (j in 1:round(NumberOfBelow1ToMake*1)){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSamples <- round(runif(2, min = 1, max = dim(Below1)[1]))
              Sample1 <- Below1[SelectedSamples[1],]
              Sample2 <- Below1[SelectedSamples[2],]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoBelow1 <- rbind.data.frame(InSilicoBelow1, New)
            }

            # Fake abundant using only abundant samples
            InSilicoOver1H <- NULL
            Over1High <- Over1[mean(Over1$Abundance) < Over1$Abundance,]
            for (j in 1:round(NumberOfOver1ToMake*(1))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample1 <- Over1High[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample2 <- Over1High[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver1H <- rbind.data.frame(InSilicoOver1H, New)
            }

            # Fake abundant using only abundant samples
            InSilicoOver1 <- NULL
            for (j in 1:round(NumberOfOver1ToMake*(1/2))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
              Sample1 <- Over1[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample2 <- Over1High[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver1 <- rbind.data.frame(InSilicoOver1, New)
            }

            # Fake samples mixed between low and high abundances
            InSilicoOver2 <- NULL
            for (j in 1:round(NumberOfOver1ToMake*(1/2))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
              Sample1 <- Over1[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Below1)[1]))
              Sample2 <- Below1[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver2 <- rbind.data.frame(InSilicoOver2, New)
            }

            # Combine the in sillico samples with the original data
            train3 <- cbind.data.frame("Original", train3)
            colnames(train3)[1] <- "Group"
            InSilicoBelow1 <- cbind.data.frame("InSilicoBelow1", InSilicoBelow1)
            colnames(InSilicoBelow1)[1] <- "Group"
            InSilicoOver1H <- cbind.data.frame("InSilicoOver1H", InSilicoOver1H)
            colnames(InSilicoOver1H)[1] <- "Group"
            InSilicoOver1 <- cbind.data.frame("InSilicoOver1", InSilicoOver1)
            colnames(InSilicoOver1)[1] <- "Group"
            InSilicoOver2 <- cbind.data.frame("InSilicoOver2", InSilicoOver2)
            colnames(InSilicoOver2)[1] <- "Group"
            train3 <- rbind.data.frame(train3, InSilicoBelow1, InSilicoOver1H, InSilicoOver1, InSilicoOver2)

            # Make an extra dataframe in the column with two classes: present and absent
            train3$Presence[train3$Abundance > 0.01] <- "Present"
            train3$Presence[train3$Abundance <= 0.01] <- "Absent"
            train3$Presence <- as.factor(train3$Presence)
            test3$Presence[test3$Abundance > 0.01] <- "Present"
            test3$Presence[test3$Abundance <= 0.01] <- "Absent"
            test3$Presence <- as.factor(test3$Presence)

            # Save the full dataframes to reload before the regression
            train3full <- train3
            test3full <- test3

            # Feature selection step
            train3Original <- train3[train3$Group == "Original",]
            train3Original <- train3Original[colnames(train3Original) != "Group"]
            train3Original <- train3Original[colnames(train3Original) != "Abundance"]
            # # Balance
            if(!summary(train3Original$Presence)[1] == summary(train3Original$Presence)[2]){train3Original <- RandOverClassif(Presence ~ ., dat = train3Original, C.perc = "balance")}
            # define the control using a random forest selection function
            control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
            # run the RFE algorithm
            results <- rfe(x = train3Original[,!names(train3Original) == "Presence"], y = train3Original$Presence, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Presence"])[2], by = 2), rfeControl = control, metric = "Accuracy")
            # plot the results
            plot(results, type = c("g", "o"))
            # Make selection
            rfeout <- results$results
            AbsoluteBest <- pickSizeBest(rfeout, metric = "Accuracy", maximize = TRUE)
            Within1Perc <- pickSizeTolerance(rfeout, metric = "Accuracy",  tol = 0.5, maximize = TRUE)
            if(results$results$Accuracy[results$results$Variables == AbsoluteBest] == 1){Within1Perc <- AbsoluteBest}
            if(Within1Perc == 1){Within1Perc <- AbsoluteBest}
            Keep <- results$optVariables[1:Within1Perc]
            KeepClassifier <- Keep
            # list the chosen features
            train3 <- train3[c("Group", Keep, "Abundance", "Presence")]
            test3 <- test3[c(Keep, "Abundance", "Presence")]

            # Make over 1 uniform
            Train3Over <- train3[train3$Abundance >= 0.01,]
            Train3Below <- train3[train3$Abundance < 0.01,]
            RangeAbundances <- range(Train3Over$Abundance)
            BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
            CutAbundances <- cut(Train3Over$Abundance, BreaksAbundances, right = FALSE)
            FrequencyAbundances <- table(CutAbundances)
            CutOff <- round(median(FrequencyAbundances))
            Subsampled <- NULL
            for (k in 1:length(FrequencyAbundances)){
              # Get samples in the kth interval
              Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
              Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
              SelectedData <- Train3Over[Train3Over$Abundance >= Lower & Train3Over$Abundance < Upper,]
              # Subsample if there are more than "cutoff"
              if (dim(SelectedData)[1] > CutOff){
                  SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                } else {
                  SelectedData <- SelectedData
                }
                # Store subsampled data
                Subsampled <- rbind(Subsampled, SelectedData)
              }
            Train3Over <- Subsampled
            # Combine with the low abundant samples
            train3 <- rbind.data.frame(Train3Over, Train3Below)

            # Temporarily remove the abundance column
            train3 <- train3[colnames(train3) != "Abundance"]
            test3 <- test3[colnames(test3) != "Abundance"]

            # Remove the "Group"-column
            train3 <- train3[colnames(train3) != "Group"]
            test3 <- test3[colnames(test3) != "Group"]

            # Balance the classes
            print(summary(train3$Presence))
            if(!summary(train3$Presence)[1] == summary(train3$Presence)[2]){train3 <- RandUnderClassif(Presence ~ ., dat = train3, C.perc = "balance", repl = FALSE)}
            print(summary(train3$Presence))

            ### Caret list
            FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Presence, k = 3, times = 1), classProbs = TRUE)

                # Create tuning grid for the RF
                    # Tune RF
                    if (dim(train3)[2]-1 > 5) {
                      mtryoptions <- seq(1, round(dim(train3[,!names(train3) == "Presence"])[2]/5), by = 1)
                    } else {
                      mtryoptions <- seq(1, dim(train3)[2]-1, by = 1)
                    }
                    tunegridRF <- expand.grid(.mtry = mtryoptions)
                    # Tune SVMPoly
                    C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                    degree <- c(1, 2, 3)
                    scale <- c(1, 2)
                    tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)

                # Train models
                model_listClassifier <- caretList(Presence ~ .,
                                        data = train3,
                                        trControl = FitControl,
                                        tuneList = list(RF = caretModelSpec(method = "rf", tuneGrid = tunegridRF, ntree = 500)))

              # Get predictions
              if(dim(test3)[2] == 2){
                testset <- as.data.frame(test3[,!names(test3) == "Presence"])
                colnames(testset) <- colnames(test3[1])
              } else {
                testset <- as.data.frame(test3[,!names(test3) == "Presence"])
              }
              ens_preds <- predict(model_listClassifier$RF, newdata = testset, type = "raw")
              ens_preds <- cbind.data.frame(ens_preds, test3$Presence)
              colnames(ens_preds) <- c("Predicted", "Real")
              rownames(ens_preds) <- rownames(test3)
              PredRFC <- ens_preds

              # Compute and save prediction probabilities
              ClassProb <- predict(model_listClassifier$RF, newdata = testset, type = "prob")
              ClassificationProbabilities <- rbind.data.frame(ClassificationProbabilities, cbind.data.frame(as.numeric(test3$Presence == "Absent"), ClassProb["Absent"]))
              # ROC <- roc(as.numeric(test3$Presence == "Absent"), ClassProbs$Absent)
              # AUC <- auc(ROC)
              # print(AUC[1])
              
              
              # Get feature importances
                  # From the model
                  ImportancesRF <- t(as.data.frame(varImp(model_listClassifier$RF)["importance"]))
                  # Features that were removed
                  RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesRF)]
                  ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                  names(ImportancesRemoved) <- RemovedFeatures
                  #
                  ImportancesClassifier <- cbind.data.frame(ImportancesRF, ImportancesRemoved)
                  ImportancesClassifier <- ImportancesClassifier[,GMMNames]
                  names(ImportancesClassifier) <- paste(names(ImportancesClassifier), "_Class", sep = "")



              ### REGRESSION ###
              # Temporarily remove the abundance column
              train3 <- train3full
              test3 <- test3full

              # Remove "Presence"-column
              train3 <- train3[colnames(train3) != "Presence"]
              test3 <- test3[colnames(test3) != "Presence"]

              # Feature selection step
              train3Original <- train3[train3$Group == "Original",]
              train3Original <- train3Original[colnames(train3Original) != "Group"]
              # more homogeneous distribution
              train3OriginalLower <- train3Original[train3Original$Abundance < 0.01,]
              train3OriginalHigher <- train3Original[train3Original$Abundance >= 0.01,]
              if(dim(train3OriginalLower)[1] > dim(train3OriginalHigher)[1]){
                train3OriginalLower <- train3OriginalLower[sample(nrow(train3OriginalLower), dim(train3OriginalHigher)[1]), ]
              }
              train3Original <- rbind.data.frame(train3OriginalLower, train3OriginalHigher)
              if(dim(train3Original)[1] > 10){
                    # define the control using a random forest selection function
                    control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
                    # run the RFE algorithm
                    results <- rfe(x = train3Original[,!names(train3Original) == "Abundance"], y = train3Original$Abundance, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Abundance"])[2], by = 2), rfeControl = control, metric = "Rsquared")
                    # plot the results
                    plot(results, type = c("g", "o"))
                    # Make selection
                    rfeout <- results$results
                    if(sum(rfeout$Rsquared == 1) == length(rfeout$Rsquared)){
                      Keep <- Keep
                    } else {
                      Within1Perc <- pickSizeTolerance(rfeout, metric = "Rsquared",  tol = 0.5, maximize = TRUE)
                      Keep <- results$optVariables[1:Within1Perc]
                    }
                    # Get the chosen features
                    train3 <- train3[c("Group", Keep, "Abundance")]
                    test3 <- test3[c(Keep, "Abundance")]
              }

              # Remove the group-column
              train3 <- train3[colnames(train3) != "Group"]

              # Reduce imbalance in the dataset
              RangeAbundances <- range(train3$Abundance)
              BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
              CutAbundances <- cut(train3$Abundance, BreaksAbundances, right = FALSE)
              FrequencyAbundances <- table(CutAbundances)
              CutOff <- round(median(FrequencyAbundances))
              Subsampled <- NULL
              for (k in 1:length(FrequencyAbundances)){
                # Get samples in the kth interval
                Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
                Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
                SelectedData <- train3[train3$Abundance >= Lower & train3$Abundance < Upper,]
                # Subsample if there are more than "cutoff"
                if (dim(SelectedData)[1] > CutOff){
                  SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                } else {
                  SelectedData <- SelectedData
                }
                # Store subsampled data
                Subsampled <- rbind(Subsampled, SelectedData)
              }
              train3 <- Subsampled

              # Logit transformation --> ensure predictions are in the 0-1 range
              train3$Abundance[train3$Abundance >= 1] <- 1 - minvalue/10
              train3$Abundance[train3$Abundance <= 0] <- minvalue/10
              train3$Abundance <- boot::logit(train3$Abundance)

              ### Caret list
              FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Abundance, k = 3, times = 1), summaryFunction = mapeexpSummary)
                  # Create tuning grids
                      # Tune SVMPoly
                      C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                      degree <- c(1, 2, 3)
                      scale <- c(1, 2)
                      tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)
                      # Tune gradient boost
                      n.trees <- c(50, 100, 250, 500)
                      interaction.depth <- c(1)
                      shrinkage <- c(0.3, 0.2, 0.1, 0.05, 0.01)
                      n.minobsinnode <- seq(1, 3, by = 1)
                      tunegridGBM <- expand.grid(n.trees = n.trees, interaction.depth = interaction.depth, shrinkage = shrinkage, n.minobsinnode = n.minobsinnode)

                  # Train models
                  model_list <- caretList(Abundance ~ .,
                                        data = train3,
                                        trControl = FitControl,
                                        tuneList = list(SVMPoly = caretModelSpec(method = "svmPoly", tuneGrid = tunegridSVMPoly, metric = "Rsquared"),
                                                        GBM = caretModelSpec(method = "gbm", tuneGrid = tunegridGBM, metric = "Rsquared")))

              # make ensemble
              greedy_ensemble <- caretEnsemble(model_list, trControl = FitControl, metric = "Rsquared")

              # Make predictions
              if(dim(test3)[2] == 2){
                testset <- as.data.frame(test3[,!names(test3) == "Abundance"])
                colnames(testset) <- colnames(test3[1])
              } else {
                testset <- as.data.frame(test3[,!names(test3) == "Abundance"])
              }
              ens_preds <- predict(greedy_ensemble, newdata = testset)
              ens_preds <- cbind.data.frame(ens_preds, test3$Abundance)
              colnames(ens_preds) <- c("Predicted", "Real")
              rownames(ens_preds) <- rownames(test3)

              # Reverse the logit transform
              ens_preds$Predicted <- boot::inv.logit(ens_preds$Predicted)

              # Get feature importances
                  # From the model
                  ImportancesEnsemble <- t(as.data.frame(varImp(greedy_ensemble)["overall"]))
                  # Features that were removed
                  RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesEnsemble)]
                  ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                  names(ImportancesRemoved) <- RemovedFeatures
                  #
                  ImportancesEnsemble <- cbind.data.frame(ImportancesEnsemble, ImportancesRemoved)
                  ImportancesEnsemble <- ImportancesEnsemble[,GMMNames]
                  names(ImportancesEnsemble) <- paste(names(ImportancesEnsemble), "_Reg", sep = "")

              ### Combine predictions from the classifier and regression ###
              Predictions <- as.data.frame(matrix(, nrow = length(test3$Abundance), ncol = 2))
              colnames(Predictions) <- c("Predicted", "Real")
              Predictions$Predicted <- ens_preds$Predicted
              Predictions$Predicted[PredRFC$Predicted == "Absent"] <- 0
              Predictions$Real <- ens_preds$Real
              rownames(Predictions) <- rownames(test3)

              # # Save the predictions
              AllPredictions <- rbind(AllPredictions, cbind.data.frame(fold, Predictions))
              AllPredictionsReg <- rbind(AllPredictionsReg, cbind.data.frame(fold, ens_preds))

              # Save predictions and calculate performance metrics
                  # combine classifier, regression, total predictions
                  Combined <- cbind.data.frame(OTUOfInterest, rep, fold, PredRFC, ens_preds$Predicted, Predictions)
                  colnames(Combined) <- c("OTU", "rep", "fold", "PredictedClass", "TrueClass", "Regression", "Combined", "TrueValue")
                  Combined$TrueClass <- as.character(Combined$TrueClass)
                  Combined$PredictedClass <- as.character(Combined$PredictedClass)
                  Combined$Index <- rownames(Combined)

                  CombinedNS <- Combined[rownames(Combined) %in% NonSorted,]
                  colnames(CombinedNS) <- c("OTU", "rep", "fold", "PredictedClass", "TrueClass", "Regression", "Combined", "TrueValue", "Index")
                  # For all data
                  PerformancePerFold_ALL_IS <- rbind(PerformancePerFold_ALL_IS, cbind.data.frame(OTUOfInterest, rep, fold, RMSE(100*Combined$Combined, 100*Combined$TrueValue), MAE(100*Combined$Combined, 100*Combined$TrueValue), R2(100*Combined$Combined, 100*Combined$TrueValue), sum(Combined$PredictedClass == Combined$TrueClass)/length(Combined$TrueClass), ImportancesClassifier, ImportancesClassifier, ImportancesEnsemble))
                  PredictionsPerFold_ALL_IS <- rbind(PredictionsPerFold_ALL_IS, Combined)
                  # For only non-sorted data
                  PerformancePerFold_NS_IS <- rbind(PerformancePerFold_NS_IS, cbind.data.frame(OTUOfInterest, rep, fold, RMSE(100*CombinedNS$Combined, 100*CombinedNS$TrueValue), MAE(100*CombinedNS$Combined, 100*CombinedNS$TrueValue), R2(100*CombinedNS$Combined, 100*CombinedNS$TrueValue), sum(CombinedNS$PredictedClass == CombinedNS$TrueClass)/length(CombinedNS$TrueClass), ImportancesClassifier, ImportancesEnsemble))
                  PredictionsPerFold_NS_IS <- rbind(PredictionsPerFold_NS_IS, CombinedNS)

        }

      # Plot all predictions on the testset
        AllPredictions$Predicted <- 100*AllPredictions$Predicted
        AllPredictions$Real <- 100*AllPredictions$Real
        p_pred <- ggplot(AllPredictions, aes(x = Real, y = Predicted)) +
                            geom_point(shape = 21, size = 2, fill = SingleColor) +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
        # p_pred

        
        AllPredictionsReg$Predicted <- 100*AllPredictionsReg$Predicted
        AllPredictionsReg$Real <- 100*AllPredictionsReg$Real
        p_predr <- ggplot(AllPredictionsReg, aes(x = Real, y = Predicted)) + 
                            geom_point(shape = 21, size = 2, fill = SingleColor) +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
        # p_predr


        # Plot all predictions on the non-sorted samples
        AllPredictionsNS <- AllPredictions[rownames(AllPredictions) %in% NonSorted,]
        AllPredictionsNS <- round(AllPredictionsNS)
        AllPredictionsNS_R2 <- R2(AllPredictionsNS$Predicted,AllPredictionsNS$Real)
        p_predNS <- ggplot(AllPredictionsNS, aes(x = Real, y = Predicted)) +
                            geom_point(shape = 21, size = 2, fill = "#6c72dd") +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            annotate(geom = "text", x = 15, y = 95, label = paste0("R.sq. = ", format(AllPredictionsNS_R2, digits = 2))) +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
        # print(p_predNS)
        
        AllPredictionsRegNS <- AllPredictionsReg[rownames(AllPredictionsReg) %in% NonSorted,]
        AllPredictionsRegNS <- round(AllPredictionsRegNS)
        AllPredictionsRegNS_R2 <- R2(AllPredictionsRegNS$Predicted, AllPredictionsRegNS$Real)
        p_predRegNS <- ggplot(AllPredictionsRegNS, aes(x = Real, y = Predicted)) +
                            geom_point(shape = 21, size = 2, fill = "#6c72dd") +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            annotate(geom = "text", x = 15, y = 95, label = paste0("R.sq. = ", format(AllPredictionsRegNS_R2, digits = 2))) +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
        # print(p_predRegNS)
        
        
        # Calculate AUC
        colnames(ClassificationProbabilities) <- c("True", "Probs")
        ROC_ALL <- roc(ClassificationProbabilities$True, ClassificationProbabilities$Probs)
        AUC_ALL <- print(auc(ROC_ALL)[1])
        
        ClassificationProbabilitiesNS <- ClassificationProbabilities[rownames(ClassificationProbabilities) %in% NonSorted,]
        if (length(unique(ClassificationProbabilitiesNS$True)) > 1){
            ROC_NS <- roc(ClassificationProbabilitiesNS$True, ClassificationProbabilitiesNS$Probs)
            AUC_NS <- print(auc(ROC_NS)[1])
        } else {
            AUC_NS <- NA
        }

        # g1 <- plot_grid(p_predRegNS, p_predNS, labels = c("A", "B"), ncol = 2, nrow = 1, scale = 0.95)
        # g1
        # 
        # g1 <- plot_grid(p_predRegNS, p_predNS, labels = c("B", "C"), ncol = 2, nrow = 1, scale = 0.95)
        # g2 <- plot_grid(NULL, g1, labels = c("A", ""), ncol = 1, nrow = 2, rel_heights = c(0.8, 1), scale = 1)
        # g2
        # ggsave(file = "Figures/ClassifierRegression.png", width = 9, height = 8, dpi = 300, units = "in", g2)

        # Save predictions and calculate performance metics
        PerformanceDataset_ALL_IS <- rbind(PerformanceDataset_ALL_IS, cbind.data.frame(OTUOfInterest, rep, RMSE(AllPredictions$Predicted,AllPredictions$Real), MAE(AllPredictions$Predicted,AllPredictions$Real), R2(AllPredictions$Predicted,AllPredictions$Real), AUC_ALL))
        PerformanceDataset_NS_IS <- rbind(PerformanceDataset_NS_IS, cbind.data.frame(OTUOfInterest, rep, RMSE(AllPredictionsNS$Predicted, AllPredictionsNS$Real), MAE(AllPredictionsNS$Predicted,AllPredictionsNS$Real), R2(AllPredictionsNS$Predicted,AllPredictionsNS$Real), AUC_NS))

      }

  }

}

# write.csv(PerformancePerFold_ALL_IS, "Results/PerformancePerFold_ALL.csv")
# write.csv(PerformancePerFold_NS_IS, "Results/PerformancePerFold_NS.csv")
# write.csv(PredictionsPerFold_ALL_IS, "Results/PredictionsPerFold_ALL.csv")
# write.csv(PredictionsPerFold_NS_IS, "Results/PredictionsPerFold_NS.csv")
# write.csv(PerformanceDataset_ALL_IS, "Results/PerformanceDataset_ALL.csv")
# write.csv(PerformanceDataset_NS_IS, "Results/PerformanceDataset_NS.csv")
```

#### Using one of the tanks as validation

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
PerformancePerFold_ALL_IS <- NULL
PerformancePerFold_NS_IS <- NULL
PredictionsPerFold_ALL_IS <- NULL
PredictionsPerFold_NS_IS <- NULL
PerformanceDataset_ALL_IS <- NULL
PerformanceDataset_NS_IS <- NULL

ID1 <- Metadata$Identifier[Metadata$Tank == "T1" & Metadata$WholeCommunityOrSorted == "Whole community"]
ID2 <- Metadata$Identifier[Metadata$Tank == "T2" & Metadata$WholeCommunityOrSorted == "Whole community"]
ID3 <- Metadata$Identifier[Metadata$Tank == "T3" & Metadata$WholeCommunityOrSorted == "Whole community"]
ID4 <- Metadata$Identifier[Metadata$Tank == "T4" & Metadata$WholeCommunityOrSorted == "Whole community"]
ID5 <- Metadata$Identifier[Metadata$Tank == "T5" & Metadata$WholeCommunityOrSorted == "Whole community"]

for (i in 1:50){

  # Select OTU of interest
  OTUOfInterest <- OTUPreprocessed$OTU[i]
  OTUAbundances <- OTUPreprocessed[OTUPreprocessed$OTU == OTUOfInterest,]
  OTUAbundances <- cbind.data.frame(names(OTUAbundances), as.numeric(paste(OTUAbundances)))[-1,]
  colnames(OTUAbundances) <- c("ID", "Abundance")

  # Combine the features and measured variables
  Dataset <- left_join(GMMOut, IdentifiersBoth, by = c("Names" = "FACS_names"))
  Dataset <- left_join(Dataset, OTUAbundances, by = c("Identifier" = "ID"))
  Dataset <- Dataset[!is.na(Dataset$Identifier),]
  rownames(Dataset) <- Dataset$Identifier
  Dataset <- Dataset[, -which(names(Dataset) %in% c("Names", "Identifier", "X1", "Population", "BacterialDensity"))]
  Dataset <- Dataset[!is.na(Dataset$Abundance),]
  
  if(sum(Dataset$Abundance > 0.01) > 3){ # Extra check for missing OTUs in a subset of the data

      # Centered log ratio transform
      Dataset <- cbind.data.frame(compositions::clr(Dataset[,!names(Dataset) == "Abundance"]), Dataset$Abundance)
      colnames(Dataset)[dim(Dataset)[2]] <- "Abundance"

      # Save dataset to reload it later
      DatasetFull <- Dataset

      # Model
      for (rep in 1){
      AllPredictions <- NULL
      AllPredictionsReg <- NULL
      # Each tank is a fold
      Set1 <- which(rownames(DatasetFull) %in% ID1[ID1 %in% rownames(DatasetFull)])
      Set2 <- which(rownames(DatasetFull) %in% ID2[ID2 %in% rownames(DatasetFull)])
      Set3 <- which(rownames(DatasetFull) %in% ID3[ID3 %in% rownames(DatasetFull)])
      Set4 <- which(rownames(DatasetFull) %in% ID4[ID4 %in% rownames(DatasetFull)])
      Set5 <- which(rownames(DatasetFull) %in% ID5[ID5 %in% rownames(DatasetFull)])
      # Combine in a list
      Folds <- list(Fold1 = Set1, Fold2 = Set2, Fold3 = Set3, Fold4 = Set4, Fold5 = Set5)
      # Train and evaluate
      for (fold in 1:length(Folds)){
            Dataset <- DatasetFull
            GMMNames <- colnames(Dataset)[!colnames(Dataset) == "Abundance"]

            # Selected fold
            Testindices <- Folds[[fold]]
            train3 <- Dataset[-Testindices, ]
            test3 <- Dataset[Testindices, ]

            # Transformation --> ensure predictions are in the 0-1 range to allow logit transformation later
            minvalue <- min(train3$Abundance[train3$Abundance > 0])

            # Get number of samples with low abundance (i.e. < 0.01) and high abundance (i.e. > 0.01)
            Below1 <- train3[train3$Abundance < 0.01,]
            Over1 <- train3[train3$Abundance >= 0.01,]

            #
            TotalNew <- 500
            NumberOfBelow1 <- dim(Below1)[1]
            NumberOfOver1 <- dim(Over1)[1]
            NumberOfOver1ToMake <- round(NumberOfBelow1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
            NumberOfBelow1ToMake <- round(NumberOfOver1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
            if(NumberOfOver1ToMake < TotalNew/2) NumberOfOver1ToMake <- TotalNew/2
            if(NumberOfBelow1ToMake < TotalNew/2) NumberOfBelow1ToMake <- TotalNew/2
            if(dim(Below1)[1] == 1){
              NumberOfBelow1ToMake <- 0
              NumberOfOver1ToMake <- TotalNew
            }

            # Max random variation (1000x smaller than the smallest value)
            RandValPredictorVals <- colMins(as.matrix(abs(train3[, !names(train3) == "Abundance"])))/100
            RandValOutput <- min(abs(train3$Abundance[train3$Abundance > 0]))/100
            RandGMMVals <- NULL
            RandAbundVals <- NULL

            # Fake zero's
            InSilicoBelow1 <- NULL
            for (j in 1:round(NumberOfBelow1ToMake*1)){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSamples <- round(runif(2, min = 1, max = dim(Below1)[1]))
              Sample1 <- Below1[SelectedSamples[1],]
              Sample2 <- Below1[SelectedSamples[2],]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoBelow1 <- rbind.data.frame(InSilicoBelow1, New)
            }

            # Fake abundant using only abundant samples
            InSilicoOver1H <- NULL
            Over1High <- Over1[mean(Over1$Abundance) < Over1$Abundance,]
            for (j in 1:round(NumberOfOver1ToMake*(1))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample1 <- Over1High[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample2 <- Over1High[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver1H <- rbind.data.frame(InSilicoOver1H, New)
            }

            # Fake abundant using only abundant samples
            InSilicoOver1 <- NULL
            for (j in 1:round(NumberOfOver1ToMake*(1/2))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
              Sample1 <- Over1[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample2 <- Over1High[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver1 <- rbind.data.frame(InSilicoOver1, New)
            }

            # Fake samples mixed between low and high abundances
            InSilicoOver2 <- NULL
            for (j in 1:round(NumberOfOver1ToMake*(1/2))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
              Sample1 <- Over1[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Below1)[1]))
              Sample2 <- Below1[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver2 <- rbind.data.frame(InSilicoOver2, New)
            }

            # Combine the in sillico samples with the original data
            train3 <- cbind.data.frame("Original", train3)
            colnames(train3)[1] <- "Group"
            InSilicoBelow1 <- cbind.data.frame("InSilicoBelow1", InSilicoBelow1)
            colnames(InSilicoBelow1)[1] <- "Group"
            InSilicoOver1H <- cbind.data.frame("InSilicoOver1H", InSilicoOver1H)
            colnames(InSilicoOver1H)[1] <- "Group"
            InSilicoOver1 <- cbind.data.frame("InSilicoOver1", InSilicoOver1)
            colnames(InSilicoOver1)[1] <- "Group"
            InSilicoOver2 <- cbind.data.frame("InSilicoOver2", InSilicoOver2)
            colnames(InSilicoOver2)[1] <- "Group"
            train3 <- rbind.data.frame(train3, InSilicoBelow1, InSilicoOver1H, InSilicoOver1, InSilicoOver2)

            # Make an extra dataframe in the column with two classes: present and absent
            train3$Presence[train3$Abundance > 0.01] <- "Present"
            train3$Presence[train3$Abundance <= 0.01] <- "Absent"
            train3$Presence <- as.factor(train3$Presence)
            test3$Presence[test3$Abundance > 0.01] <- "Present"
            test3$Presence[test3$Abundance <= 0.01] <- "Absent"
            test3$Presence <- as.factor(test3$Presence)

            # Save the full dataframes to reload before the regression
            train3full <- train3
            test3full <- test3

            # Feature selection step
            train3Original <- train3[train3$Group == "Original",]
            train3Original <- train3Original[colnames(train3Original) != "Group"]
            train3Original <- train3Original[colnames(train3Original) != "Abundance"]
            # # Balance
            if(!summary(train3Original$Presence)[1] == summary(train3Original$Presence)[2]){train3Original <- RandOverClassif(Presence ~ ., dat = train3Original, C.perc = "balance")}
            # define the control using a random forest selection function
            control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
            # run the RFE algorithm
            results <- rfe(x = train3Original[,!names(train3Original) == "Presence"], y = train3Original$Presence, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Presence"])[2], by = 2), rfeControl = control, metric = "Accuracy")
            # plot the results
            plot(results, type = c("g", "o"))
            # Make selection
            rfeout <- results$results
            AbsoluteBest <- pickSizeBest(rfeout, metric = "Accuracy", maximize = TRUE)
            Within1Perc <- pickSizeTolerance(rfeout, metric = "Accuracy",  tol = 0.5, maximize = TRUE)
            if(results$results$Accuracy[results$results$Variables == AbsoluteBest] == 1){Within1Perc <- AbsoluteBest}
            if(Within1Perc == 1){Within1Perc <- AbsoluteBest}
            Keep <- results$optVariables[1:Within1Perc]
            KeepClassifier <- Keep
            # list the chosen features
            train3 <- train3[c("Group", Keep, "Abundance", "Presence")]
            test3 <- test3[c(Keep, "Abundance", "Presence")]

            # Make over 1 uniform
            Train3Over <- train3[train3$Abundance >= 0.01,]
            Train3Below <- train3[train3$Abundance < 0.01,]
            RangeAbundances <- range(Train3Over$Abundance)
            BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
            CutAbundances <- cut(Train3Over$Abundance, BreaksAbundances, right = FALSE)
            FrequencyAbundances <- table(CutAbundances)
            CutOff <- round(median(FrequencyAbundances))
            Subsampled <- NULL
            for (k in 1:length(FrequencyAbundances)){
              # Get samples in the kth interval
              Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
              Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
              SelectedData <- Train3Over[Train3Over$Abundance >= Lower & Train3Over$Abundance < Upper,]
              # Subsample if there are more than "cutoff"
              if (dim(SelectedData)[1] > CutOff){
                  SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                } else {
                  SelectedData <- SelectedData
                }
                # Store subsampled data
                Subsampled <- rbind(Subsampled, SelectedData)
              }
            Train3Over <- Subsampled
            # Combine with the low abundant samples
            train3 <- rbind.data.frame(Train3Over, Train3Below)

            # Temporarily remove the abundance column
            train3 <- train3[colnames(train3) != "Abundance"]
            test3 <- test3[colnames(test3) != "Abundance"]

            # Remove the "Group"-column
            train3 <- train3[colnames(train3) != "Group"]
            test3 <- test3[colnames(test3) != "Group"]

            # Balance the classes
            print(summary(train3$Presence))
            if(!summary(train3$Presence)[1] == summary(train3$Presence)[2]){train3 <- RandUnderClassif(Presence ~ ., dat = train3, C.perc = "balance", repl = FALSE)}
            print(summary(train3$Presence))

            ### Caret list
            FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Presence, k = 3, times = 1), classProbs = TRUE)

                # Create tuning grid for the RF
                    # Tune RF
                    if (dim(train3)[2]-1 > 5) {
                      mtryoptions <- seq(1, round(dim(train3[,!names(train3) == "Presence"])[2]/5), by = 1)
                    } else {
                      mtryoptions <- seq(1, dim(train3)[2]-1, by = 1)
                    }
                    tunegridRF <- expand.grid(.mtry = mtryoptions)
                    # Tune SVMPoly
                    C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                    degree <- c(1, 2, 3)
                    scale <- c(1, 2)
                    tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)

                # Train models
                model_listClassifier <- caretList(Presence ~ .,
                                        data = train3,
                                        trControl = FitControl,
                                        tuneList = list(RF = caretModelSpec(method = "rf", tuneGrid = tunegridRF, ntree = 500)))

              # Get predictions
              if(dim(test3)[2] == 2){
                testset <- as.data.frame(test3[,!names(test3) == "Presence"])
                colnames(testset) <- colnames(test3[1])
              } else {
                testset <- as.data.frame(test3[,!names(test3) == "Presence"])
              }
              ens_preds <- predict(model_listClassifier$RF, newdata = testset, type = "raw")
              ens_preds <- cbind.data.frame(ens_preds, test3$Presence)
              colnames(ens_preds) <- c("Predicted", "Real")
              rownames(ens_preds) <- rownames(test3)
              PredRFC <- ens_preds
              # Get feature importances
                  # From the model
                  ImportancesRF <- t(as.data.frame(varImp(model_listClassifier$RF)["importance"]))
                  # Features that were removed
                  RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesRF)]
                  ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                  names(ImportancesRemoved) <- RemovedFeatures
                  #
                  ImportancesClassifier <- cbind.data.frame(ImportancesRF, ImportancesRemoved)
                  ImportancesClassifier <- ImportancesClassifier[,GMMNames]
                  names(ImportancesClassifier) <- paste(names(ImportancesClassifier), "_Class", sep = "")



              ### REGRESSION ###
              # Temporarily remove the abundance column
              train3 <- train3full
              test3 <- test3full

              # Remove "Presence"-column
              train3 <- train3[colnames(train3) != "Presence"]
              test3 <- test3[colnames(test3) != "Presence"]

              # Feature selection step
              train3Original <- train3[train3$Group == "Original",]
              train3Original <- train3Original[colnames(train3Original) != "Group"]
              # more homogeneous distribution
              train3OriginalLower <- train3Original[train3Original$Abundance < 0.01,]
              train3OriginalHigher <- train3Original[train3Original$Abundance >= 0.01,]
              if(dim(train3OriginalLower)[1] > dim(train3OriginalHigher)[1]){
                train3OriginalLower <- train3OriginalLower[sample(nrow(train3OriginalLower), dim(train3OriginalHigher)[1]), ]
              }
              train3Original <- rbind.data.frame(train3OriginalLower, train3OriginalHigher)
              # define the control using a random forest selection function
              control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
              # run the RFE algorithm
              results <- rfe(x = train3Original[,!names(train3Original) == "Abundance"], y = train3Original$Abundance, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Abundance"])[2], by = 2), rfeControl = control, metric = "Rsquared")
              # plot the results
              plot(results, type = c("g", "o"))
              # Make selection
              rfeout <- results$results
              if(sum(rfeout$Rsquared == 1) == length(rfeout$Rsquared)){
                Keep <- Keep
              } else {
                Within1Perc <- pickSizeTolerance(rfeout, metric = "Rsquared",  tol = 0.5, maximize = TRUE)
                # AbsoluteBest <- pickSizeBest(rfeout, metric = "Rsquared", maximize = TRUE)
                Keep <- results$optVariables[1:Within1Perc]
              }
              # Keep <- c(Keep, KeepClassifier[!KeepClassifier %in% Keep])
              # Get the chosen features
              train3 <- train3[c("Group", Keep, "Abundance")]
              test3 <- test3[c(Keep, "Abundance")]

              # Remove the group-column
              train3 <- train3[colnames(train3) != "Group"]

              # Reduce imbalance in the dataset
              RangeAbundances <- range(train3$Abundance)
              BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
              CutAbundances <- cut(train3$Abundance, BreaksAbundances, right = FALSE)
              FrequencyAbundances <- table(CutAbundances)
              CutOff <- round(median(FrequencyAbundances))
              Subsampled <- NULL
              for (k in 1:length(FrequencyAbundances)){
                # Get samples in the kth interval
                Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
                Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
                SelectedData <- train3[train3$Abundance >= Lower & train3$Abundance < Upper,]
                # Subsample if there are more than "cutoff"
                if (dim(SelectedData)[1] > CutOff){
                  SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                } else {
                  SelectedData <- SelectedData
                }
                # Store subsampled data
                Subsampled <- rbind(Subsampled, SelectedData)
              }
              train3 <- Subsampled

              # Logit transformation --> ensure predictions are in the 0-1 range
              train3$Abundance[train3$Abundance >= 1] <- 1 - minvalue/10
              train3$Abundance[train3$Abundance <= 0] <- minvalue/10
              train3$Abundance <- boot::logit(train3$Abundance)

              ### Caret list
              FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Abundance, k = 3, times = 1), summaryFunction = mapeexpSummary)
                  # Create tuning grids
                      # Tune SVMPoly
                      C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                      degree <- c(1, 2, 3)
                      scale <- c(1, 2)
                      tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)
                      # Tune gradient boost
                      n.trees <- c(50, 100, 250, 500)
                      interaction.depth <- c(1)
                      shrinkage <- c(0.3, 0.2, 0.1, 0.05, 0.01)
                      n.minobsinnode <- seq(1, 3, by = 1)
                      tunegridGBM <- expand.grid(n.trees = n.trees, interaction.depth = interaction.depth, shrinkage = shrinkage, n.minobsinnode = n.minobsinnode)

                  # Train models
                  model_list <- caretList(Abundance ~ .,
                                        data = train3,
                                        trControl = FitControl,
                                        tuneList = list(SVMPoly = caretModelSpec(method = "svmPoly", tuneGrid = tunegridSVMPoly, metric = "Rsquared"),
                                                        GBM = caretModelSpec(method = "gbm", tuneGrid = tunegridGBM, metric = "Rsquared")))

              # make ensemble
              greedy_ensemble <- caretEnsemble(model_list, trControl = FitControl, metric = "Rsquared")

              # Make predictions
              if(dim(test3)[2] == 2){
                testset <- as.data.frame(test3[,!names(test3) == "Abundance"])
                colnames(testset) <- colnames(test3[1])
              } else {
                testset <- as.data.frame(test3[,!names(test3) == "Abundance"])
              }
              ens_preds <- predict(greedy_ensemble, newdata = testset)
              ens_preds <- cbind.data.frame(ens_preds, test3$Abundance)
              colnames(ens_preds) <- c("Predicted", "Real")
              rownames(ens_preds) <- rownames(test3)

              # Reverse the logit transform
              ens_preds$Predicted <- boot::inv.logit(ens_preds$Predicted)

              # Get feature importances
                  # From the model
                  ImportancesEnsemble <- t(as.data.frame(varImp(greedy_ensemble)["overall"]))
                  # Features that were removed
                  RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesEnsemble)]
                  ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                  names(ImportancesRemoved) <- RemovedFeatures
                  #
                  ImportancesEnsemble <- cbind.data.frame(ImportancesEnsemble, ImportancesRemoved)
                  ImportancesEnsemble <- ImportancesEnsemble[,GMMNames]
                  names(ImportancesEnsemble) <- paste(names(ImportancesEnsemble), "_Reg", sep = "")

              ### Combine predictions from the classifier and regression ###
              Predictions <- as.data.frame(matrix(, nrow = length(test3$Abundance), ncol = 2))
              colnames(Predictions) <- c("Predicted", "Real")
              Predictions$Predicted <- ens_preds$Predicted
              Predictions$Predicted[PredRFC$Predicted == "Absent"] <- 0
              Predictions$Real <- ens_preds$Real
              rownames(Predictions) <- rownames(test3)

              # # Save the predictions
              AllPredictions <- rbind(AllPredictions, cbind.data.frame(fold, Predictions))
              AllPredictionsReg <- rbind(AllPredictionsReg, cbind.data.frame(fold, ens_preds))

              # Save predictions and calculate performance metrics
                  # combine classifier, regression, total predictions
                  Combined <- cbind.data.frame(OTUOfInterest, rep, fold, PredRFC, ens_preds$Predicted, Predictions)
                  colnames(Combined) <- c("OTU", "rep", "fold", "PredictedClass", "TrueClass", "Regression", "Combined", "TrueValue")
                  Combined$TrueClass <- as.character(Combined$TrueClass)
                  Combined$PredictedClass <- as.character(Combined$PredictedClass)
                  Combined$Index <- rownames(Combined)

                  CombinedNS <- Combined[rownames(Combined) %in% NonSorted,]
                  colnames(CombinedNS) <- c("OTU", "rep", "fold", "PredictedClass", "TrueClass", "Regression", "Combined", "TrueValue", "Index")
                  # For all data
                  PerformancePerFold_ALL_IS <- rbind(PerformancePerFold_ALL_IS, cbind.data.frame(OTUOfInterest, rep, fold, RMSE(100*Combined$Combined, 100*Combined$TrueValue), MAE(100*Combined$Combined, 100*Combined$TrueValue), R2(100*Combined$Combined, 100*Combined$TrueValue), sum(Combined$PredictedClass == Combined$TrueClass)/length(Combined$TrueClass), ImportancesClassifier, ImportancesClassifier, ImportancesEnsemble))
                  PredictionsPerFold_ALL_IS <- rbind(PredictionsPerFold_ALL_IS, Combined)
                  # For only non-sorted data
                  PerformancePerFold_NS_IS <- rbind(PerformancePerFold_NS_IS, cbind.data.frame(OTUOfInterest, rep, fold, RMSE(100*CombinedNS$Combined, 100*CombinedNS$TrueValue), MAE(100*CombinedNS$Combined, 100*CombinedNS$TrueValue), R2(100*CombinedNS$Combined, 100*CombinedNS$TrueValue), sum(CombinedNS$PredictedClass == CombinedNS$TrueClass)/length(CombinedNS$TrueClass), ImportancesClassifier, ImportancesEnsemble))
                  PredictionsPerFold_NS_IS <- rbind(PredictionsPerFold_NS_IS, CombinedNS)

        }

      # Plot all predictions on the testset
        AllPredictions$Predicted <- 100*AllPredictions$Predicted
        AllPredictions$Real <- 100*AllPredictions$Real
        p_pred <- ggplot(AllPredictions, aes(x = Real, y = Predicted, fill = as.factor(fold))) +
                            geom_point(shape = 21, size = 2) +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            ggtitle(OTUOfInterest) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
        # p_pred


        AllPredictionsReg$Predicted <- 100*AllPredictionsReg$Predicted
        AllPredictionsReg$Real <- 100*AllPredictionsReg$Real
        p_predr <- ggplot(AllPredictionsReg, aes(x = Real, y = Predicted, fill = as.factor(fold))) +
                            geom_point(shape = 21, size = 2) +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            ggtitle(OTUOfInterest) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
        # p_predr

        # Plot all predictions on the non-sorted samples
        AllPredictionsNS <- AllPredictions[rownames(AllPredictions) %in% NonSorted,]
        AllPredictionsNS <- round(AllPredictionsNS)
        p_predNS <- ggplot(AllPredictionsNS, aes(x = Real, y = Predicted, fill = as.factor(fold))) +
                            geom_point(shape = 21, size = 2) +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            ggtitle(OTUOfInterest) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
        # print(p_predNS)

      # Save predictions and calculate performance metics
        PerformanceDataset_ALL_IS <- rbind(PerformanceDataset_ALL_IS, cbind.data.frame(OTUOfInterest, rep, RMSE(AllPredictions$Predicted,AllPredictions$Real), MAE(AllPredictions$Predicted,AllPredictions$Real), R2(AllPredictions$Predicted,AllPredictions$Real)))
        PerformanceDataset_NS_IS <- rbind(PerformanceDataset_NS_IS, cbind.data.frame(OTUOfInterest, rep, RMSE(AllPredictionsNS$Predicted, AllPredictionsNS$Real), MAE(AllPredictionsNS$Predicted,AllPredictionsNS$Real), R2(AllPredictionsNS$Predicted,AllPredictionsNS$Real)))

      }

  }

}

# write.csv(PerformancePerFold_ALL_IS, "Results/PerformancePerFold_ALL_1TankAsTest.csv")
# write.csv(PerformancePerFold_NS_IS, "Results/PerformancePerFold_NS_1TankAsTest.csv")
# write.csv(PredictionsPerFold_ALL_IS, "Results/PredictionsPerFold_ALL_1TankAsTest.csv")
# write.csv(PredictionsPerFold_NS_IS, "Results/PredictionsPerFold_NS_1TankAsTest.csv")
# write.csv(PerformanceDataset_ALL_IS, "Results/PerformanceDataset_ALL_1TankAsTest.csv")
# write.csv(PerformanceDataset_NS_IS, "Results/PerformanceDataset_NS_1TankAsTest.csv")
```

#### Check sensitivity to dataset size

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
PerformancePerFold_ALL_IS <- NULL
PerformancePerFold_NS_IS <- NULL
PredictionsPerFold_ALL_IS <- NULL
PredictionsPerFold_NS_IS <- NULL
PerformanceDataset_ALL_IS <- NULL
PerformanceDataset_NS_IS <- NULL

for (i in 1){

  # Select OTU of interest
  OTUOfInterest <- OTUPreprocessed$OTU[i]
  OTUAbundances <- OTUPreprocessed[OTUPreprocessed$OTU == OTUOfInterest,]
  OTUAbundances <- cbind.data.frame(names(OTUAbundances), as.numeric(paste(OTUAbundances)))[-1,]
  colnames(OTUAbundances) <- c("ID", "Abundance")

  # Combine the features and measured variables
  Dataset <- left_join(GMMOut, IdentifiersBoth, by = c("Names" = "FACS_names"))
  Dataset <- left_join(Dataset, OTUAbundances, by = c("Identifier" = "ID"))
  Dataset <- Dataset[!is.na(Dataset$Identifier),]
  rownames(Dataset) <- Dataset$Identifier
  Dataset <- Dataset[, -which(names(Dataset) %in% c("Names", "Identifier", "X1", "Population", "BacterialDensity"))]
  Dataset <- Dataset[!is.na(Dataset$Abundance),]

  if(sum(Dataset$Abundance > 0.01) > 3){ # Extra check for missing OTUs in a subset of the data

      # Centered log ratio transform
      Dataset <- cbind.data.frame(compositions::clr(Dataset[,!names(Dataset) == "Abundance"]), Dataset$Abundance)
      colnames(Dataset)[dim(Dataset)[2]] <- "Abundance"

      # Save dataset to reload it later
      DatasetFull <- Dataset

      #
      Samplesizes <- c(1, 2, 3, 4)
      for (size in Samplesizes){
        # DatasetFull <- DatasetFullComplete[sample(nrow(DatasetFullComplete), size),]
        # Model
        for (rep in 1:5){
        AllPredictions <- NULL
        AllPredictionsReg <- NULL
        ClassificationProbabilities <- NULL
        # Split data into folds
        NumberOfFolds <- 5
        Set1 <- 1
        Set2 <- 2
        Set3 <- 3
        Set4 <- 4
        Set5 <- 5
        Sets <- c("Set1", "Set2", "Set3", "Set4", "Set5")
        for (k in 1:(floor(dim(DatasetFull)[1]/NumberOfFolds)-1)){
          # Get indices
          Set1 <- c(Set1, k*NumberOfFolds)
          Set2 <- c(Set2, (k*NumberOfFolds)+1)
          Set3 <- c(Set3, (k*NumberOfFolds)+2)
          Set4 <- c(Set4, (k*NumberOfFolds)+3)
          Set5 <- c(Set5, (k*NumberOfFolds)+4)
        }
        if(max(Set5) < dim(DatasetFull)[1]){
          NUmberLeft <- dim(DatasetFull)[1] - max(Set5)
          for (l in 1:NUmberLeft){
            assign(Sets[l], c(get(Sets[l]), max(Set5) + l))
          }
        }
        if(rep %in% c(2,3)){
          NumberOfSwitches <- round(length(Set5)/3)
          for (pos in 1:NumberOfSwitches){
            Set1[rep*pos] <- Set2[rep*pos]
            Set2[rep*pos] <- Set3[rep*pos]
            Set3[rep*pos] <- Set4[rep*pos]
            Set4[rep*pos] <- Set5[rep*pos]
            Set5[rep*pos] <- Set1[rep*pos]
          }
        }
        # If one of the sets had an element less it might have generated NA
        Set1 <- Set1[!is.na(Set1)]
        Set2 <- Set2[!is.na(Set2)]
        Set3 <- Set3[!is.na(Set3)]
        Set4 <- Set4[!is.na(Set4)]
        Set5 <- Set5[!is.na(Set5)]
        # Combine in a list
        Folds <- list(Fold1 = Set1, Fold2 = Set2, Fold3 = Set3, Fold4 = Set4, Fold5 = Set5)
        # Train and evaluate
        for (fold in 1:length(Folds)){
              Dataset <- DatasetFull
              GMMNames <- colnames(Dataset)[!colnames(Dataset) == "Abundance"]

              # Selected fold
              Testindices <- Folds[[fold]]
              train3 <- Dataset[-Testindices, ]
              test3 <- Dataset[Testindices, ]

              # Make trainingset  smaller
              KeepAsTrain <- sample(nrow(train3), round((size/4)*dim(train3)[1]))
              # test3 <- rbind.data.frame(test3, train3[-KeepAsTrain,])
              train3 <- train3[KeepAsTrain,]

              # Transformation --> ensure predictions are in the 0-1 range to allow logit transformation later
              minvalue <- min(train3$Abundance[train3$Abundance > 0])

              # Get number of samples with low abundance (i.e. < 0.01) and high abundance (i.e. > 0.01)
              Below1 <- train3[train3$Abundance < 0.01,]
              Over1 <- train3[train3$Abundance >= 0.01,]

              #
              TotalNew <- 500
              NumberOfBelow1 <- dim(Below1)[1]
              NumberOfOver1 <- dim(Over1)[1]
              NumberOfOver1ToMake <- round(NumberOfBelow1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
              NumberOfBelow1ToMake <- round(NumberOfOver1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
              if(NumberOfOver1ToMake < TotalNew/2) NumberOfOver1ToMake <- TotalNew/2
              if(NumberOfBelow1ToMake < TotalNew/2) NumberOfBelow1ToMake <- TotalNew/2
              if(dim(Below1)[1] == 1){
                NumberOfBelow1ToMake <- 0
                NumberOfOver1ToMake <- TotalNew
              }

              # Max random variation (1000x smaller than the smallest value)
              RandValPredictorVals <- colMins(as.matrix(abs(train3[, !names(train3) == "Abundance"])))/100
              RandValOutput <- min(abs(train3$Abundance[train3$Abundance > 0]))/100
              RandGMMVals <- NULL
              RandAbundVals <- NULL

              # Fake zero's
              InSilicoBelow1 <- NULL
              for (j in 1:round(NumberOfBelow1ToMake*1)){
                for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
                RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
                # Select random samples
                SelectedSamples <- round(runif(2, min = 1, max = dim(Below1)[1]))
                Sample1 <- Below1[SelectedSamples[1],]
                Sample2 <- Below1[SelectedSamples[2],]
                # Random mixing proportions
                MixProps <- runif(1, min = 0, max = 1)
                # Mix
                New <- MixProps*Sample1 + (1-MixProps)*Sample2
                New <- New + c(RandGMMVals, RandAbundVals)
                # Save
                InSilicoBelow1 <- rbind.data.frame(InSilicoBelow1, New)
              }

              # Fake abundant using only abundant samples
              InSilicoOver1H <- NULL
              Over1High <- Over1[mean(Over1$Abundance) < Over1$Abundance,]
              for (j in 1:round(NumberOfOver1ToMake*(1))){
                for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
                RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
                # Select random samples
                SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
                Sample1 <- Over1High[SelectedSample1,]
                SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
                Sample2 <- Over1High[SelectedSample2,]
                # Random mixing proportions
                MixProps <- runif(1, min = 0, max = 1)
                # Mix
                New <- MixProps*Sample1 + (1-MixProps)*Sample2
                New <- New + c(RandGMMVals, RandAbundVals)
                # Save
                InSilicoOver1H <- rbind.data.frame(InSilicoOver1H, New)
              }

              # Fake abundant using only abundant samples
              InSilicoOver1 <- NULL
              for (j in 1:round(NumberOfOver1ToMake*(1/2))){
                for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
                RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
                # Select random samples
                SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
                Sample1 <- Over1[SelectedSample1,]
                SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
                Sample2 <- Over1High[SelectedSample2,]
                # Random mixing proportions
                MixProps <- runif(1, min = 0, max = 1)
                # Mix
                New <- MixProps*Sample1 + (1-MixProps)*Sample2
                New <- New + c(RandGMMVals, RandAbundVals)
                # Save
                InSilicoOver1 <- rbind.data.frame(InSilicoOver1, New)
              }

              # Fake samples mixed between low and high abundances
              InSilicoOver2 <- NULL
              for (j in 1:round(NumberOfOver1ToMake*(1/2))){
                for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
                RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
                # Select random samples
                SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
                Sample1 <- Over1[SelectedSample1,]
                SelectedSample2 <- round(runif(1, min = 1, max = dim(Below1)[1]))
                Sample2 <- Below1[SelectedSample2,]
                # Random mixing proportions
                MixProps <- runif(1, min = 0, max = 1)
                # Mix
                New <- MixProps*Sample1 + (1-MixProps)*Sample2
                New <- New + c(RandGMMVals, RandAbundVals)
                # Save
                InSilicoOver2 <- rbind.data.frame(InSilicoOver2, New)
              }

              # Combine the in sillico samples with the original data
              train3 <- cbind.data.frame("Original", train3)
              colnames(train3)[1] <- "Group"
              InSilicoBelow1 <- cbind.data.frame("InSilicoBelow1", InSilicoBelow1)
              colnames(InSilicoBelow1)[1] <- "Group"
              InSilicoOver1H <- cbind.data.frame("InSilicoOver1H", InSilicoOver1H)
              colnames(InSilicoOver1H)[1] <- "Group"
              InSilicoOver1 <- cbind.data.frame("InSilicoOver1", InSilicoOver1)
              colnames(InSilicoOver1)[1] <- "Group"
              InSilicoOver2 <- cbind.data.frame("InSilicoOver2", InSilicoOver2)
              colnames(InSilicoOver2)[1] <- "Group"
              train3 <- rbind.data.frame(train3, InSilicoBelow1, InSilicoOver1H, InSilicoOver1, InSilicoOver2)

              # Make an extra dataframe in the column with two classes: present and absent
              train3$Presence[train3$Abundance > 0.01] <- "Present"
              train3$Presence[train3$Abundance <= 0.01] <- "Absent"
              train3$Presence <- as.factor(train3$Presence)
              test3$Presence[test3$Abundance > 0.01] <- "Present"
              test3$Presence[test3$Abundance <= 0.01] <- "Absent"
              test3$Presence <- as.factor(test3$Presence)

              # Save the full dataframes to reload before the regression
              train3full <- train3
              test3full <- test3

              # Feature selection step
              train3Original <- train3[train3$Group == "Original",]
              train3Original <- train3Original[colnames(train3Original) != "Group"]
              train3Original <- train3Original[colnames(train3Original) != "Abundance"]
              # # Balance
              if(!summary(train3Original$Presence)[1] == summary(train3Original$Presence)[2]){train3Original <- RandOverClassif(Presence ~ ., dat = train3Original, C.perc = "balance")}
              # define the control using a random forest selection function
              control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
              # run the RFE algorithm
              results <- rfe(x = train3Original[,!names(train3Original) == "Presence"], y = train3Original$Presence, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Presence"])[2], by = 2), rfeControl = control, metric = "Accuracy")
              # plot the results
              plot(results, type = c("g", "o"))
              # Make selection
              rfeout <- results$results
              AbsoluteBest <- pickSizeBest(rfeout, metric = "Accuracy", maximize = TRUE)
              Within1Perc <- pickSizeTolerance(rfeout, metric = "Accuracy",  tol = 0.5, maximize = TRUE)
              if(results$results$Accuracy[results$results$Variables == AbsoluteBest] == 1){Within1Perc <- AbsoluteBest}
              if(Within1Perc == 1){Within1Perc <- AbsoluteBest}
              Keep <- results$optVariables[1:Within1Perc]
              KeepClassifier <- Keep
              # list the chosen features
              train3 <- train3[c("Group", Keep, "Abundance", "Presence")]
              test3 <- test3[c(Keep, "Abundance", "Presence")]

              # Make over 1 uniform
              Train3Over <- train3[train3$Abundance >= 0.01,]
              Train3Below <- train3[train3$Abundance < 0.01,]
              RangeAbundances <- range(Train3Over$Abundance)
              BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
              CutAbundances <- cut(Train3Over$Abundance, BreaksAbundances, right = FALSE)
              FrequencyAbundances <- table(CutAbundances)
              CutOff <- round(median(FrequencyAbundances))
              Subsampled <- NULL
              for (k in 1:length(FrequencyAbundances)){
                # Get samples in the kth interval
                Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
                Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
                SelectedData <- Train3Over[Train3Over$Abundance >= Lower & Train3Over$Abundance < Upper,]
                # Subsample if there are more than "cutoff"
                if (dim(SelectedData)[1] > CutOff){
                    SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                  } else {
                    SelectedData <- SelectedData
                  }
                  # Store subsampled data
                  Subsampled <- rbind(Subsampled, SelectedData)
                }
              Train3Over <- Subsampled
              # Combine with the low abundant samples
              train3 <- rbind.data.frame(Train3Over, Train3Below)

              # Temporarily remove the abundance column
              train3 <- train3[colnames(train3) != "Abundance"]
              test3 <- test3[colnames(test3) != "Abundance"]

              # Remove the "Group"-column
              train3 <- train3[colnames(train3) != "Group"]
              test3 <- test3[colnames(test3) != "Group"]

              # Balance the classes
              print(summary(train3$Presence))
              if(!summary(train3$Presence)[1] == summary(train3$Presence)[2]){train3 <- RandUnderClassif(Presence ~ ., dat = train3, C.perc = "balance", repl = FALSE)}
              print(summary(train3$Presence))

              ### Caret list
              FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Presence, k = 3, times = 1), classProbs = TRUE)

                  # Create tuning grid for the RF
                      # Tune RF
                      if (dim(train3)[2]-1 > 5) {
                        mtryoptions <- seq(1, round(dim(train3[,!names(train3) == "Presence"])[2]/5), by = 1)
                      } else {
                        mtryoptions <- seq(1, dim(train3)[2]-1, by = 1)
                      }
                      tunegridRF <- expand.grid(.mtry = mtryoptions)
                      # Tune SVMPoly
                      C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                      degree <- c(1, 2, 3)
                      scale <- c(1, 2)
                      tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)

                  # Train models
                  model_listClassifier <- caretList(Presence ~ .,
                                          data = train3,
                                          trControl = FitControl,
                                          tuneList = list(RF = caretModelSpec(method = "rf", tuneGrid = tunegridRF, ntree = 500)))

           
              # Get predictions
              if(dim(test3)[2] == 2){
                testset <- as.data.frame(test3[,!names(test3) == "Presence"])
                colnames(testset) <- colnames(test3[1])
              } else {
                testset <- as.data.frame(test3[,!names(test3) == "Presence"])
              }
              ens_preds <- predict(model_listClassifier$RF, newdata = testset, type = "raw")
              ens_preds <- cbind.data.frame(ens_preds, test3$Presence)
              colnames(ens_preds) <- c("Predicted", "Real")
              rownames(ens_preds) <- rownames(test3)
              PredRFC <- ens_preds

              # Compute and save prediction probabilities
              ClassProb <- predict(model_listClassifier$RF, newdata = testset, type = "prob")
              ClassificationProbabilities <- rbind.data.frame(ClassificationProbabilities, cbind.data.frame(as.numeric(test3$Presence == "Absent"), ClassProb["Absent"]))
              # ROC <- roc(as.numeric(test3$Presence == "Absent"), ClassProbs$Absent)
              # AUC <- auc(ROC)
              # print(AUC[1])
              
              
              # Get feature importances
                  # From the model
                  ImportancesRF <- t(as.data.frame(varImp(model_listClassifier$RF)["importance"]))
                  # Features that were removed
                  RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesRF)]
                  ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                  names(ImportancesRemoved) <- RemovedFeatures
                  #
                  ImportancesClassifier <- cbind.data.frame(ImportancesRF, ImportancesRemoved)
                  ImportancesClassifier <- ImportancesClassifier[,GMMNames]
                  names(ImportancesClassifier) <- paste(names(ImportancesClassifier), "_Class", sep = "")



                ### REGRESSION ###
                # Temporarily remove the abundance column
                train3 <- train3full
                test3 <- test3full

                # Remove "Presence"-column
                train3 <- train3[colnames(train3) != "Presence"]
                test3 <- test3[colnames(test3) != "Presence"]

                # Feature selection step
                train3Original <- train3[train3$Group == "Original",]
                train3Original <- train3Original[colnames(train3Original) != "Group"]
                # more homogeneous distribution
                train3OriginalLower <- train3Original[train3Original$Abundance < 0.01,]
                train3OriginalHigher <- train3Original[train3Original$Abundance >= 0.01,]
                if(dim(train3OriginalLower)[1] > dim(train3OriginalHigher)[1]){
                  train3OriginalLower <- train3OriginalLower[sample(nrow(train3OriginalLower), dim(train3OriginalHigher)[1]), ]
                }
                train3Original <- rbind.data.frame(train3OriginalLower, train3OriginalHigher)
                # define the control using a random forest selection function
                control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
                # run the RFE algorithm
                results <- rfe(x = train3Original[,!names(train3Original) == "Abundance"], y = train3Original$Abundance, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Abundance"])[2], by = 2), rfeControl = control, metric = "Rsquared")
                # plot the results
                plot(results, type = c("g", "o"))
                # Make selection
                rfeout <- results$results
                if(sum(rfeout$Rsquared == 1) == length(rfeout$Rsquared)){
                  Keep <- Keep
                } else {
                  Within1Perc <- pickSizeTolerance(rfeout, metric = "Rsquared",  tol = 0.5, maximize = TRUE)
                  # AbsoluteBest <- pickSizeBest(rfeout, metric = "Rsquared", maximize = TRUE)
                  Keep <- results$optVariables[1:Within1Perc]
                }
                # Keep <- c(Keep, KeepClassifier[!KeepClassifier %in% Keep])
                # Get the chosen features
                train3 <- train3[c("Group", Keep, "Abundance")]
                test3 <- test3[c(Keep, "Abundance")]

                # Remove the group-column
                train3 <- train3[colnames(train3) != "Group"]

                # Reduce imbalance in the dataset
                RangeAbundances <- range(train3$Abundance)
                BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
                CutAbundances <- cut(train3$Abundance, BreaksAbundances, right = FALSE)
                FrequencyAbundances <- table(CutAbundances)
                CutOff <- round(median(FrequencyAbundances))
                Subsampled <- NULL
                for (k in 1:length(FrequencyAbundances)){
                  # Get samples in the kth interval
                  Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
                  Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
                  SelectedData <- train3[train3$Abundance >= Lower & train3$Abundance < Upper,]
                  # Subsample if there are more than "cutoff"
                  if (dim(SelectedData)[1] > CutOff){
                    SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                  } else {
                    SelectedData <- SelectedData
                  }
                  # Store subsampled data
                  Subsampled <- rbind(Subsampled, SelectedData)
                }
                train3 <- Subsampled

                # Logit transformation --> ensure predictions are in the 0-1 range
                train3$Abundance[train3$Abundance >= 1] <- 1 - minvalue/10
                train3$Abundance[train3$Abundance <= 0] <- minvalue/10
                train3$Abundance <- boot::logit(train3$Abundance)

                ### Caret list
                FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Abundance, k = 3, times = 1), summaryFunction = mapeexpSummary)
                    # Create tuning grids
                        # Tune SVMPoly
                        C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                        degree <- c(1, 2, 3)
                        scale <- c(1, 2)
                        tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)
                        # Tune gradient boost
                        n.trees <- c(50, 100, 250, 500)
                        interaction.depth <- c(1)
                        shrinkage <- c(0.3, 0.2, 0.1, 0.05, 0.01)
                        n.minobsinnode <- seq(1, 3, by = 1)
                        tunegridGBM <- expand.grid(n.trees = n.trees, interaction.depth = interaction.depth, shrinkage = shrinkage, n.minobsinnode = n.minobsinnode)

                    # Train models
                    model_list <- caretList(Abundance ~ .,
                                          data = train3,
                                          trControl = FitControl,
                                          tuneList = list(SVMPoly = caretModelSpec(method = "svmPoly", tuneGrid = tunegridSVMPoly, metric = "Rsquared"),
                                                          GBM = caretModelSpec(method = "gbm", tuneGrid = tunegridGBM, metric = "Rsquared")))

                # make ensemble
                greedy_ensemble <- caretEnsemble(model_list, trControl = FitControl, metric = "Rsquared")

                # Make predictions
                if(dim(test3)[2] == 2){
                  testset <- as.data.frame(test3[,!names(test3) == "Abundance"])
                  colnames(testset) <- colnames(test3[1])
                } else {
                  testset <- as.data.frame(test3[,!names(test3) == "Abundance"])
                }
                ens_preds <- predict(greedy_ensemble, newdata = testset)
                ens_preds <- cbind.data.frame(ens_preds, test3$Abundance)
                colnames(ens_preds) <- c("Predicted", "Real")
                rownames(ens_preds) <- rownames(test3)

                # Reverse the logit transform
                ens_preds$Predicted <- boot::inv.logit(ens_preds$Predicted)

                # Get feature importances
                    # From the model
                    ImportancesEnsemble <- t(as.data.frame(varImp(greedy_ensemble)["overall"]))
                    # Features that were removed
                    RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesEnsemble)]
                    ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                    names(ImportancesRemoved) <- RemovedFeatures
                    #
                    ImportancesEnsemble <- cbind.data.frame(ImportancesEnsemble, ImportancesRemoved)
                    ImportancesEnsemble <- ImportancesEnsemble[,GMMNames]
                    names(ImportancesEnsemble) <- paste(names(ImportancesEnsemble), "_Reg", sep = "")

                ### Combine predictions from the classifier and regression ###
                Predictions <- as.data.frame(matrix(, nrow = length(test3$Abundance), ncol = 2))
                colnames(Predictions) <- c("Predicted", "Real")
                Predictions$Predicted <- ens_preds$Predicted
                Predictions$Predicted[PredRFC$Predicted == "Absent"] <- 0
                Predictions$Real <- ens_preds$Real
                rownames(Predictions) <- rownames(test3)

                # # Save the predictions
                AllPredictions <- rbind(AllPredictions, cbind.data.frame(fold, Predictions))
                AllPredictionsReg <- rbind(AllPredictionsReg, cbind.data.frame(fold, ens_preds))

                # Save predictions and calculate performance metrics
                    # combine classifier, regression, total predictions
                    Combined <- cbind.data.frame(OTUOfInterest, rep, fold, PredRFC, ens_preds$Predicted, Predictions)
                    colnames(Combined) <- c("OTU", "rep", "fold", "PredictedClass", "TrueClass", "Regression", "Combined", "TrueValue")
                    Combined$TrueClass <- as.character(Combined$TrueClass)
                    Combined$PredictedClass <- as.character(Combined$PredictedClass)
                    Combined$Index <- rownames(Combined)

                    CombinedNS <- Combined[rownames(Combined) %in% NonSorted,]
                    colnames(CombinedNS) <- c("OTU", "rep", "fold", "PredictedClass", "TrueClass", "Regression", "Combined", "TrueValue", "Index")
                    # For all data
                    PerformancePerFold_ALL_IS <- rbind(PerformancePerFold_ALL_IS, cbind.data.frame(OTUOfInterest, size, rep, fold, RMSE(100*Combined$Combined, 100*Combined$TrueValue), MAE(100*Combined$Combined, 100*Combined$TrueValue), R2(100*Combined$Combined, 100*Combined$TrueValue), sum(Combined$PredictedClass == Combined$TrueClass)/length(Combined$TrueClass), ImportancesClassifier, ImportancesClassifier, ImportancesEnsemble))
                    PredictionsPerFold_ALL_IS <- rbind(PredictionsPerFold_ALL_IS, Combined)
                    # For only non-sorted data
                    PerformancePerFold_NS_IS <- rbind(PerformancePerFold_NS_IS, cbind.data.frame(OTUOfInterest, size, rep, fold, RMSE(100*CombinedNS$Combined, 100*CombinedNS$TrueValue), MAE(100*CombinedNS$Combined, 100*CombinedNS$TrueValue), R2(100*CombinedNS$Combined, 100*CombinedNS$TrueValue), sum(CombinedNS$PredictedClass == CombinedNS$TrueClass)/length(CombinedNS$TrueClass), ImportancesClassifier, ImportancesEnsemble))
                    PredictionsPerFold_NS_IS <- rbind(PredictionsPerFold_NS_IS, CombinedNS)

          }

        # Plot all predictions on the testset
          AllPredictions$Predicted <- 100*AllPredictions$Predicted
          AllPredictions$Real <- 100*AllPredictions$Real
          p_pred <- ggplot(AllPredictions, aes(x = Real, y = Predicted, fill = as.factor(fold))) +
                              geom_point(shape = 21, size = 2) +
                              geom_abline(intercept = 0, slope = 1) +
                              coord_fixed() +
                              scale_y_continuous(limits = c(0, 100)) +
                              scale_x_continuous(limits = c(0, 100)) +
                              ggtitle(OTUOfInterest) +
                              labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                              theme_cowplot() +
                              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
          p_pred


          AllPredictionsReg$Predicted <- 100*AllPredictionsReg$Predicted
          AllPredictionsReg$Real <- 100*AllPredictionsReg$Real
          p_predr <- ggplot(AllPredictionsReg, aes(x = Real, y = Predicted, fill = as.factor(fold))) +
                              geom_point(shape = 21, size = 2) +
                              geom_abline(intercept = 0, slope = 1) +
                              coord_fixed() +
                              scale_y_continuous(limits = c(0, 100)) +
                              scale_x_continuous(limits = c(0, 100)) +
                              ggtitle(OTUOfInterest) +
                              labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                              theme_cowplot() +
                              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
          p_predr

          # Plot all predictions on the non-sorted samples
          AllPredictionsNS <- AllPredictions[rownames(AllPredictions) %in% NonSorted,]
          AllPredictionsNS <- round(AllPredictionsNS)
          p_predNS <- ggplot(AllPredictionsNS, aes(x = Real, y = Predicted, fill = as.factor(fold))) +
                              geom_point(shape = 21, size = 2) +
                              geom_abline(intercept = 0, slope = 1) +
                              coord_fixed() +
                              scale_y_continuous(limits = c(0, 100)) +
                              scale_x_continuous(limits = c(0, 100)) +
                              ggtitle(OTUOfInterest) +
                              labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                              theme_cowplot() +
                              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
          print(p_predNS)
        
        # Calculate AUC
        colnames(ClassificationProbabilities) <- c("True", "Probs")
        ROC_ALL <- roc(ClassificationProbabilities$True, ClassificationProbabilities$Probs)
        AUC_ALL <- print(auc(ROC_ALL)[1])
        
        ClassificationProbabilitiesNS <- ClassificationProbabilities[rownames(ClassificationProbabilities) %in% NonSorted,]
        if (length(unique(ClassificationProbabilitiesNS$True)) > 1){
            ROC_NS <- roc(ClassificationProbabilitiesNS$True, ClassificationProbabilitiesNS$Probs)
            AUC_NS <- print(auc(ROC_NS)[1])
        } else {
            AUC_NS <- NA
        }
        

        # Save predictions and calculate performance metics
        PerformanceDataset_ALL_IS <- rbind(PerformanceDataset_ALL_IS, cbind.data.frame(OTUOfInterest, rep, RMSE(AllPredictions$Predicted,AllPredictions$Real), MAE(AllPredictions$Predicted,AllPredictions$Real), R2(AllPredictions$Predicted,AllPredictions$Real), AUC_ALL))
        PerformanceDataset_NS_IS <- rbind(PerformanceDataset_NS_IS, cbind.data.frame(OTUOfInterest, rep, RMSE(AllPredictionsNS$Predicted, AllPredictionsNS$Real), MAE(AllPredictionsNS$Predicted,AllPredictionsNS$Real), R2(AllPredictionsNS$Predicted,AllPredictionsNS$Real), AUC_NS))

      }
    }

  }

}
#
# write.csv(PerformancePerFold_ALL_IS, "Results/PerformancePerFold_ALL_IS_NrOfSamples_OTU1.csv")
# write.csv(PerformancePerFold_NS_IS, "Results/PerformancePerFold_NS_IS_NrOfSamples_OTU1.csv")
# write.csv(PredictionsPerFold_ALL_IS, "Results/PredictionsPerFold_ALL_IS_NrOfSamples_OTU1.csv")
# write.csv(PredictionsPerFold_NS_IS, "Results/PredictionsPerFold_NS_IST_NrOfSamples_OTU1.csv")
# write.csv(PerformanceDataset_ALL_IS, "Results/PerformanceDataset_ALL_IS_NrOfSamples_OTU1.csv")
# write.csv(PerformanceDataset_NS_IS, "Results/PerformanceDataset_NS_IS_NrOfSamples_OTU1.csv")
```

### Plot results

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Upload results
PredictionsPerFold <- read.csv("Results/PredictionsPerFold_NS.csv")
```

#### Regression

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Calculate false positive and false negative rates
shared.t.ns.rel <- sweep(shared.t.ns, 2, colSums(shared.t.ns), `/`)
shared.t.ns.rel <- shared.t.ns.rel[NonSorted]
Results <- NULL
for (i in unique(PredictionsPerFold$OTU)){
  for (j in unique(PredictionsPerFold$rep)){
    # Select the predictions from this repeat of the selected fold
    SelectedSet <- PredictionsPerFold[PredictionsPerFold$OTU == i & PredictionsPerFold$rep == j,]
    # R2
    R2_Regression <- R2(SelectedSet$Regression, SelectedSet$TrueValue)
    R2_Final <- R2(SelectedSet$Combined, SelectedSet$TrueValue)
    # MAE
    MAE_Regression <- MAE(SelectedSet$Regression, SelectedSet$TrueValue)
    MAE_Final <- MAE(SelectedSet$Combined, SelectedSet$TrueValue)
    nMAE_Regression <- MAE(SelectedSet$Regression, SelectedSet$TrueValue)/mean(as.matrix(shared.t.ns.rel[i,]))
    nMAE_Final <- MAE(SelectedSet$Combined, SelectedSet$TrueValue)/mean(as.matrix(shared.t.ns.rel[i,]))
    # False positive and negative before imposing classifier
    FPBefore <- dim(SelectedSet[SelectedSet$TrueClass == "Absent" & SelectedSet$Regression >= 0.01,])[1]
    FNBefore <- dim(SelectedSet[SelectedSet$TrueClass == "Present" & SelectedSet$Regression < 0.01,])[1]
    # False positive and negative after imposing classifier
    FPAfter <- dim(SelectedSet[SelectedSet$TrueClass == "Absent" & SelectedSet$Combined >= 0.01,])[1]
    FNAfter <- dim(SelectedSet[SelectedSet$TrueClass == "Present" & SelectedSet$Combined < 0.01,])[1]
    # Add absolute abundances
    SelectedSet$Index <- as.character(SelectedSet$Index)
    SelectedSet <- left_join(SelectedSet, Subsetphyseqobj[c("OTU", "Sample", "BacterialDensity")], by = c("OTU" = "OTU", "Index" = "Sample"))
    SelectedSet$CombinedAbsolute <- SelectedSet$Combined*SelectedSet$BacterialDensity
    SelectedSet$TrueValueAbsolute <- SelectedSet$TrueValue*SelectedSet$BacterialDensity
    R2_Final_Absolute <- R2(SelectedSet$CombinedAbsolute, SelectedSet$TrueValueAbsolute)
    # Save results
    Results <- rbind.data.frame(Results, cbind.data.frame(i, j, R2_Regression, R2_Final, MAE_Regression, MAE_Final, nMAE_Regression, nMAE_Final, FPBefore, FNBefore, FPAfter, FNAfter, R2_Final_Absolute))
  }
}
colnames(Results)[1:2] <- c("OTU", "rep")
Results <- Results[complete.cases(Results),]
Results <- melt(Results, id.vars = c("OTU", "rep"))
Results2 <- Results

# Sort the dataframe according to average performance
MeanRegressionPerformance <- Results %>% group_by(OTU, variable) %>% summarise_at(.vars = names(.)[4], .funs = c(mean = "mean", sd = "sd"))
Results <- left_join(Results, MeanRegressionPerformance, by = c("OTU", "variable"))
ResultsRegression <- Results %>% dplyr::filter(variable %in% c("R2_Final", "R2_Regression"))
taxonomy.np.ns$OTU <- rownames(taxonomy.np.ns)
ResultsRegression <- left_join(ResultsRegression, taxonomy.np.ns, by = c("OTU"))
ResultsRegression$Label <- paste(ResultsRegression$OTU, " (", ResultsRegression$Genus, ")", sep = "")
ResultsRegression <- ResultsRegression[order(-ResultsRegression$mean),] 
ResultsRegression$Label <- factor(ResultsRegression$Label, levels = unique(ResultsRegression$Label))

# Plot R2 values
p_R2_stat <- ResultsRegression %>%
              dplyr::filter(variable %in% c("R2_Final")) %>%
              ggplot(data = ., aes(x = Label, y = value, fill = variable)) +
              geom_errorbar(aes(x = Label, ymin = mean, ymax = mean), color = "#6c72dd", width = 0.8) +
              geom_point(shape = 21, fill = "#6c72dd") +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
              guides(color = FALSE, fill = FALSE) + 
              labs(color = "", y = expression(paste("R"^"2")), x = "") +
              scale_y_continuous(limits = c(0, 1))
print(p_R2_stat)
png("Figures/AQUACULTURE-FinalR2.png", width = 9, height = 6, res = 500, units = "in")
print(p_R2_stat)
dev.off()

p_R2 <- ResultsRegression %>%
              dplyr::filter(variable %in% c("R2_Regression", "R2_Final")) %>%
              ggplot(data = ., aes(x = Label, y = value, fill = variable)) +
              geom_errorbar(aes(x = Label, ymin = mean, ymax = mean, color = variable), width = 0.8, size = 1) +
              geom_point(shape = 21) +
              scale_fill_manual("",values = c("#6c72dd", "#4fb783"), labels = c("Regression alone", "Final model")) +
              scale_color_manual("",values = c("#6c72dd", "#4fb783")) +
              scale_y_continuous(breaks = seq(0, 1, by = 0.25), limits = c(0, 1)) +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 1.5), "cm"), legend.position = "top", legend.justification = "center", legend.text = element_text(size = 12)) +
              guides(color = FALSE, fill = guide_legend(override.aes = list(size = 3))) + 
              labs(color = "", y = expression(paste("R"^"2")), x = "") 
p_R2
png("Figures/AQUACULTURE-Final-VS-RegressionAlone.png", width = 11, height = 8, res = 500, units = "in")
print(p_R2)
dev.off()

# Min, max and mean
min(ResultsRegression$mean[ResultsRegression$variable == "R2_Regression"])
max(ResultsRegression$mean[ResultsRegression$variable == "R2_Regression"])
mean(ResultsRegression$mean[ResultsRegression$variable == "R2_Regression"])
sd(ResultsRegression$mean[ResultsRegression$variable == "R2_Regression"])
min(ResultsRegression$mean[ResultsRegression$variable == "R2_Final"])
max(ResultsRegression$mean[ResultsRegression$variable == "R2_Final"])
mean(ResultsRegression$mean[ResultsRegression$variable == "R2_Final"])
sd(ResultsRegression$mean[ResultsRegression$variable == "R2_Final"])


# False positive and negative
# Before
FPBefore <- Results2[Results2$variable == "FPBefore",]
FNBefore <- Results2[Results2$variable == "FNBefore",]
FPBefore <- FPBefore %>% group_by(OTU) %>% summarise_at(.vars = names(.)[4], .funs = c(mean = "mean", sd = "sd"))
FNBefore <- FNBefore %>% group_by(OTU) %>% summarise_at(.vars = names(.)[4], .funs = c(mean = "mean", sd = "sd"))
Before <- left_join(FPBefore, FNBefore, by = c("OTU"))
colnames(Before) <- c("OTU", "meanFP_Before", "sdFP_Before", "meanFN_Before", "sdFNv")
# After
FPAfter <- Results2[Results2$variable == "FPAfter",]
FNAfter <- Results2[Results2$variable == "FNAfter",]
FPAfter <- FPAfter %>% group_by(OTU) %>% summarise_at(.vars = names(.)[4], .funs = c(mean = "mean", sd = "sd"))
FNAfter <- FNAfter %>% group_by(OTU) %>% summarise_at(.vars = names(.)[4], .funs = c(mean = "mean", sd = "sd"))
After <- left_join(FPAfter, FNAfter, by = c("OTU"))
colnames(After) <- c("OTU", "meanFP_After", "sdFP_After", "meanFN_After", "sdFN_After")
# Combine
BeforeAfter <- left_join(Before, After, by = c("OTU"))
# Average before
min(BeforeAfter$meanFP_Before)
max(BeforeAfter$meanFP_Before)
mean(BeforeAfter$meanFP_Before)
sd(BeforeAfter$meanFP_Before)
min(BeforeAfter$meanFP_After)
max(BeforeAfter$meanFP_After)
mean(BeforeAfter$meanFP_After)
sd(BeforeAfter$meanFP_After)

min(BeforeAfter$meanFN_Before)
max(BeforeAfter$meanFN_Before)
mean(BeforeAfter$meanFN_Before)
sd(BeforeAfter$meanFN_Before)
min(BeforeAfter$meanFN_After)
max(BeforeAfter$meanFN_After)
mean(BeforeAfter$meanFN_After)
sd(BeforeAfter$meanFN_After)


# Plot MAE values
MeanRegressionPerformanceMAE <- Results2 %>% group_by(OTU, variable) %>% summarise_at(.vars = names(.)[4], .funs = c(mean = "mean", sd = "sd"))
MeanRegressionPerformanceMAE <- left_join(Results2, MeanRegressionPerformanceMAE, by = c("OTU", "variable"))
MeanRegressionPerformanceMAE <- MeanRegressionPerformanceMAE %>% dplyr::filter(variable %in% c("MAE_Final", "MAE_Regression", "nMAE_Final", "nMAE_Regression"))
taxonomy.np.ns$OTU <- rownames(taxonomy.np.ns)
MeanRegressionPerformanceMAE <- left_join(MeanRegressionPerformanceMAE, taxonomy.np.ns, by = c("OTU"))
MeanRegressionPerformanceMAE$Label <- paste(MeanRegressionPerformanceMAE$OTU, " (", MeanRegressionPerformanceMAE$Genus, ")", sep = "")
MeanRegressionPerformanceMAE$Label <- factor(MeanRegressionPerformanceMAE$Label, levels =  levels(ResultsRegression$Label))

p_MAE <- MeanRegressionPerformanceMAE %>%
              dplyr::filter(variable %in% c("MAE_Final", "MAE_Regression")) %>%
              ggplot(data = ., aes(x = Label, y = 100*value, fill = variable)) +
              geom_errorbar(aes(x = Label, ymin = 100*mean, ymax = 100*mean, color = variable), width = 0.8, size = 1) +
              geom_point(shape = 21) +
              scale_fill_manual("", values = c("#6c72dd", "#4fb783"), labels = c("Model performance", "Final pipeline performance")) +
              scale_color_manual("", values = c("#6c72dd", "#4fb783")) +
              scale_y_continuous(breaks = seq(0, 10, by = 2.5)) +
              guides(fill = guide_legend(override.aes = list(size = 5))) + 
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm"), legend.position = "bottom", legend.justification = "center", legend.text = element_text(size = 14)) +
              guides(color = FALSE, fill = guide_legend(override.aes = list(size = 3))) + 
              labs(color = "", y = "MAE", x = "")
print(p_MAE)

# Stat
100*mean(MeanRegressionPerformanceMAE$value[MeanRegressionPerformanceMAE$variable == "MAE_Regression"])
100*sd(MeanRegressionPerformanceMAE$value[MeanRegressionPerformanceMAE$variable == "MAE_Regression"])
100*min(MeanRegressionPerformanceMAE$value[MeanRegressionPerformanceMAE$variable == "MAE_Regression"])
100*max(MeanRegressionPerformanceMAE$value[MeanRegressionPerformanceMAE$variable == "MAE_Regression"])
100*mean(MeanRegressionPerformanceMAE$value[MeanRegressionPerformanceMAE$variable == "MAE_Final"])
100*sd(MeanRegressionPerformanceMAE$value[MeanRegressionPerformanceMAE$variable == "MAE_Final"])
100*min(MeanRegressionPerformanceMAE$value[MeanRegressionPerformanceMAE$variable == "MAE_Final"])
100*max(MeanRegressionPerformanceMAE$value[MeanRegressionPerformanceMAE$variable == "MAE_Final"])
```

#### Classifier

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Calculate false positive and false negative rates
Results <- NULL
for (i in unique(PredictionsPerFold$OTU)){
  for (j in unique(PredictionsPerFold$rep)){
    # Select the predictions from this repeat of the selected fold
    SelectedSet <- PredictionsPerFold[PredictionsPerFold$OTU == i & PredictionsPerFold$rep == j,]
    SelectedSet$CombinedClass <- "Absent"
    SelectedSet$CombinedClass[SelectedSet$Combined > 0.01] <- "Present"
    # Accuracy
    Accuracy_Classifier <- sum(SelectedSet$PredictedClass == SelectedSet$TrueClass)/length(SelectedSet$TrueClass)
    Accuracy_Final <- sum(SelectedSet$CombinedClass == SelectedSet$TrueClass)/length(SelectedSet$TrueClass)
    # False positive: Negatives with positive outcome/All negatives 
    NrFalsePositive <- length(SelectedSet$X[SelectedSet$TrueClass == "Absent" & SelectedSet$PredictedClass == "Present"])
    NrTotalTrueAbsent <- length(SelectedSet$X[SelectedSet$TrueClass == "Absent"])
    FalsePositiveRate <- NrFalsePositive/NrTotalTrueAbsent
    # False negative
    NrFalseNegative <- length(SelectedSet$X[SelectedSet$TrueClass == "Present" & SelectedSet$PredictedClass == "Absent"])
    NrTotalTruePresent <- length(SelectedSet$X[SelectedSet$TrueClass == "Present"])
    FalseNegativeRate <- NrFalseNegative/NrTotalTruePresent
    # Save results
    Results <- rbind.data.frame(Results, cbind.data.frame(i, j, Accuracy_Classifier, Accuracy_Final, NrFalsePositive, NrFalseNegative, FalsePositiveRate, FalseNegativeRate))
  }
}
colnames(Results)[1:2] <- c("OTU", "rep")
Results <- Results[complete.cases(Results),]
Results <- melt(Results, id.vars = c("OTU", "rep"))


# Sort the dataframe according to average performance
MeanClassifierFPFN <- Results %>% group_by(OTU, variable) %>% summarise_at(.vars = names(.)[4],.funs = c(mean = "mean", sd = "sd"))
MeanClassifierFPFN <- left_join(Results, MeanClassifierFPFN, by = c("OTU", "variable"))
MeanClassifierFPFN <- MeanClassifierFPFN %>% dplyr::filter(variable %in% c("NrFalsePositive", "NrFalseNegative"))
taxonomy.np.ns$OTU <- rownames(taxonomy.np.ns)
MeanClassifierFPFN <- left_join(MeanClassifierFPFN, taxonomy.np.ns, by = c("OTU"))
MeanClassifierFPFN$Label <- paste(MeanClassifierFPFN$OTU, " (", MeanClassifierFPFN$Genus, ")", sep = "")


# Split for more clear visualisation
p_FPFN1 <- MeanClassifierFPFN %>% 
              dplyr::filter(variable %in% c("NrFalsePositive", "NrFalseNegative")) %>%
              dplyr::filter(OTU %in% unique(MeanClassifierFPFN$OTU)[1:15]) %>%
              ggplot(data = ., aes(x = OTU, y = value, fill = variable)) +
              geom_errorbar(aes(x = OTU, ymin = mean, ymax = mean, color = variable), size = 1, width = 0.5) +
              geom_point(shape = 21, alpha = 1) +
              stat_compare_means(tip.length = 0.01,
                                 method = "wilcox.test",
                                 label = "p.format",
                                 size = 3) +
              scale_fill_manual("",values = c("#434982", "#4fb783"), labels = c("False positive", "False negative")) + 
              scale_color_manual("",values = c("#434982", "#4fb783")) +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), legend.justification = "center",  legend.position = "top", strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
              guides(color = FALSE, fill = guide_legend(override.aes = list(size = 4))) + 
              labs(color = "", y = "Nr. of samples", x = "") +
              scale_y_continuous(limits = c(0, 25))
p_FPFN2 <- MeanClassifierFPFN %>% 
              dplyr::filter(variable %in% c("NrFalsePositive", "NrFalseNegative")) %>%
              dplyr::filter(OTU %in% unique(MeanClassifierFPFN$OTU)[16:30]) %>%
              ggplot(data = ., aes(x = OTU, y = value, fill = variable)) +
              geom_errorbar(aes(x = OTU, ymin = mean, ymax = mean, color = variable), size = 1, width = 0.5) +
              geom_point(shape = 21, alpha = 1) +
              stat_compare_means(tip.length = 0.01,
                                 method = "wilcox.test",
                                 label = "p.format",
                                 size = 3) +
              scale_fill_manual("",values = c("#434982", "#4fb783"), labels = c("False positive", "False negative")) + 
              scale_color_manual("",values = c("#434982", "#4fb783")) +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
              guides(color = FALSE, fill = FALSE) + 
              labs(color = "", y = "Nr. of samples", x = "") +
              scale_y_continuous(limits = c(0, 25))
p_FPFN3 <- MeanClassifierFPFN %>% 
              dplyr::filter(variable %in% c("NrFalsePositive", "NrFalseNegative")) %>%
              dplyr::filter(OTU %in% unique(MeanClassifierFPFN$OTU)[31:50]) %>%
              ggplot(data = ., aes(x = OTU, y = value, fill = variable)) +
              geom_errorbar(aes(x = OTU, ymin = mean, ymax = mean, color = variable), size = 1, width = 0.5) +
              geom_point(shape = 21, alpha = 1) +
              stat_compare_means(tip.length = 0.01,
                                 method = "wilcox.test",
                                 label = "p.format",
                                 size = 3) +
              scale_fill_manual("",values = c("#434982", "#4fb783"), labels = c("False positive", "False negative")) + 
              scale_color_manual("",values = c("#434982", "#4fb783")) +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
              guides(color = FALSE, fill = FALSE) + 
              labs(color = "", y = "Nr. of samples", x = "") +
              scale_y_continuous(limits = c(0, 25))

g1 <- plot_grid(p_FPFN1, p_FPFN2, p_FPFN3, ncol = 1, nrow = 3, scale = 0.95)
g1
ggsave(file = "Figures/AQUACULTURE-FPFN.png", width = 10, height = 12, dpi = 300, units = "in", g1)


# Plot model accuracies of the classifier alone
# Sort the dataframe according to average performance
MeanClassifierPerformance <- Results %>% group_by(OTU, variable) %>% summarise_at(.vars = names(.)[4],.funs = c(mean = "mean", sd = "sd"))
Results <- left_join(Results, MeanClassifierPerformance, by = c("OTU", "variable"))
ResultsClassifier <- Results %>% dplyr::filter(variable %in% c("Accuracy_Classifier"))
taxonomy.np.ns$OTU <- rownames(taxonomy.np.ns)
ResultsClassifier <- left_join(ResultsClassifier, taxonomy.np.ns, by = c("OTU"))
ResultsClassifier$Label <- paste(ResultsClassifier$OTU, " (", ResultsClassifier$Genus, ")", sep = "")
ResultsClassifier <- ResultsClassifier[order(-ResultsClassifier$mean),] 
ResultsClassifier$Label <- factor(ResultsClassifier$Label, levels = unique(ResultsClassifier$Label))
# Plot
p_Accuracy <- ResultsClassifier %>% 
              dplyr::filter(variable %in% c("Accuracy_Classifier")) %>% 
              ggplot(data = ., aes(x = Label, y = 100*value)) +
              geom_errorbar(aes(x = Label, ymin = 100*mean, ymax = 100*mean), color = "#6c72dd", width = 0.8) +
              geom_point(shape = 21, fill = "#6c72dd") +
              geom_hline(yintercept = 50, color = "#4fb783") +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
              labs(color = "", y = "Accuracy (%)", x = "") +
              guides(color = FALSE, fill = FALSE) + 
              scale_y_continuous(limits = c(0, 100))
print(p_Accuracy)
png("Figures/AQUACULTURE-Accuracy.png", width = 9, height = 6, res = 500, units = "in")
print(p_Accuracy)
dev.off()


# Change order to match regression for plot
ResultsClassifier$Label <- factor(ResultsClassifier$Label, levels = unique(ResultsRegression$Label))
p_AccuracyII <- ResultsClassifier %>% 
              dplyr::filter(variable %in% c("Accuracy_Classifier")) %>% 
              ggplot(data = ., aes(x = Label, y = 100*value)) +
              geom_errorbar(aes(x = Label, ymin = 100*mean, ymax = 100*mean), color = "#6c72dd", width = 0.8) +
              geom_point(shape = 21, fill = "#6c72dd") +
              geom_hline(yintercept = 50, color = "#5b5b5b") + 
              scale_y_continuous(breaks = seq(0, 100, by = 25)) +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
              labs(color = "", y = "Accuracy (%)", x = "") +
              guides(color = FALSE, fill = FALSE) + 
              scale_y_continuous(limits = c(0, 100))
print(p_AccuracyII)


# Minimal and maximal accuracy
min(MeanClassifierPerformance$mean[MeanClassifierPerformance$variable == "Accuracy_Classifier"])
max(MeanClassifierPerformance$mean[MeanClassifierPerformance$variable == "Accuracy_Classifier"])
mean(MeanClassifierPerformance$mean[MeanClassifierPerformance$variable == "Accuracy_Classifier"])
sd(MeanClassifierPerformance$mean[MeanClassifierPerformance$variable == "Accuracy_Classifier"])
```

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Plot AUC values
PerformanceDataset <- read.csv("Results/PerformanceDataset_NS.csv")
PerformanceDataset <- PerformanceDataset[c("OTUOfInterest", "AUC_NS")]
MeanAUC <- PerformanceDataset %>% group_by(OTUOfInterest) %>% summarise_at(.vars = names(.)[2], .funs = c(mean = "mean", sd = "sd"))
PerformanceDataset <- left_join(PerformanceDataset, MeanAUC, by = c("OTUOfInterest"))

# Add taxonomy
PerformanceDataset <- left_join(PerformanceDataset, taxonomy.np.ns, by = c("OTUOfInterest" = "OTU"))
PerformanceDataset$Label <- paste(PerformanceDataset$OTU, " (", PerformanceDataset$Genus, ")", sep = "")

# Change order to match regression for plot
PerformanceDataset$Label <- factor(PerformanceDataset$Label, levels = unique(ResultsRegression$Label))
p_AUC <- PerformanceDataset %>% 
              ggplot(data = ., aes(x = Label, y = AUC_NS)) +
              geom_errorbar(aes(x = Label, ymin = mean, ymax = mean), color = "#6c72dd", width = 0.8) +
              geom_point(shape = 21, fill = "#6c72dd") +
              geom_hline(yintercept = 0.5, color = "#5b5b5b") + 
              scale_y_continuous(breaks = seq(0, 1, by = 0.25), limits = c(0, 1)) +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
              labs(color = "", y = "AUC", x = "") +
              guides(color = FALSE, fill = FALSE)
print(p_AUC)


min(PerformanceDataset$AUC_NS[!is.na(PerformanceDataset$AUC_NS)])
max(PerformanceDataset$AUC_NS[!is.na(PerformanceDataset$AUC_NS)])
mean(PerformanceDataset$AUC_NS[!is.na(PerformanceDataset$AUC_NS)])
sd(PerformanceDataset$AUC_NS[!is.na(PerformanceDataset$AUC_NS)])
```

#### Combined figure for regression and classification

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
p_AUCAdj <- p_AUC + theme(axis.title.x = element_blank(), axis.text.x = element_blank())
p_AccAdj <- p_AccuracyII + theme(axis.title.x = element_blank(), axis.text.x = element_blank())
p_R2Adj <- p_R2 + theme(axis.title.x = element_blank(), axis.text.x = element_blank(), legend.position = "none")
g1 <- plot_grid(p_AccAdj, p_AUCAdj, p_R2Adj, p_MAE, align = 'v', axis = 'l', ncol = 1, nrow = 4, rel_heights = c(0.5, 0.5, 0.5, 1.3), scale = 1, labels = c("A", "B", "C", "D"))
ggsave(file = "Figures/AQUACULTURE-PerformanceTop50.png", width = 10, height = 14, dpi = 300, units = "in", g1)
```

#### Difference when individual tanks are used for validation

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Not per tank
PredictionsPerFold <- read.csv("Results/PredictionsPerFold_NS_NoSort.csv")
shared.t.ns.rel <- sweep(shared.t.ns, 2, colSums(shared.t.ns), `/`)
shared.t.ns.rel <- shared.t.ns.rel[NonSorted]
Results <- NULL
for (i in unique(PredictionsPerFold$OTU)){
  for (j in unique(PredictionsPerFold$rep)){
    # Select the predictions from this repeat of the selected fold
    SelectedSet <- PredictionsPerFold[PredictionsPerFold$OTU == i & PredictionsPerFold$rep == j,]
    # R2
    R2_Regression <- R2(SelectedSet$Regression, SelectedSet$TrueValue)
    R2_Final <- R2(SelectedSet$Combined, SelectedSet$TrueValue)
    # MAE
    MAE_Regression <- MAE(SelectedSet$Regression, SelectedSet$TrueValue)
    MAE_Final <- MAE(SelectedSet$Combined, SelectedSet$TrueValue)
    nMAE_Regression <- MAE(SelectedSet$Regression, SelectedSet$TrueValue)/mean(as.matrix(shared.t.ns.rel[i,]))
    nMAE_Final <- MAE(SelectedSet$Combined, SelectedSet$TrueValue)/mean(as.matrix(shared.t.ns.rel[i,]))
    # False positive and negative before imposing classifier
    FPBefore <- dim(SelectedSet[SelectedSet$TrueClass == "Absent" & SelectedSet$Regression >= 0.01,])[1]
    FNBefore <- dim(SelectedSet[SelectedSet$TrueClass == "Present" & SelectedSet$Regression < 0.01,])[1]
    # False positive and negative after imposing classifier
    FPAfter <- dim(SelectedSet[SelectedSet$TrueClass == "Absent" & SelectedSet$Combined >= 0.01,])[1]
    FNAfter <- dim(SelectedSet[SelectedSet$TrueClass == "Present" & SelectedSet$Combined < 0.01,])[1]
    # Add absolute abundances
    SelectedSet$Index <- as.character(SelectedSet$Index)
    SelectedSet <- left_join(SelectedSet, Subsetphyseqobj[c("OTU", "Sample", "BacterialDensity")], by = c("OTU" = "OTU", "Index" = "Sample"))
    SelectedSet$CombinedAbsolute <- SelectedSet$Combined*SelectedSet$BacterialDensity
    SelectedSet$TrueValueAbsolute <- SelectedSet$TrueValue*SelectedSet$BacterialDensity
    R2_Final_Absolute <- R2(SelectedSet$CombinedAbsolute, SelectedSet$TrueValueAbsolute)
    # Save results
    Results <- rbind.data.frame(Results, cbind.data.frame(i, j, R2_Regression, R2_Final, MAE_Regression, MAE_Final, nMAE_Regression, nMAE_Final, FPBefore, FNBefore, FPAfter, FNAfter, R2_Final_Absolute))
  }
}
colnames(Results)[1:2] <- c("OTU", "rep")
Results <- Results[complete.cases(Results),]
Results <- melt(Results, id.vars = c("OTU", "rep"))
NotPerTank <- Results


# Per tank
PredictionsPerFold <- read.csv("Results/PredictionsPerFold_NS_1TankAsTest.csv")
shared.t.ns.rel <- sweep(shared.t.ns, 2, colSums(shared.t.ns), `/`)
shared.t.ns.rel <- shared.t.ns.rel[NonSorted]
Results <- NULL
for (i in unique(PredictionsPerFold$OTU)){
  for (j in unique(PredictionsPerFold$rep)){
    # Select the predictions from this repeat of the selected fold
    SelectedSet <- PredictionsPerFold[PredictionsPerFold$OTU == i & PredictionsPerFold$rep == j,]
    # R2
    R2_Regression <- R2(SelectedSet$Regression, SelectedSet$TrueValue)
    R2_Final <- R2(SelectedSet$Combined, SelectedSet$TrueValue)
    # MAE
    MAE_Regression <- MAE(SelectedSet$Regression, SelectedSet$TrueValue)
    MAE_Final <- MAE(SelectedSet$Combined, SelectedSet$TrueValue)
    nMAE_Regression <- MAE(SelectedSet$Regression, SelectedSet$TrueValue)/mean(as.matrix(shared.t.ns.rel[i,]))
    nMAE_Final <- MAE(SelectedSet$Combined, SelectedSet$TrueValue)/mean(as.matrix(shared.t.ns.rel[i,]))
    # False positive and negative before imposing classifier
    FPBefore <- dim(SelectedSet[SelectedSet$TrueClass == "Absent" & SelectedSet$Regression >= 0.01,])[1]
    FNBefore <- dim(SelectedSet[SelectedSet$TrueClass == "Present" & SelectedSet$Regression < 0.01,])[1]
    # False positive and negative after imposing classifier
    FPAfter <- dim(SelectedSet[SelectedSet$TrueClass == "Absent" & SelectedSet$Combined >= 0.01,])[1]
    FNAfter <- dim(SelectedSet[SelectedSet$TrueClass == "Present" & SelectedSet$Combined < 0.01,])[1]
    # Add absolute abundances
    SelectedSet$Index <- as.character(SelectedSet$Index)
    SelectedSet <- left_join(SelectedSet, Subsetphyseqobj[c("OTU", "Sample", "BacterialDensity")], by = c("OTU" = "OTU", "Index" = "Sample"))
    SelectedSet$CombinedAbsolute <- SelectedSet$Combined*SelectedSet$BacterialDensity
    SelectedSet$TrueValueAbsolute <- SelectedSet$TrueValue*SelectedSet$BacterialDensity
    R2_Final_Absolute <- R2(SelectedSet$CombinedAbsolute, SelectedSet$TrueValueAbsolute)
    # Save results
    Results <- rbind.data.frame(Results, cbind.data.frame(i, j, R2_Regression, R2_Final, MAE_Regression, MAE_Final, nMAE_Regression, nMAE_Final, FPBefore, FNBefore, FPAfter, FNAfter, R2_Final_Absolute))
  }
}
colnames(Results)[1:2] <- c("OTU", "rep")
Results <- Results[complete.cases(Results),]
Results <- melt(Results, id.vars = c("OTU", "rep"))
PerTank <- Results


# Compare
NotPerTank <- NotPerTank[NotPerTank$variable == "R2_Final",]
NotPerTank <- NotPerTank[,c("OTU", "variable", "value")]
mean(NotPerTank$value)
sd(NotPerTank$value)

PerTank <- PerTank[PerTank$variable == "R2_Final",]
PerTank <- PerTank[,c("OTU", "variable", "value")]
mean(PerTank$value)
sd(PerTank$value)

Join <- left_join(NotPerTank, PerTank, by = c("OTU"))
t <- as.data.frame(Join$value.x-Join$value.y)
t <- t[!is.na(t)]
mean(t)
```

#### Link with feature importances and location of sorting gates

```{r FACS_Gates, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Upload results
PredictionsPerFold <- read.csv("Results/PredictionsPerFold_NS.csv")
# For each sample of the sorted subpopulations, check which taxa were present at higher than 1%
shared.t.ns.rel <- sweep(shared.t.ns, 2, colSums(shared.t.ns), `/`)
MetadataSubPops <- Metadata[Metadata$Population %in% c("1", "2", "3", "4", "5"),]
ResultsPresenceSortedPops <- NULL
for (i in c("1", "2", "3", "4", "5")){
  SelectedSamples <- MetadataSubPops[MetadataSubPops$Population == i,]
  SelectedOTUTable <- shared.t.ns.rel[1:50, SelectedSamples$Identifier]
  SelectedOTUTable <- SelectedOTUTable > 0.01
  if (!is.null(dim(SelectedOTUTable))){
    SelectedOTUTable <- (rowSums(SelectedOTUTable) > 1) & (rowSums(SelectedOTUTable)/ncol(SelectedOTUTable) > 0.01)
  }
  ResultsPresenceSortedPops <- rbind.data.frame(ResultsPresenceSortedPops, SelectedOTUTable)
  colnames(ResultsPresenceSortedPops) <- names(SelectedOTUTable)
}
```

```{r FACS_Gates, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
param_sort <- c("SSC-H", "FITC-H")

pGs_1 <- matrix(c(7.8,9.8,9.8,7.8,
            10.6,10.6,12,12),
            ncol = 2,
            nrow = 4)
colnames(pGs_1) <- param_sort
pGs_1 <- polygonGate(.gate = pGs_1)

pGs_2 <- matrix(c(7.2,9.8,9.8,7.2,
            9.9,9.9,10.5,10.5),
            ncol = 2,
            nrow = 4)
colnames(pGs_2) <- param_sort
pGs_2 <- polygonGate(.gate = pGs_2)

pGs_3 <- matrix(c(7.2,6,6,7.2,
            10,10,10.8,10.8),
            ncol = 2,
            nrow = 4)
colnames(pGs_3) <- param_sort
pGs_3 <- polygonGate(.gate = pGs_3)

pGs_4 <- matrix(c(7.2,5,5,8.5,8.5,7.2,
             10,10,8.6,8.6,9.9,9.9),
             ncol = 2, 
             nrow = 6)
colnames(pGs_4) <- param_sort
pGs_4 <- polygonGate(.gate = pGs_4)


pGs_5 <- matrix(c(6,7,7,6,
            7.5,7.5,8.5,8.5),
            ncol = 2,
            nrow = 4)
colnames(pGs_5) <- param_sort
pGs_5 <- polygonGate(.gate = pGs_5)

pGs_6 <- matrix(c(2.8,4.5,4.5,2.8,
            7.6,7.6,8.7,8.7),
            ncol = 2,
            nrow = 4)
colnames(pGs_6) <- param_sort
pGs_6 <- polygonGate(.gate = pGs_6)

# Convert gates so they can be used as input for ggplot
df1 <- fortify(pGs_1)/maxval
df2 <- fortify(pGs_2)/maxval
df3 <- fortify(pGs_3)/maxval
df4 <- fortify(pGs_4)/maxval
df5 <- fortify(pGs_5)/maxval
```

```{r PlotFeatures_RandomForest, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Upload results
PerformancePerFold <- read.csv("Results/PerformancePerFold_NS.csv")

# Feature importances classifier
ImporancesClassifier <- cbind.data.frame(PerformancePerFold$OTU, PerformancePerFold[, grepl("_Class", names(PerformancePerFold))])
colnames(ImporancesClassifier)[1] <- "OTU"
MeanImporancesClassifier <- ImporancesClassifier %>%
                            group_by(OTU) %>%
                            summarise(across(everything(), list(mean)))
Taxa <- MeanImporancesClassifier$OTU
MeanImporancesClassifier <- t(MeanImporancesClassifier[!colnames(MeanImporancesClassifier) == "OTU"])
colnames(MeanImporancesClassifier) <- paste("Class_", Taxa, sep = "")
MeanImporancesClassifier <- as.data.frame(MeanImporancesClassifier)
MeanImporancesClassifier$GMM <- gsub("_Class_1", "", rownames(MeanImporancesClassifier))
# Add a column with TRUE FALSE to evaluate which GMMs are included in the model
MeanImporancesClassifier <- cbind.data.frame(MeanImporancesClassifier, MeanImporancesClassifier[colnames(MeanImporancesClassifier)[!colnames(MeanImporancesClassifier) == "GMM"]] > 0)
colnames(MeanImporancesClassifier)[(length(Taxa)+2):(2*length(Taxa)+1)] <- paste(colnames(MeanImporancesClassifier)[(length(Taxa)+2):(2*length(Taxa)+1)], "_LOGIC", sep = "")

# Feature importances regression
ImporancesRegression <- cbind.data.frame(PerformancePerFold$OTU, PerformancePerFold[, grepl("_Reg", names(PerformancePerFold))])
colnames(ImporancesRegression)[1] <- "OTU"
MeanImporancesRegression <- ImporancesRegression %>%
                            group_by(OTU) %>%
                            summarise(across(everything(), list(mean)))
Taxa <- MeanImporancesRegression$OTU
MeanImporancesRegression <- t(MeanImporancesRegression[!colnames(MeanImporancesRegression) == "OTU"])
colnames(MeanImporancesRegression) <- paste("Reg_", Taxa, sep = "")
MeanImporancesRegression <- as.data.frame(MeanImporancesRegression)
MeanImporancesRegression$GMM <- gsub("_Reg_1", "", rownames(MeanImporancesRegression))
# Add a column with TRUE FALSE to evaluate which GMMs are included in the model
MeanImporancesRegression <- cbind.data.frame(MeanImporancesRegression, MeanImporancesRegression[colnames(MeanImporancesRegression)[!colnames(MeanImporancesRegression) == "GMM"]] > 0)
colnames(MeanImporancesRegression)[(length(Taxa)+2):(2*length(Taxa)+1)]  <- paste(colnames(MeanImporancesRegression)[(length(Taxa)+2):(2*length(Taxa)+1)] , "_LOGIC", sep = "")

# Make a pooled sample and add the corresponding GMM identities per cell
Pooled <- FCS_pool(flowData_transformed, stub = "*")
PooledSubsampled <- FCS_resample(Pooled, replace = TRUE, sample = 500000)
PooledSubsampled <- PooledSubsampled[, paramGMM]
grid <- PooledSubsampled[[1]]@exprs
pred <- predict(gmm_clust, grid)
grid <- cbind.data.frame(grid, paste("GMM", pred$classification, sep = ""))
colnames(grid)[length(paramGMM)+1] <- "Classification"
# Add the importances to each of the cells according to the GMM to which they belong
grid <- left_join(grid, MeanImporancesClassifier, by = c("Classification" = "GMM"))
grid <- left_join(grid, MeanImporancesRegression, by = c("Classification" = "GMM"))


# for each otu plot the feature importances and gates in which they were detected
for (i in colnames(ResultsPresenceSortedPops)[1:10]){
     Detected <- as.vector(ResultsPresenceSortedPops[i])
     colnames(Detected) <- "det"
     # Make sizes of the boxes in which OTU is found bigger
     Sizes <- rep(0.75, 5)
     Sizes[Detected$det] <- 2
     # Make color of the boxes in which OTU is found different
     Colors <- rep("#707070", 5)
     Colors[Detected$det] <- "#434982"
     # Colnames
     Importance <- paste("Reg_", i , sep = "")
     # PLot the GMM
     grid <- grid[order(grid[Importance]),]
     
     gridSub <- grid[200000:500000,]
     p_GMMgrid <- gridSub %>%
                  ggplot(data = .) + 
                  geom_point(alpha = 0.3, shape = 16, size = 0.9, aes_string(y = "`FITC-H`", x = "`SSC-H`", color = Importance)) +
                  scale_x_continuous(limits = c(0.35, 0.85)) +
                  scale_y_continuous(limits = c(0.58, 0.95)) +
                  scale_color_distiller(palette = 'BuPu', direction = 1) +
                  geom_path(data = df1, aes(x = `SSC-H`, y = `FITC-H`), color = Colors[1], size = Sizes[1]) + 
                  geom_path(data = df2, aes(x = `SSC-H`, y = `FITC-H`), color = Colors[2], size = Sizes[2]) + 
                  geom_path(data = df3, aes(x = `SSC-H`, y = `FITC-H`), color = Colors[3], size = Sizes[3]) + 
                  geom_path(data = df4, aes(x = `SSC-H`, y = `FITC-H`), color = Colors[4], size = Sizes[4]) + 
                  geom_path(data = df5, aes(x = `SSC-H`, y = `FITC-H`), color = Colors[5], size = Sizes[5]) + 
                  labs(x = "Side scatter", y = "SYBR Green I fluorescence", color = "Importance") +
                  ggtitle(i) +
                  theme_cowplot() +
                  theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
     print(p_GMMgrid) 
     png(paste( "Figures/AQUACULTURE-Importances-Reg-", i, ".png", sep = ""), width = 6, height = 4.5, res = 500, units = "in")
     print(p_GMMgrid)
     dev.off()
}
```

#### Link feature importances and taxonomic dissimilarity

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Generate a phylogenetic distances between the OTUs
    PredictionsPerFold <- read.csv("Results/PredictionsPerFold_NS.csv")
    # Read the fasta file with the (aligned) reference sequences
    RefSeqs <- Biostrings::readDNAStringSet(filepath = "Data/Aquaculture/Illumina/stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.pick.opti_mcc.0.03.rep.fasta", format = "fasta")
    # Only keep the OTU's that were still retained after the scaling
    RefSeqs <- RefSeqs[which(rownames(shared.t.ns.old) %in% unique(PerformanceDataset$OTU))]
    length(RefSeqs)
    # Convert to a DNAbin object to make trees
    RefSeqs <- as.DNAbin(RefSeqs)
    # Make labels easier
    names(RefSeqs) <- str_extract(names(RefSeqs), "Otu[0-9]{5}")
    # Calculate distances between the sequences
    Distances <- dist.dna(RefSeqs, model = "TN93") # K80, TN93
    Taxdist <- as.data.frame(as.matrix(Distances))
    
    
# Similarity of the feature abundances
        PerformancePerFold <- read.csv("Results/PerformancePerFold_NS.csv")
        # Feature importances classifier
        ImporancesClassifier <- cbind.data.frame(PerformancePerFold$OTU, PerformancePerFold[, grepl("_Class", names(PerformancePerFold))])
        colnames(ImporancesClassifier)[1] <- "OTU"
        MeanImporancesClassifier <- ImporancesClassifier %>%
                                    group_by(OTU) %>%
                                    summarise(across(everything(), list(mean)))
        Taxa <- MeanImporancesClassifier$OTU
        MeanImporancesClassifier <- t(MeanImporancesClassifier[!colnames(MeanImporancesClassifier) == "OTU"])
        colnames(MeanImporancesClassifier) <- Taxa
        MeanImporancesClassifier <- as.data.frame(MeanImporancesClassifier)
        MeanImporancesClassifier$GMM <- gsub("_Class_1", "", rownames(MeanImporancesClassifier))

        # Feature importances regression
        ImporancesRegression <- cbind.data.frame(PerformancePerFold$OTU, PerformancePerFold[, grepl("_Reg", names(PerformancePerFold))])
        colnames(ImporancesRegression)[1] <- "OTU"
        MeanImporancesRegression <- ImporancesRegression %>%
                                    group_by(OTU) %>%
                                    summarise(across(everything(), list(mean)))
        Taxa <- MeanImporancesRegression$OTU
        MeanImporancesRegression <- t(MeanImporancesRegression[!colnames(MeanImporancesRegression) == "OTU"])
        colnames(MeanImporancesRegression) <- Taxa
        MeanImporancesRegression <- as.data.frame(MeanImporancesRegression)
        MeanImporancesRegression$GMM <- gsub("_Reg_1", "", rownames(MeanImporancesRegression))

        # Calculate similarity feature importances
        impdis <- vegdist(t(MeanImporancesClassifier[!colnames(MeanImporancesClassifier) == "GMM"]), method = "bray") # binary = "TRUE"
        impdis <- as.data.frame(as.matrix(impdis))

# Combine feature importances dissimilarity and taxonomic distance
Results <- NULL
for (i in 1:dim(impdis)[1]){
  for (j in 2:dim(impdis)[1]){
    # Selected OTUs
    Taxon1 <- colnames(impdis)[i]
    Taxon2 <- colnames(impdis)[j]
    # Get taxonomic distance
    Taxonomic <- Taxdist[Taxon1, Taxon2]
    # Get dissimilarity feature importances
    Features <- impdis[Taxon1, Taxon2]
    # Save results
    Results <- rbind.data.frame(Results, cbind.data.frame(Taxon1, Taxon2, Taxonomic, Features))
  }
}
# Remove taxon combined with itself
Results <- Results[!Results$Taxon1 == Results$Taxon2,]
Results$Features <- 1-Results$Features

# Plot
LM <- lm(Features ~ Taxonomic, data = Results) 
p <- ggplot(Results, aes(x = Taxonomic, y = Features)) +
         geom_point(shape = 21, size = 2, size = 0.9, alpha = 0.7, fill = SingleColor) +
         geom_smooth(method = 'lm', formula = y ~ x, col = "black") +
         labs(x = "Phylogenetic distance", y = "Feature importance similarity") +
         annotate(geom = "text", x = 0.35, y = 0.6, label = paste0("Adj.R.sq. = ", format(summary(LM)$r.squared, digits = 2), "\nCp = ", formatC(cor(Results$Taxonomic, Results$Features), format = "f", digits = 2), "\nn = ", dim(Results)[1]), hjust = 0) + 
         theme_cowplot() +
         theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1)) 
print(p)
png("Figures/AQUACULTURE-Phylogeny-FeatureSimilarity.png", width = 6, height = 4.5, res = 500, units = "in")
print(p)
dev.off()
```

#### Sensitivity to dataset size

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
### FOR OTU 1 ###
      # Calculate classifier performance
      PredictionsPerFold <- read.csv("Results/PredictionsPerFold_NS_IS_NrOfSamples_OTU1.csv")
      PredictionsPerFold$Subsample <- c(rep(1, dim(PredictionsPerFold)[1]/4), rep(2, dim(PredictionsPerFold)[1]/4), rep(3, dim(PredictionsPerFold)[1]/4), rep(4, dim(PredictionsPerFold)[1]/4))
      
      Results <- NULL
      for (i in unique(PredictionsPerFold$OTU)){
        for(k in unique(PredictionsPerFold$Subsample)){
          for (j in unique(PredictionsPerFold$rep)){
            # Select the predictions from this repeat of the selected fold
            SelectedSet <- PredictionsPerFold[PredictionsPerFold$OTU == i & PredictionsPerFold$rep == j & PredictionsPerFold$Subsample == k,]
            SelectedSet$CombinedClass <- "Absent"
            SelectedSet$CombinedClass[SelectedSet$Combined > 0.01] <- "Present"
            SelectedSet <- SelectedSet[SelectedSet$Index %in% NonSorted,]
            # Accuracy
            Accuracy_Classifier <- sum(SelectedSet$PredictedClass == SelectedSet$TrueClass)/length(SelectedSet$TrueClass)
            Accuracy_Final <- sum(SelectedSet$CombinedClass == SelectedSet$TrueClass)/length(SelectedSet$TrueClass)
            # False positive: Negatives with positive outcome/All negatives
            NrFalsePositive <- length(SelectedSet$X[SelectedSet$TrueClass == "Absent" & SelectedSet$PredictedClass == "Present"])
            NrTotalTrueAbsent <- length(SelectedSet$X[SelectedSet$TrueClass == "Absent"])
            FalsePositiveRate <- NrFalsePositive/NrTotalTrueAbsent
            # False negative
            NrFalseNegative <- length(SelectedSet$X[SelectedSet$TrueClass == "Present" & SelectedSet$PredictedClass == "Absent"])
            NrTotalTruePresent <- length(SelectedSet$X[SelectedSet$TrueClass == "Present"])
            FalseNegativeRate <- NrFalseNegative/NrTotalTruePresent
            # Save results
            Results <- rbind.data.frame(Results, cbind.data.frame(i, j, k, Accuracy_Classifier, Accuracy_Final, NrFalsePositive, NrFalseNegative, FalsePositiveRate, FalseNegativeRate))
          }
        }
      }
      colnames(Results)[1:3] <- c("OTU", "rep", "Subsample")
      Results <- Results[complete.cases(Results),]
      Results <- melt(Results, id.vars = c("OTU", "rep", "Subsample"))
      
      # Calculate average performance
      MeanClassifierPerformance <- Results %>% group_by(OTU, variable, Subsample) %>% summarise_at(.vars = names(.)[5],.funs = c(mean = "mean", sd = "sd"))
      Results <- left_join(Results, MeanClassifierPerformance, by = c("OTU", "variable", "Subsample"))
      Results$Subsample <- as.factor(Results$Subsample)
      
      # Plot
      p_Accuracy_OTU1 <- Results %>%
                          dplyr::filter(variable %in% c("Accuracy_Classifier")) %>%
                          ggplot(data = ., aes(x = Subsample, y = 100*value)) +
                          geom_errorbar(aes(x = Subsample, ymin = 100*mean, ymax = 100*mean), color = "#6c72dd", width = 0.8) +
                          geom_point(shape = 21, fill = "#6c72dd") +
                          geom_hline(yintercept = 50, color = "#5b5b5b") + 
                          scale_x_discrete("Fraction used for training", labels = c("20 %", "40 %", "60 %", "80 %")) +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
                          labs(color = "", y = "Accuracy (%)") +
                          guides(color = FALSE, fill = FALSE) +
                          scale_y_continuous(limits = c(0, 100))
      print(p_Accuracy_OTU1)

### FOR OTU 6 ###
      # Calculate classifier performance
      PredictionsPerFold <- read.csv("Results/PredictionsPerFold_NS_IS_NrOfSamples_OTU6.csv")
      PredictionsPerFold$Subsample <- c(rep(1, dim(PredictionsPerFold)[1]/4), rep(2, dim(PredictionsPerFold)[1]/4), rep(3, dim(PredictionsPerFold)[1]/4), rep(4, dim(PredictionsPerFold)[1]/4))
      
      Results <- NULL
      for (i in unique(PredictionsPerFold$OTU)){
        for(k in unique(PredictionsPerFold$Subsample)){
          for (j in unique(PredictionsPerFold$rep)){
            # Select the predictions from this repeat of the selected fold
            SelectedSet <- PredictionsPerFold[PredictionsPerFold$OTU == i & PredictionsPerFold$rep == j & PredictionsPerFold$Subsample == k,]
            SelectedSet$CombinedClass <- "Absent"
            SelectedSet$CombinedClass[SelectedSet$Combined > 0.01] <- "Present"
            SelectedSet <- SelectedSet[SelectedSet$Index %in% NonSorted,]
            # Accuracy
            Accuracy_Classifier <- sum(SelectedSet$PredictedClass == SelectedSet$TrueClass)/length(SelectedSet$TrueClass)
            Accuracy_Final <- sum(SelectedSet$CombinedClass == SelectedSet$TrueClass)/length(SelectedSet$TrueClass)
            # False positive: Negatives with positive outcome/All negatives
            NrFalsePositive <- length(SelectedSet$X[SelectedSet$TrueClass == "Absent" & SelectedSet$PredictedClass == "Present"])
            NrTotalTrueAbsent <- length(SelectedSet$X[SelectedSet$TrueClass == "Absent"])
            FalsePositiveRate <- NrFalsePositive/NrTotalTrueAbsent
            # False negative
            NrFalseNegative <- length(SelectedSet$X[SelectedSet$TrueClass == "Present" & SelectedSet$PredictedClass == "Absent"])
            NrTotalTruePresent <- length(SelectedSet$X[SelectedSet$TrueClass == "Present"])
            FalseNegativeRate <- NrFalseNegative/NrTotalTruePresent
            # Save results
            Results <- rbind.data.frame(Results, cbind.data.frame(i, j, k, Accuracy_Classifier, Accuracy_Final, NrFalsePositive, NrFalseNegative, FalsePositiveRate, FalseNegativeRate))
          }
        }
      }
      colnames(Results)[1:3] <- c("OTU", "rep", "Subsample")
      Results <- Results[complete.cases(Results),]
      Results <- melt(Results, id.vars = c("OTU", "rep", "Subsample"))
      
      # Calculate average performance
      MeanClassifierPerformance <- Results %>% group_by(OTU, variable, Subsample) %>% summarise_at(.vars = names(.)[5],.funs = c(mean = "mean", sd = "sd"))
      Results <- left_join(Results, MeanClassifierPerformance, by = c("OTU", "variable", "Subsample"))
      Results$Subsample <- as.factor(Results$Subsample)
      
      # Plot
      p_Accuracy_OTU6 <- Results %>%
                          dplyr::filter(variable %in% c("Accuracy_Classifier")) %>%
                          ggplot(data = ., aes(x = Subsample, y = 100*value)) +
                          geom_errorbar(aes(x = Subsample, ymin = 100*mean, ymax = 100*mean), color = "#6c72dd", width = 0.8) +
                          geom_point(shape = 21, fill = "#6c72dd") +
                          geom_hline(yintercept = 50, color = "#5b5b5b") +
                          scale_x_discrete("Fraction used for training", labels = c("20 %", "40 %", "60 %", "80 %")) +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
                          labs(color = "", y = "Accuracy (%)") +
                          guides(color = FALSE, fill = FALSE) +
                          scale_y_continuous(limits = c(0, 100))
      print(p_Accuracy_OTU6)
```

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
### FOR OTU 1 ###
      # Calculate classifier performance
      PredictionsPerFold <- read.csv("Results/PredictionsPerFold_NS_IS_NrOfSamples_OTU1.csv")
      PredictionsPerFold$Subsample <- c(rep(1, dim(PredictionsPerFold)[1]/4), rep(2, dim(PredictionsPerFold)[1]/4), rep(3, dim(PredictionsPerFold)[1]/4), rep(4, dim(PredictionsPerFold)[1]/4))
      Results <- NULL
      for (i in unique(PredictionsPerFold$OTU)){
        for(k in unique(PredictionsPerFold$Subsample)){
          for (j in unique(PredictionsPerFold$rep)){
          # Select the predictions from this repeat of the selected fold
          SelectedSet <- PredictionsPerFold[PredictionsPerFold$OTU == i & PredictionsPerFold$rep == j & PredictionsPerFold$Subsample == k,]
          # SelectedSet <- SelectedSet[SelectedSet$X %in% NonSorted,]
          # R2
          R2_Regression <- R2(SelectedSet$Regression, SelectedSet$TrueValue)
          R2_Final <- R2(SelectedSet$Combined, SelectedSet$TrueValue)
          # MAE
          MAE_Regression <- MAE(SelectedSet$Regression, SelectedSet$TrueValue)
          MAE_Final <- MAE(SelectedSet$Combined, SelectedSet$TrueValue)
          # Save results
          Results <- rbind.data.frame(Results, cbind.data.frame(i, j, k, R2_Regression, R2_Final, MAE_Regression, MAE_Final))
          }
        }
      }
      colnames(Results)[1:3] <- c("OTU", "rep", "Subsample")
      Results <- Results[complete.cases(Results),]
      Results <- melt(Results, id.vars = c("OTU", "rep", "Subsample"))

      # Calculate average performance
      MeanClassifierPerformance <- Results %>% group_by(OTU, variable, Subsample) %>% summarise_at(.vars = names(.)[5],.funs = c(mean = "mean", sd = "sd"))
      Results <- left_join(Results, MeanClassifierPerformance, by = c("OTU", "variable", "Subsample"))
      Results$Subsample <- as.factor(Results$Subsample)
      
      # Plot
      p_Regression_OTU1 <- Results %>%
                          dplyr::filter(variable %in% c("R2_Final")) %>%
                          ggplot(data = ., aes(x = Subsample, y = value)) +
                          geom_errorbar(aes(x = Subsample, ymin = mean, ymax = mean), color = "#6c72dd", width = 0.8) +
                          geom_point(shape = 21, fill = "#6c72dd") +
                          geom_hline(yintercept = 50, color = "#4fb783") +
                          scale_x_discrete("Fraction used for training", labels = c("20 %", "40 %", "60 %", "80 %")) +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
                          labs(color = "", y = expression(paste("R"^"2"))) +
                          guides(color = FALSE, fill = FALSE) +
                          scale_y_continuous(limits = c(0, 1))
      print(p_Regression_OTU1)

### FOR OTU 6 ###
      # Calculate classifier performance
      PredictionsPerFold <- read.csv("Results/PredictionsPerFold_NS_IS_NrOfSamples_OTU6.csv")
      PredictionsPerFold$Subsample <- c(rep(1, dim(PredictionsPerFold)[1]/4), rep(2, dim(PredictionsPerFold)[1]/4), rep(3, dim(PredictionsPerFold)[1]/4), rep(4, dim(PredictionsPerFold)[1]/4))
      Results <- NULL
      for (i in unique(PredictionsPerFold$OTU)){
        for(k in unique(PredictionsPerFold$Subsample)){
          for (j in unique(PredictionsPerFold$rep)){
          # Select the predictions from this repeat of the selected fold
          SelectedSet <- PredictionsPerFold[PredictionsPerFold$OTU == i & PredictionsPerFold$rep == j & PredictionsPerFold$Subsample == k,]
          # R2
          R2_Regression <- R2(SelectedSet$Regression, SelectedSet$TrueValue)
          R2_Final <- R2(SelectedSet$Combined, SelectedSet$TrueValue)
          # MAE
          MAE_Regression <- MAE(SelectedSet$Regression, SelectedSet$TrueValue)
          MAE_Final <- MAE(SelectedSet$Combined, SelectedSet$TrueValue)
          # Save results
          Results <- rbind.data.frame(Results, cbind.data.frame(i, j, k, R2_Regression, R2_Final, MAE_Regression, MAE_Final))
          }
        }
      }
      colnames(Results)[1:3] <- c("OTU", "rep", "Subsample")
      Results <- Results[complete.cases(Results),]
      Results <- melt(Results, id.vars = c("OTU", "rep", "Subsample"))

      # Calculate average performance
      MeanClassifierPerformance <- Results %>% group_by(OTU, variable, Subsample) %>% summarise_at(.vars = names(.)[5],.funs = c(mean = "mean", sd = "sd"))
      Results <- left_join(Results, MeanClassifierPerformance, by = c("OTU", "variable", "Subsample"))
      Results$Subsample <- as.factor(Results$Subsample)
      
      # Plot
      p_Regression_OTU6 <- Results %>%
                          dplyr::filter(variable %in% c("R2_Final")) %>%
                          ggplot(data = ., aes(x = Subsample, y = value)) +
                          geom_errorbar(aes(x = Subsample, ymin = mean, ymax = mean), color = "#6c72dd", width = 0.8) +
                          geom_point(shape = 21, fill = "#6c72dd") +
                          geom_hline(yintercept = 50, color = "#4fb783") +
                          scale_x_discrete("Fraction used for training", labels = c("20 %", "40 %", "60 %", "80 %")) +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
                          labs(color = "", y = expression(paste("R"^"2"))) +
                          guides(color = FALSE, fill = FALSE) +
                          scale_y_continuous(limits = c(0, 1))
      print(p_Regression_OTU6)
```

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Combined plot
g <- plot_grid(p_Accuracy_OTU1, p_Accuracy_OTU6, p_Regression_OTU1, p_Regression_OTU6, labels = c("A", "B", "C", "D"), ncol = 2, nrow = 2)
ggsave(file = "Figures/AQUACULTURE-InfluenceNumberOfSamples.png", width = 8, height = 6, dpi = 500, units = "in", g)

# Remove variables that are no longer needed
rm(list = ls())
# Load convenience funtions
source("ConvenienceFunctions.R")
```

### Make predictions on time series

#### Load and preprocess data

```{r FACSVERSE_LoadData, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Upload fcs-files
Datapath <- c("Data/Aquaculture/FCM/FACSVerse/")
fcsfiles <- list.files(path = Datapath, recursive = TRUE, pattern = ".fcs", full.names = TRUE)
flowData <- flowCore::read.flowSet(files = fcsfiles, transformation = FALSE, pattern = ".fcs", ignore.text.offset = TRUE, emptyValue = FALSE)
# Remove variables that are no longer needed
remove(Datapath, fcsfiles)
```

```{r FACSVERSE_MakeMetadataFromSamplenames, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Read metadata
metadata <- readxl::read_excel("./Metadata/FACS-LABELS.xlsx")
metadata <- data.frame(metadata, do.call(rbind, strsplit(metadata$Sample_names, split = "_")))
# Load file for relabeling Extra samples
ExtraLabels <- readxl::read_excel("./Metadata/Extra_analyses.xlsx")
metadata <- left_join(metadata, ExtraLabels, by = c("X1" = "Sample_ID"))
metadata[!is.na(metadata$Relabel), "X1"] <- metadata[!is.na(metadata$Relabel), "Relabel"]
metadata <- metadata[, -c(10:11)]
# Extract metadata from sample names
metadata <- cbind(metadata, do.call(rbind, strsplit(as.character(metadata$X1), split = ".", fixed = TRUE)))[, -14]
colnames(metadata) <- c("FACS_names", "Sample_names", "Remark", "Quality" , "Plate_carrier", "Sample", "Type", "Stain", "Dilution", "Tank", "Day", "Timepoint", "Feeding_status")
metadata$Dilution <- as.numeric(as.character(metadata$Dilution))
metadata$Time_cont <- as.numeric(gsub("D","",metadata$Day)) + (((as.numeric(as.character(metadata$Timepoint)))*3) - 1)/24
# Keep only the data from this experiment
metadata <- metadata[metadata$FACS_names %in% sampleNames(flowData),]

# Remove variables that are no longer needed
remove(ExtraLabels)
```

```{r FACSVERSE_AsinhTransform, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Keep high-quality samples
flowData <- flowData[metadata$FACS_names[metadata$Quality == "OK"]]

# Select phenotypic features of interest and transform parameters
flowData_transformed <- transform(flowData,
                                   `FSC-H` = asinh(`FSC-H`), 
                                    `SSC-H` = asinh(`SSC-H`), 
                                    `FITC-H` = asinh(`FITC-H`), 
                                    `PE-H` = asinh(`PE-H`),
                                    `PerCP-Cy5.5-H` = asinh(`PerCP-Cy5.5-H`), 
                                    `PE-Cy7-H` = asinh(`PE-Cy7-H`), 
                                    `APC-H` = asinh(`APC-H`), 
                                    `V450-H` = asinh(`V450-H`),
                                    `V500-H` = asinh(`V500-H`))
param <- c("FITC-H", "FSC-H", "SSC-H", "PerCP-Cy5.5-H")
remove(flowData)
```

```{r FACSVERSE_GateCheck, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Bacterial population
sqrcut1 <- matrix(c(6.8,7,12.7,12.7,
                    3.5,4,10.9,3.5),
                  ncol = 2, 
                  nrow = 4)
colnames(sqrcut1) <- c("FITC-H","PerCP-Cy5.5-H")
polyGate1 <- polygonGate(.gate = sqrcut1, filterId = "Total Cells")
flowData_transformed <- Subset(flowData_transformed, polyGate1)
```

```{r Preprocessing_GMM, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Normalise
mytrans <- function(x) x/maxval # use same maxval as model training!!!!
flowData_transformed <- transform(flowData_transformed,
                                  `FITC-H` = mytrans(`FITC-H`),
                                  `PerCP-Cy5.5-H` = mytrans(`PerCP-Cy5.5-H`), 
                                  `SSC-H` = mytrans(`SSC-H`),
                                  `FSC-H` = mytrans(`FSC-H`),
                                  `PE-H` = mytrans(`PE-H`),
                                  `PE-Cy7-H` = mytrans(`PE-Cy7-H`), 
                                  `APC-H` = mytrans(`APC-H`), 
                                  `V450-H` = mytrans(`V450-H`),
                                  `V500-H` = mytrans(`V500-H`))
# Parameters to take into account for the model
paramGMM <- c("FITC-H", "FSC-H", "SSC-H", "PerCP-Cy5.5-H")
# Upload the GMM:
gmm_clust <- readRDS(file = "Results/GMMFits/GMMs_4param_10to150per5.rds")

#
flowData_transformed <- FCS_resample(flowData_transformed, replace = TRUE, sample = 10000)

# Apply GMM mask to the data
NumberOfClusters <- gmm_clust$G
params_gmm <- colnames(gmm_clust$data)
flowData_transformed <- flowData_transformed[, params_gmm] # subset to the relevant parameters
GMMALL <- data.frame(matrix(nrow = NumberOfClusters+1, ncol = length(flowData_transformed))) # Initialize a df to store the results of the predictions
rownames(GMMALL) <- c(1:NumberOfClusters, "(Other)")
for (i in 1:length(flowData_transformed)){
    RawData <- flowData_transformed[[i]]@exprs
    GMMPred <- predict(gmm_clust, RawData)
    GMMPred <- as.factor(GMMPred$classification)
    Summary <- summary(GMMPred)
    Summary <- Summary[rownames(GMMALL)] # Reorganise to the same order as the df that was initialised above
    GMMALL[,i] <- Summary
    print(i)
}
# Replace the NA values by 0
GMMALL[is.na(GMMALL)] <- 0
rownames(GMMALL) <- c(paste("GMM", 1:NumberOfClusters, sep = ""), "Other")
colnames(GMMALL) <- sampleNames(flowData_transformed)
# Normalise the GMM abundances to sum = 1
GMMALL <- sweep(GMMALL, 2, colSums(GMMALL), `/`)
GMMALL <- t(GMMALL)
GMMALL <- as.data.frame(GMMALL)
GMMALL$Names <- rownames(GMMALL)
```

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Selected OTU
i = 1

# Select OTU of interest
OTUOfInterest <- OTUPreprocessed$OTU[i]
OTUAbundances <- OTUPreprocessed[OTUPreprocessed$OTU == OTUOfInterest,]
OTUAbundances <- cbind.data.frame(names(OTUAbundances), as.numeric(paste(OTUAbundances)))[-1,]
colnames(OTUAbundances) <- c("ID", "Abundance")

# Combine the features and measured variables
Dataset <- left_join(GMMOut, IdentifiersBoth, by = c("Names" = "FACS_names"))
Dataset <- left_join(Dataset, OTUAbundances, by = c("Identifier" = "ID"))
Dataset <- Dataset[!is.na(Dataset$Identifier),]
rownames(Dataset) <- Dataset$Identifier
Dataset <- Dataset[, -which(names(Dataset) %in% c("Names", "Identifier", "X1", "Population", "BacterialDensity"))]
Dataset <- Dataset[!is.na(Dataset$Abundance),]

# Centered log ratio transform
Dataset <- cbind.data.frame(compositions::clr(Dataset[,!names(Dataset) == "Abundance"]), Dataset$Abundance)
colnames(Dataset)[dim(Dataset)[2]] <- "Abundance"

# Save dataset to reload it later
DatasetFull <- Dataset

# Model
train3 <- DatasetFull
GMMNames <- colnames(Dataset)[!colnames(Dataset) == "Abundance"]
  
# Transformation --> ensure predictions are in the 0-1 range to allow logit transformation later
minvalue <- min(train3$Abundance[train3$Abundance > 0])
  
# Get number of samples with low abundance (i.e. < 0.01) and high abundance (i.e. > 0.01)
Below1 <- train3[train3$Abundance < 0.01,]
Over1 <- train3[train3$Abundance >= 0.01,]
  
#
TotalNew <- 1000
NumberOfBelow1 <- dim(Below1)[1]
NumberOfOver1 <- dim(Over1)[1]
NumberOfOver1ToMake <- round(NumberOfBelow1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
NumberOfBelow1ToMake <- round(NumberOfOver1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
if(NumberOfOver1ToMake < TotalNew/2) NumberOfOver1ToMake <- TotalNew/2
if(NumberOfBelow1ToMake < TotalNew/2) NumberOfBelow1ToMake <- TotalNew/2
if(dim(Below1)[1] == 1){
    NumberOfBelow1ToMake <- 0
    NumberOfOver1ToMake <- TotalNew
}
  
# Max random variation (1000x smaller than the smallest value)
RandValPredictorVals <- colMins(as.matrix(abs(train3[, !names(train3) == "Abundance"])))/100
RandValOutput <- min(abs(train3$Abundance[train3$Abundance > 0]))/100
RandGMMVals <- NULL
RandAbundVals <- NULL
            
# Fake zero's
InSilicoBelow1 <- NULL
for (j in 1:(NumberOfBelow1ToMake*1)){
    for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
        RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
        # Select random samples
        SelectedSamples <- round(runif(2, min = 1, max = dim(Below1)[1]))
        Sample1 <- Below1[SelectedSamples[1],]
        Sample2 <- Below1[SelectedSamples[2],]
        # Random mixing proportions
        MixProps <- runif(1, min = 0, max = 1)
        # Mix
        New <- MixProps*Sample1 + (1-MixProps)*Sample2
        New <- New + c(RandGMMVals, RandAbundVals)
        # Save
        InSilicoBelow1 <- rbind.data.frame(InSilicoBelow1, New)
} #1
  
# Fake abundant using only abundant samples
InSilicoOver1H <- NULL
Over1High <- Over1[mean(Over1$Abundance) < Over1$Abundance,]
for (j in 1:round(NumberOfOver1ToMake*(1))){
    for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
        RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample1 <- Over1High[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample2 <- Over1High[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver1H <- rbind.data.frame(InSilicoOver1H, New)
            } #1
  
# Fake abundant using only abundant samples
InSilicoOver1 <- NULL
for (j in 1:round(NumberOfOver1ToMake*(1/2))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
              Sample1 <- Over1[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample2 <- Over1High[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver1 <- rbind.data.frame(InSilicoOver1, New)
            } #1
            
# Fake samples mixed between low and high abundances
InSilicoOver2 <- NULL
for (j in 1:round(NumberOfOver1ToMake*(1/2))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
              Sample1 <- Over1[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Below1)[1]))
              Sample2 <- Below1[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver2 <- rbind.data.frame(InSilicoOver2, New)
            } #2
  
# Keep original samples aside
Original <- train3
              
# Combine the in sillico samples with the original data
train3 <- cbind.data.frame("Original", train3)
colnames(train3)[1] <- "Group"
InSilicoBelow1 <- cbind.data.frame("InSilicoBelow1", InSilicoBelow1)
colnames(InSilicoBelow1)[1] <- "Group"
InSilicoOver1H <- cbind.data.frame("InSilicoOver1H", InSilicoOver1H)
colnames(InSilicoOver1H)[1] <- "Group"
InSilicoOver1 <- cbind.data.frame("InSilicoOver1", InSilicoOver1)
colnames(InSilicoOver1)[1] <- "Group"
InSilicoOver2 <- cbind.data.frame("InSilicoOver2", InSilicoOver2)
colnames(InSilicoOver2)[1] <- "Group"
train3 <- rbind.data.frame(train3, InSilicoBelow1, InSilicoOver1H, InSilicoOver1, InSilicoOver2)
  
# Make an extra dataframe in the column with two classes: present and absent
train3$Presence[train3$Abundance > 0.01] <- "Present"
train3$Presence[train3$Abundance <= 0.01] <- "Absent"
train3$Presence <- as.factor(train3$Presence)
Original$Presence[Original$Abundance > 0.01] <- "Present"
Original$Presence[Original$Abundance <= 0.01] <- "Absent"
Original$Presence <- as.factor(Original$Presence)

# Save the full dataframes to reload before the regression
train3full <- train3
            
# Feature selection step
train3Original <- train3[train3$Group == "Original",]
train3Original <- train3Original[colnames(train3Original) != "Group"]
train3Original <- train3Original[colnames(train3Original) != "Abundance"]
# Balance
if(!summary(train3Original$Presence)[1] == summary(train3Original$Presence)[2]){train3Original <- RandOverClassif(Presence ~ ., dat = train3Original, C.perc = "balance")}
# define the control using a random forest selection function
control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
# run the RFE algorithm
results <- rfe(x = train3Original[,!names(train3Original) == "Presence"], y = train3Original$Presence, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Presence"])[2], by = 2), rfeControl = control, metric = "Accuracy")
# summarize the results
print(results)
# plot the results
plot(results, type = c("g", "o"))
# Make selection
rfeout <- results$results
AbsoluteBest <- pickSizeBest(rfeout, metric = "Accuracy", maximize = TRUE)
Within1Perc <- pickSizeTolerance(rfeout, metric = "Accuracy",  tol = 0.5, maximize = TRUE)
if(results$results$Accuracy[results$results$Variables == AbsoluteBest] == 1){Within1Perc <- AbsoluteBest}
if(Within1Perc == 1){Within1Perc <- AbsoluteBest}
Keep <- results$optVariables[1:Within1Perc]
# list the chosen features
train3 <- train3[c("Group", Keep, "Abundance", "Presence")]
KeepClassifier <- Keep
            
# Make over 1 uniform
Train3Over <- train3[train3$Abundance >= 0.01,]
Train3Below <- train3[train3$Abundance < 0.01,]
RangeAbundances <- range(Train3Over$Abundance)
BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
CutAbundances <- cut(Train3Over$Abundance, BreaksAbundances, right = FALSE)
FrequencyAbundances <- table(CutAbundances)
CutOff <- round(median(FrequencyAbundances))
Subsampled <- NULL
for (k in 1:length(FrequencyAbundances)){
     # Get samples in the kth interval
     Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
     Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
     SelectedData <- Train3Over[Train3Over$Abundance >= Lower & Train3Over$Abundance < Upper,]
     # Subsample if there are more than "cutoff"
     if (dim(SelectedData)[1] > CutOff){
        SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
      } else {
        SelectedData <- SelectedData
      }
      # Store subsampled data
      Subsampled <- rbind(Subsampled, SelectedData)
}
Train3Over <- Subsampled
# Combine with the low abundant samples
train3 <- rbind.data.frame(Train3Over, Train3Below)
  
# Temporarily remove the abundance column
train3 <- train3[colnames(train3) != "Abundance"]
            
# Remove the "Group"-column
train3 <- train3[colnames(train3) != "Group"]
  
# Balance the classes
print(summary(train3$Presence))
if(!summary(train3$Presence)[1] == summary(train3$Presence)[2]){train3 <- RandUnderClassif(Presence ~ ., dat = train3, C.perc = "balance", repl = FALSE)}
print(summary(train3$Presence))
  
### Caret list
FitControl <- trainControl(method = "cv", number = 10, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Presence, k = 3, times = 1), classProbs = TRUE)
  
# Create tuning grid for the RF
   # Tune RF
   if (dim(train3)[2]-1 > 5) {
       mtryoptions <- seq(1, round(dim(train3[,!names(train3) == "Presence"])[2]/5), by = 1)
   } else {
      mtryoptions <- seq(1, dim(train3)[2]-1, by = 1)
   }
   tunegridRF <- expand.grid(.mtry = mtryoptions)

# Train models
model_listClassifier <- caretList(Presence ~ .,
                                  data = train3,
                                  trControl = FitControl,
                                  tuneList = list(RF = caretModelSpec(method = "rf", tuneGrid = tunegridRF, ntree = 500)))

# Get predictions
ens_preds <- predict(model_listClassifier$RF, newdata = Original, type = "raw")
ens_preds <- cbind.data.frame(ens_preds, Original$Presence)
colnames(ens_preds) <- c("Predicted", "Real")
rownames(ens_preds) <- rownames(Original)
PredRFC <- ens_preds
sum(PredRFC$Predicted == PredRFC$Real)/length(PredRFC$Predicted)


### REGRESSION ###
              # Temporarily remove the abundance column
              train3 <- train3full
              
              # Remove "Presence"-column
              train3 <- train3[colnames(train3) != "Presence"]
                   
              # Feature selection step
              train3Original <- train3[train3$Group == "Original",]
              train3Original <- train3Original[colnames(train3Original) != "Group"]
              # more homogeneous distribution
              train3OriginalLower <- train3Original[train3Original$Abundance < 0.01,]
              train3OriginalHigher <- train3Original[train3Original$Abundance >= 0.01,]
              if(dim(train3OriginalLower)[1] > dim(train3OriginalHigher)[1]){
                train3OriginalLower <- train3OriginalLower[sample(nrow(train3OriginalLower), dim(train3OriginalHigher)[1]), ]
              }
              train3Original <- rbind.data.frame(train3OriginalLower, train3OriginalHigher)
              # define the control using a random forest selection function
              control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
              # run the RFE algorithm
              results <- rfe(x = train3Original[,!names(train3Original) == "Abundance"], y = train3Original$Abundance, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Abundance"])[2], by = 2), rfeControl = control, metric = "Rsquared")
              # summarize the results
              print(results)
              # plot the results
              plot(results, type = c("g", "o"))
              # Make selection
              rfeout <- results$results
              if(sum(rfeout$Rsquared == 1) == length(rfeout$Rsquared)){
                Keep <- Keep
              } else {
                Within1Perc <- pickSizeTolerance(rfeout, metric = "Rsquared",  tol = 0.5, maximize = TRUE)
                AbsoluteBest <- pickSizeBest(rfeout, metric = "Rsquared", maximize = TRUE)
                Keep <- results$optVariables[1:Within1Perc]
              }
              # Get the chosen features
              train3 <- train3[c("Group", Keep, "Abundance")]
              KeepRegression <- Keep
              
              # Remove the group-column
              train3 <- train3[colnames(train3) != "Group"]
  
              # Reduce imbalance in the dataset
              RangeAbundances <- range(train3$Abundance)
              BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
              CutAbundances <- cut(train3$Abundance, BreaksAbundances, right = FALSE)
              FrequencyAbundances <- table(CutAbundances)
              CutOff <- round(median(FrequencyAbundances))
              Subsampled <- NULL
              for (k in 1:length(FrequencyAbundances)){
                # Get samples in the kth interval
                Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
                Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
                SelectedData <- train3[train3$Abundance >= Lower & train3$Abundance < Upper,]
                # Subsample if there are more than "cutoff"
                if (dim(SelectedData)[1] > CutOff){
                  SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                } else {
                  SelectedData <- SelectedData
                }
                # Store subsampled data
                Subsampled <- rbind(Subsampled, SelectedData)
              }
              train3 <- Subsampled
              
# Logit transformation --> ensure predictions are in the 0-1 range
train3$Abundance[train3$Abundance >= 1] <- 1 - minvalue/10
train3$Abundance[train3$Abundance <= 0] <- minvalue/10
train3$Abundance <- boot::logit(train3$Abundance)
  
### Caret list
FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Abundance, k = 3, times = 1), summaryFunction = mapeexpSummary)
              
# Create tuning grids
    # Tune SVMPoly
    C <- c(0.001, 0.01, 0.1, 1, 10, 100)
    degree <- c(1, 2, 3)
    scale <- c(1, 2)
    tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)
    # Tune gradient boost
    n.trees <- c(50, 100, 250, 500)
    interaction.depth <- c(1)
    shrinkage <- c(0.3, 0.2, 0.1, 0.05, 0.01)
    n.minobsinnode <- seq(1, 3, by = 1)
    tunegridGBM <- expand.grid(n.trees = n.trees, interaction.depth = interaction.depth, shrinkage = shrinkage, n.minobsinnode = n.minobsinnode)
  
# Train models
model_list <- caretList(Abundance ~ .,
                          data = train3,
                          trControl = FitControl,
                          tuneList = list(SVMPoly = caretModelSpec(method = "svmPoly", tuneGrid = tunegridSVMPoly, metric = "Rsquared"),
                                          GBM = caretModelSpec(method = "gbm", tuneGrid = tunegridGBM, metric = "Rsquared")))
  
# make ensemble
greedy_ensemble <- caretEnsemble(model_list, trControl = FitControl, metric = "Rsquared")
  
# Make predictions
ens_preds <- predict(greedy_ensemble, newdata = Original)
ens_preds <- cbind.data.frame(ens_preds, Original$Abundance)
colnames(ens_preds) <- c("Predicted", "Real")
rownames(ens_preds) <- rownames(Original)
  
# Reverse the logit transform
ens_preds$Predicted <- boot::inv.logit(ens_preds$Predicted)
  
### Combine predictions from the classifier and regression ###
Predictions <- as.data.frame(matrix(, nrow = length(Original$Abundance), ncol = 2))
colnames(Predictions) <- c("Predicted", "Real")
Predictions$Predicted <- ens_preds$Predicted
Predictions$Predicted[PredRFC$Predicted == "Absent"] <- 0
Predictions$Real <- ens_preds$Real
rownames(Predictions) <- rownames(train3)
              
  
# Plot
Predictions$Predicted <- 100*Predictions$Predicted
Predictions$Real <- 100*Predictions$Real
p_pred <- ggplot(Predictions, aes(x = Real, y = Predicted)) +
                            geom_point(shape = 21, size = 2) +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            ggtitle(OTUOfInterest) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
p_pred
# Performance metrics and plots           
RMSE(Predictions$Predicted, Predictions$Real)
MAE(Predictions$Predicted, Predictions$Real)
R2(Predictions$Predicted, Predictions$Real)


# Plot all predictions on the non-sorted samples
PredictionsNS <- Predictions[rownames(Predictions) %in% NonSorted,]
p_predNS <- ggplot(PredictionsNS, aes(x = Real, y = Predicted)) +
                            geom_point(shape = 21, size = 2) +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            ggtitle(OTUOfInterest) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
print(p_predNS)
# Performance metrics and plots           
RMSE(PredictionsNS$Predicted, PredictionsNS$Real)
MAE(PredictionsNS$Predicted, PredictionsNS$Real)
R2(PredictionsNS$Predicted, PredictionsNS$Real)
```

#### Make predictions

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Isometric log ratio transform
GMMALL2 <- cbind.data.frame(compositions::clr(GMMALL[,!names(GMMALL) == "Names"]), GMMALL$Names)
colnames(GMMALL2)[dim(GMMALL2)[2]] <- "Names"

# Predictions Classifier
          PredClass <- predict(model_listClassifier$RF, newdata = GMMALL2[,!names(GMMALL2) == "Names"], type = "raw")
          PredProbsClass <- predict(model_listClassifier$RF, newdata = GMMALL2[,!names(GMMALL2) == "Names"], type = "prob")["Present"]
          PredClass <- cbind.data.frame(PredClass, PredProbsClass, GMMALL2$Names)
          colnames(PredClass) <- c("Predicted", "ProbabilityPresent", "Names")
          PredRFC <- PredClass

# Predictions regression
          ens_preds <- predict(greedy_ensemble, newdata = GMMALL2[,!names(GMMALL2) == "Names"], type = "raw")
          ens_preds <- cbind.data.frame(ens_preds, GMMALL2$Names)
          colnames(ens_preds) <- c("Predicted", "Names")
          # Reverse the logit transform
          ens_preds$Predicted <- boot::inv.logit(ens_preds$Predicted)
          
# Combined predictions
          ### Combine predictions from the classifier and regression ###
          Predictions <- as.data.frame(matrix(, nrow = length(GMMALL2$Names), ncol = 2))
          colnames(Predictions) <- c("Names", "PredAbundance")
          Predictions$PredAbundance <- ens_preds$Predicted
          Predictions$PredAbundance[PredRFC$PredAbundance == "Absent"] <- 0
          Predictions$Names <- ens_preds$Names
          Predictions$PredClass <- PredRFC$Predicted
          Predictions$PredClassProb <- PredRFC$ProbabilityPresent 
```

#### Plot predictions

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Combine predictions, metadata and cell counts
Results <- left_join(Predictions, metadata, by = c("Names" = "FACS_names"))
Results <- Results[Results$Quality == "OK",]
Counts <- read.csv("Metadata/CellCounts.csv")
Counts <- Counts[c("Sample", "BacterialDensity")]
Counts$Sample <- gsub("Artemia", "Art", Counts$Sample)
Results <- left_join(Results, Counts, by = c("Sample" = "Sample"))
Results$Sample <- as.character(gsub(".A", "", Results$Sample))
Results$Sample <- as.character(gsub(".B", "", Results$Sample))
Results <- as.data.frame(Results)
Results <- Results[c("Sample", "Tank", "Day", "Timepoint", "Time_cont", "PredAbundance", "PredClass", "PredClassProb", "BacterialDensity")]

# Average predictions over the replicates
ResultsAverage <- NULL
for (j in unique(Results$Sample)){
  Selected <- Results[Results$Sample == j,]
  # Get averages over the replicates
  PredAbundance <- mean(Selected$PredAbundance)
  PredClassProbs <- mean(Selected$PredClassProb)
  BacterialDensity <- mean(Selected$BacterialDensity)
  AverageSelected <- cbind.data.frame(unique(Selected$Sample), unique(Selected$Tank), unique(Selected$Day), unique(Selected$Timepoint), unique(Selected$Time_cont), PredAbundance, PredClassProbs, BacterialDensity)
  # Check what the average predicted class is, and if necessary, correct the predicted value accordingly
  AverageSelected$PredClass <- "none"
  if (AverageSelected$PredClassProbs < 0.5){
    AverageSelected$PredClass <- "Absent"  
    AverageSelected$PredAbundance <- 0
  } else if (AverageSelected$PredClassProbs >= 0.5){
    AverageSelected$PredClass <- "Present"  
  }
  # Store results
  ResultsAverage <- rbind.data.frame(ResultsAverage, AverageSelected)
}
colnames(ResultsAverage) <- c("Sample", "Tank", "Day", "Timepoint", "Time_cont", "PredAbundance", "PredClassProb", "BacterialDensity", "PredClass")

# Get samples for which Illumina data is available
  # Data of the selected otus
  OTUOfInterest <- OTUPreprocessed$OTU[i]
  OTUAbundances <- OTUPreprocessed[OTUPreprocessed$OTU == OTUOfInterest,]
  OTUAbundances <- cbind.data.frame(names(OTUAbundances), as.numeric(paste(OTUAbundances)))[-1,]
  colnames(OTUAbundances) <- c("ID", "Abundance")

  # Get correspondingsamplenames
  Dataset <- left_join(GMMOut, IdentifiersBoth, by = c("Names" = "FACS_names"))
  Dataset <- left_join(Dataset, OTUAbundances, by = c("Identifier" = "ID"))
  Dataset <- Dataset[!is.na(Dataset$Identifier),]
  rownames(Dataset) <- Dataset$Identifier
  Dataset <- Dataset[c("Abundance", "X1")]
  colnames(Dataset) <- c("TrueAbundance", "Sample")
  Dataset$Sample <- as.character(gsub(".B", "", Dataset$Sample))
  Dataset$Sample <- as.character(gsub(".A", "", Dataset$Sample))
  Dataset$TrueClass <- "Absent"
  Dataset$TrueClass[Dataset$TrueAbundance > 0.005] <- "Present"
  Dataset <- Dataset[rownames(Dataset) %in% NonSorted,]

  # Combine predictions and true values for plotting
  ResultsAverage <- left_join(ResultsAverage, Dataset, by = c("Sample"))
  
  # If measured is available, replace the measured value by the predicted one
  ResultsAverage$PredClass[!is.na(ResultsAverage$TrueAbundance)] <- ResultsAverage$TrueClass[!is.na(ResultsAverage$TrueAbundance)] 
  ResultsAverage$PredAbundance[!is.na(ResultsAverage$TrueAbundance)] <- ResultsAverage$TrueAbundance[!is.na(ResultsAverage$TrueAbundance)] 
  
  # Add a column for "Predicted" vs. "Measured" samples
  ResultsAverage$Category <- "Measured"
  ResultsAverage$Category[is.na(ResultsAverage$TrueAbundance)] <- "Predicted"
  ResultsAverage$CategoryWithLabel <- paste(ResultsAverage$PredClass, "-", ResultsAverage$Category)
  ResultsAverage$PredAbsAbundance <- ResultsAverage$PredAbundance * ResultsAverage$BacterialDensity
  
  # Dataframe of only measured samples
  ResultsAverageM <- ResultsAverage[ResultsAverage$Category == "Measured",]
  ResultsAverageM <- ResultsAverageM %>%
                     dplyr::filter(Tank %in% c("T1","T2","T3","T4","T5")) %>%
                     dplyr::filter(Timepoint %in% c(1, 2, 3, 4, 5, 6, 7, 8))
  
  # Plot
  p_abundances_Classifier <- ResultsAverage %>%
                    dplyr::filter(Tank %in% c("T1","T2","T3","T4","T5")) %>%
                    dplyr::filter(Timepoint %in% c(1, 2, 3, 4, 5, 6, 7, 8)) %>%
                    ggplot(data = ., aes(x = Time_cont, y = 1, fill = CategoryWithLabel)) +
                    geom_bar(stat = "identity", colour = "black") +
                    facet_grid(Tank ~ .) +
                    ylab("xxx") +
                    xlab("Time (d)") +
                    guides(fill = guide_legend(nrow = 2, byrow = TRUE)) +
                    scale_fill_manual("", values = c("#d67002", "#f4d866", "#0f3057", "#5899d1")) +
                    scale_x_continuous(limits = c(2, 19), expand = c(0, 0)) +
                    theme_cowplot() +
                    theme(legend.text.align = 0, plot.title = element_text(hjust = 0.5), axis.text.y = element_text(color = "white", size = 14), axis.ticks.y = element_blank(), panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), legend.position = "top", legend.justification = 'center', axis.title.y = element_text(color = "white", size = 14, face = "bold"))
  print(p_abundances_Classifier)
  
  p_abundances_Final <- ResultsAverage %>%
                    dplyr::filter(Tank %in% c("T1","T2","T3","T4","T5")) %>%
                    dplyr::filter(Timepoint %in% c(1, 2, 3, 4, 5, 6, 7, 8)) %>%
                    ggplot(data = ., aes(x = Time_cont, y = 100*PredAbundance, fill = Category)) +
                    geom_bar(stat = "identity", colour = "black") +
                    geom_line(data = ResultsAverageM, aes(x = Time_cont, y = 100*PredAbundance), color = "#420c59") +
                    facet_grid(Tank ~ .) +
                    ylab("Relative abundance (%)") +
                    xlab("Time (d)") +
                    scale_fill_manual("", values = c("#420c59", "#c49fd4")) +
                    scale_x_continuous(limits = c(2, 19), expand = c(0, 0)) +
                    scale_y_continuous(limits = c(0, 100), expand = c(0, 0)) +
                    theme_cowplot() +
                    theme(legend.text.align = 0, plot.title = element_text(hjust = 0.5), panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), legend.position = "top", legend.justification = 'center') # panel.spacing = unit(2, "lines")
  print(p_abundances_Final)
  
  p_absabundances_Final <- ResultsAverage %>%
                    dplyr::filter(Tank %in% c("T1","T2","T3","T4","T5")) %>%
                    dplyr::filter(Timepoint %in% c(1, 2, 3, 4, 5, 6, 7, 8)) %>%
                    ggplot(data = ., aes(x = Time_cont, y = PredAbsAbundance, fill = Category)) +
                    geom_bar(stat = "identity", colour = "black") +
                    geom_line(data = ResultsAverageM, aes(x = Time_cont, y = PredAbsAbundance), color = "#00473c") +
                    facet_grid(Tank ~ .) +
                    ylab("Absolute abundance (cells/mL)") +
                    xlab("Time (d)") +
                    scale_fill_manual("", values = c("#00473c", "#85cca8")) +
                    scale_x_continuous(limits = c(2, 19), expand = c(0, 0)) +
                    theme_cowplot() +
                    theme(legend.text.align = 0, plot.title = element_text(hjust = 0.5), panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), legend.position = "top", legend.justification = 'center') # panel.spacing = unit(2, "lines")
  print(p_absabundances_Final)
  
  
  ## Assembled plot
  g3 <- plot_grid(p_abundances_Classifier, p_abundances_Final, p_absabundances_Final, labels = c("A", "B", "C"), ncol = 1, nrow = 3, scale = 1, rel_heights = c(0.85, 1, 1))
  ggsave(file = paste("Figures/DATASET-", i, "-Vertical.png", sep = ""), width = 8, height = 14, dpi = 500, units = "in", g3)

# Remove variables that are no longer needed
rm(list = ls())
# Load convenience funtions
source("ConvenienceFunctions.R")
```

# Reactor dataset (validation 1)

### Upload and process FCM and community compositions data

```{r LoadLibraries, message = FALSE, warning = FALSE}
# Upload data
Datapath <- c("./Data/Reactor/FCM/")
fcsfiles <- list.files(path = Datapath, recursive = TRUE, pattern = ".fcs", full.names = TRUE)
flowData <- flowCore::read.flowSet(files = fcsfiles, pattern = ".fcs")

# Remove all variables that are no longer needed
remove(Datapath, fcsfiles)
```

```{r AccuriC6_MakeMetadataFromSamplenames, echo = TRUE, dpi = 500, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = FALSE}
names <- cbind.data.frame(flowCore::sampleNames(flowData), do.call(rbind, lapply(strsplit(flowCore::sampleNames(flowData),"_"), rbind)))
colnames(names) <- c("samplename", "date", "Group")
names$Group <- as.character(gsub(".fcs", "", names$Group))
# Make metadata from sample names
metadata <- readxl::read_excel("./Metadata/REACTOR-MetadataFCM.xlsx")
metadata$date <- as.character(metadata$date)
metadata <- left_join(names, metadata, by = c("date", "Group"))
# Remove variables that are no longer needed
remove(names)
```

```{r AccuriC6_MakeMetadataFromSamplenames, echo = TRUE, dpi = 500, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = FALSE}
# Make metadata from sample names
OTUtable <- readxl::read_excel("./Metadata/REACTOR-MetadataIllumina.xlsx", sheet = 1)
Taxonomy <- readxl::read_excel("./Metadata/REACTOR-MetadataIllumina.xlsx", sheet = 2)
SampleInfo <- readxl::read_excel("./Metadata/REACTOR-MetadataIllumina.xlsx", sheet = 3)

# Singlet removal: 10576 reads are retained (see Supporting Information of Liu et al)
OTU <- as.matrix(OTUtable[,-1])
rownames(OTU) <- OTUtable$Name
OTU <- otu_table(OTU, taxa_are_rows = FALSE)
TAX <- as.matrix(Taxonomy)
rownames(TAX) <- Taxonomy$OTU
TAX <- tax_table(Taxonomy)
taxa_names(TAX) <- Taxonomy$OTU
physeqobj <- phyloseq(OTU, TAX)

# Do the scaling is already OK
sample_sums(physeqobj)

# Calculate relative abundances 
otuabundances <- OTUtable[!colnames(OTUtable) == "Name"]
otuabundances <- as.matrix(otuabundances)
otuabundances <- sweep(otuabundances, 1, rowSums(otuabundances), `/`)
OTUtable <- cbind.data.frame(OTUtable$Name, otuabundances)
colnames(OTUtable)[1] <- "Name"

# Remove non abundant OTUs
OTUtable <- OTUtable[,-1]
OTUtable <- OTUtable[,colSums(OTUtable > 0.01) > 1] # Remove OTUs that are not at least once abundant
OTUs <- colnames(OTUtable)[-1]
OTUtable <- sweep(OTUtable, 1, rowSums(OTUtable), `/`)
OTUtable$Name <- rownames(OTU)

# Combine available info
df <- left_join(SampleInfo, metadata, by = c("Day" = "day", "Reactor" = "Group"))
df <- left_join(df, OTUtable, by = c("Name" = "Name"))
df <- as.data.frame(df)
df <- df[df$Gate == "Whole community",]
dfOTUTable <- df

fcsnames <- df$samplename[!is.na(df$samplename)]
```

```{r AccuriC6_AsinhTransform, echo = TRUE, dpi = 500, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = FALSE}
# Keep only samples for which there is Illuminadata
flowData <- flowData[fcsnames]

# Transform data
flowData_transformed <- flowCore::transform(flowData,
                                      `PMT 1` = asinh(`PMT 1`),
                                      `PMT 2` = asinh(`PMT 2`),
                                      `PMT 3` = asinh(`PMT 3`),
                                      `PMT 4` = asinh(`PMT 4`),
                                      `PMT 5` = asinh(`PMT 5`),
                                      `PMT 6` = asinh(`PMT 6`),
                                      `PMT 7` = asinh(`PMT 7`),
                                      `PMT 8` = asinh(`PMT 8`),
                                      `PMT 9` = asinh(`PMT 9`),
                                      `PMT 10` = asinh(`PMT 10`),
                                      `PMT 11` = asinh(`PMT 11`),
                                      `PMT 12` = asinh(`PMT 12`),
                                      `PMT 13` = asinh(`PMT 13`),
                                      `PMT 14` = asinh(`PMT 14`))
# Remove variables that are no longer needed
remove(flowData)
```

```{r AccuriC6_ApplyGate, echo = TRUE, dpi = 500, out.width = "70%", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = FALSE, fig.show = 'hold'}
sqrcut1 <- matrix(c(1.2, 1.2, 2, 5, 6, 6, 7.2, 8, 8, 4.4,
                    1.3, 5.7, 5.7, 6.2, 8, 8, 8, 8, 7, 1.3),
                     ncol = 2,
                     nrow = 10)
colnames(sqrcut1) <- c("PMT 1", "PMT 9")
polyGate <- polygonGate(.gate = sqrcut1, filterId = "Cells")
# Gating quality check
for (i in base::sample(1:length(flowData_transformed), size = 5)) {
  print(xyplot(`PMT 9` ~ `PMT 1`, data = flowData_transformed[i],
              filter = polyGate,
              scales = list(y = list(limits = c(1,10)),
                            x = list(limits = c(0,10))),
              axis = axis.default,
              nbin = 125,
              par.strip.text = list(col = "black", font = 3, cex = 0.75),
              smooth = FALSE))
}
# Remove variables that are no longer needed
remove(sqrcut1, i)
```

```{r AccuriC6Plus_ApplyGating, echo = TRUE, dpi = 500, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = TRUE, results = "hide"}
# Apply gate on samples
flowData_transformed <- Subset(flowData_transformed, polyGate)

# # Calculate cell densities
# # Cellcounts
# Count <- flowCore::filter(flowData_transformed, polyGate)
# Count <- toTable(summary(Count))
# metadata <- dplyr::left_join(metadata, Count[c("sample", "true")], by = c("samplename" = "sample"))
# colnames(metadata)[6] <- "Count"
# # Volume
# vol <- as.numeric(flowCore::fsApply(flowData_transformed, FUN = function(x) x@description$`$VOL`))/1000
# # Cell densities
# CellDensities

```

```{r AccuriC6_NormaliseDataOnFL1, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
summary <- fsApply(x = flowData_transformed, FUN = function(x) apply(x, 2, max), use.exprs = TRUE)
maxval <- max(summary[,"PMT 9"])
mytrans <- function(x) x/maxval
flowData_transformed <- transform(flowData_transformed,
                                  `PMT 1` = mytrans(`PMT 1`),
                                  `PMT 2` = mytrans(`PMT 2`),
                                  `PMT 9` = mytrans(`PMT 9`))
remove(mytrans, summary, maxval) # not needed further
```

```{r Mock_GenerateGMM, echo = TRUE, dpi = 500, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = FALSE,  results = "hide"}
# Parameters to take into account for the model
# paramGMM <- c("PMT 1", "PMT 9")
# Subsample to lower sample size to make the training faster
# flowData_transformed <- FCS_resample(flowData_transformed, replace = TRUE, sample = 20000)
# fcs_x <- flowData_transformed[, paramGMM]
# fcs_x <- Phenoflow::FCS_pool(fcs_x, stub = "*")
# fcs_x <- fcs_x[, paramGMM] # The FCS_pool makes an extra column called "Original" which we don't need
# Check different number of clusters
# gmm_clust <- Mclust(data = exprs(fcs_x[[1]]), G = seq(from = 1, to = 100, by = 5))
# saveRDS(object = gmm_clust, file = "Data/ValidationSets/Mock/GMMs_Mock_1to100per5_V2.rds")
# # Check different number of clusters
# gmm_clustII <- Mclust(data = exprs(fcs_x[[1]]), G = seq(from = 30, to = 35, by = 1))
# saveRDS(object = gmm_clustII, file = "Data/ValidationSets/Mock/GMMs_Mockou_30to35per1.rds")
```

```{r Mock_ApplyGMM, echo = TRUE, dpi = 500, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = FALSE,  results = "hide"}
# Upload the GMM
gmm_clust <- readRDS(file = "Results/GMMFits/GMMs_Liu_1to100per5_V3_3param.rds")

# Plot the BIC values for the different models to see the optimization
NoClusters <- dimnames(gmm_clust$BIC)[[1]]
BICValues <- data.frame(as.matrix(gmm_clust$BIC)[1:length(NoClusters),])
BICValues$NoClusters <- rownames(BICValues)
BICValues <- reshape2::melt(BICValues, id.vars = "NoClusters")
colnames(BICValues) <- c("NoClusters", "ModelType", "BIC")
BICValues$NoClusters <- as.numeric(BICValues$NoClusters)
BICValues <- BICValues[!is.na(BICValues$BIC),] # remove the NA values
BICValues$ModelType <- droplevels(BICValues$ModelType, except = unique(BICValues$ModelType))# remove levels that are not being used
p_bic <- BICValues %>% 
          ggplot(data = ., aes(x = NoClusters, y = BIC)) +
          geom_line(alpha = 1, aes(color = ModelType), show.legend = F) +
          geom_point(shape = 21, size = 3, alpha = 1, aes(fill = ModelType)) +
          labs(x = "Number of clusters", y = "BIC", fill = "Model type") +
          theme_cowplot() +
          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
print(p_bic)


#
# flowData_transformed <- FCS_resample(flowData_transformed, sample = 20000)

# Apply GMM mask to the data
NumberOfClusters <- gmm_clust$G
params_gmm <- colnames(gmm_clust$data)
flowData_transformed <- flowData_transformed[, params_gmm] # subset to the relevant parameters
GMMOut <- data.frame(matrix(nrow = NumberOfClusters+1, ncol = length(flowData_transformed))) # Initialize a df to store the results of the predictions
rownames(GMMOut) <- c(1:NumberOfClusters, "(Other)")
for (i in 1:length(flowData_transformed)){
    RawData <- flowData_transformed[[i]]@exprs
    GMMPred <- predict(gmm_clust, RawData)
    GMMPred <- as.factor(GMMPred$classification)
    Summary <- summary(GMMPred)
    Summary <- Summary[rownames(GMMOut)] # Reorganise to the same order as the df that was initialised above
    GMMOut[,i] <- Summary
}
# Replace the NA values by 0
GMMOut[is.na(GMMOut)] <- 0
rownames(GMMOut) <- c(paste("GMM", 1:NumberOfClusters, sep = ""), "Other")
colnames(GMMOut) <- sampleNames(flowData_transformed)
# Normalise the GMM abundances to sum = 1
GMMOut <- sweep(GMMOut, 2, colSums(GMMOut), `/`)
GMMOut <- t(GMMOut)
GMMOut <- as.data.frame(GMMOut)
GMMOut$Names <- rownames(GMMOut)

# Remove variables that are no longer needed 
remove(p_bic, RawData, Summary, gmm_clust, NoClusters, BICValues, flowData_transformed, params_gmm, i, GMMPred)
```

### Train models

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
REACTOR_PerformancePerFold_ALL_NIS <- NULL
REACTOR_PredictionsPerFold_ALL_NIS <- NULL
REACTOR_PerformanceDataset_ALL_NIS <- NULL

for (i in 1:20){
  
  # Select OTU of interest
  TaxonOfInterest <- OTUs[i]
  TaxonAbundances <- dfOTUTable[, c("samplename", TaxonOfInterest)]
  colnames(TaxonAbundances) <- c("Names", "Abundance")

  # Combine the features and measured variables
  Dataset <- left_join(TaxonAbundances, GMMOut, by = c("Names" = "Names"))
  Dataset <- Dataset[complete.cases(Dataset),]
  rownames(Dataset) <- Dataset$Names
  Dataset <- Dataset[, -which(names(Dataset) %in% c("Names"))]

  if(length(unique(Dataset$Abundance[Dataset$Abundance>0.01])) > 3){ # Extra check for missing OTUs in a subset of the data

      # Centered log ratio transform
      Dataset <- cbind.data.frame(compositions::clr(Dataset[,!names(Dataset) == "Abundance"]), Dataset$Abundance)
      colnames(Dataset)[dim(Dataset)[2]] <- "Abundance"

      # Save dataset to reload it later
      DatasetFull <- Dataset[order(Dataset$Abundance),]

      # Model
      for (rep in 1:3){
      AllPredictions <- NULL
      AllPredictionsReg <- NULL
      ClassificationProbabilities <- NULL
      # Split data into folds
      NumberOfFolds <- 5
      Set1 <- 1
      Set2 <- 2
      Set3 <- 3
      Set4 <- 4
      Set5 <- 5
      Sets <- c("Set1", "Set2", "Set3", "Set4", "Set5")
      for (k in 1:(floor(dim(Dataset)[1]/NumberOfFolds)-1)){
        # Get indices
        Set1 <- c(Set1, k*NumberOfFolds)
        Set2 <- c(Set2, (k*NumberOfFolds)+1)
        Set3 <- c(Set3, (k*NumberOfFolds)+2)
        Set4 <- c(Set4, (k*NumberOfFolds)+3)
        Set5 <- c(Set5, (k*NumberOfFolds)+4)
      }
      if(max(Set5) < dim(Dataset)[1]){
        NUmberLeft <- dim(Dataset)[1] - max(Set5)
        for (l in 1:NUmberLeft){
          assign(Sets[l], c(get(Sets[l]), max(Set5) + l))
        }
      }
      if(rep %in% c(2,3)){
        NumberOfSwitches <- round(length(Set5)/3)
        for (pos in 1:NumberOfSwitches){
          Set1[rep*pos] <- Set2[rep*pos]
          Set2[rep*pos] <- Set3[rep*pos]
          Set3[rep*pos] <- Set4[rep*pos]
          Set4[rep*pos] <- Set5[rep*pos]
          Set5[rep*pos] <- Set1[rep*pos]
        }
      }
      # If one of the sets had an element less it might have generated NA
      Set1 <- Set1[!is.na(Set1)]
      Set2 <- Set2[!is.na(Set2)]
      Set3 <- Set3[!is.na(Set3)]
      Set4 <- Set4[!is.na(Set4)]
      Set5 <- Set5[!is.na(Set5)]
      # Combine in a list
      Folds <- list(Fold1 = Set1, Fold2 = Set2, Fold3 = Set3, Fold4 = Set4, Fold5 = Set5)
      # Train and evaluate
      for (fold in 1:length(Folds)){
            Dataset <- DatasetFull
            GMMNames <- colnames(Dataset)[!colnames(Dataset) == "Abundance"]

            # Selected fold
            Testindices <- Folds[[fold]]
            train3 <- Dataset[-Testindices, ]
            test3 <- Dataset[Testindices, ]

            # Transformation --> ensure predictions are in the 0-1 range to allow logit transformation later
            minvalue <- min(train3$Abundance[train3$Abundance > 0])

            # Get number of samples with low abundance (i.e. < 0.01) and high abundance (i.e. > 0.01)
            Below1 <- train3[train3$Abundance < 0.01,]
            Over1 <- train3[train3$Abundance >= 0.01,]

            #
            TotalNew <- 500
            NumberOfBelow1 <- dim(Below1)[1]
            NumberOfOver1 <- dim(Over1)[1]
            NumberOfOver1ToMake <- round(NumberOfBelow1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
            NumberOfBelow1ToMake <- round(NumberOfOver1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
            if(NumberOfOver1ToMake < TotalNew/2) NumberOfOver1ToMake <- TotalNew/2
            if(NumberOfBelow1ToMake < TotalNew/2) NumberOfBelow1ToMake <- TotalNew/2
            if(dim(Below1)[1] == 1){
              NumberOfBelow1ToMake <- 0
              NumberOfOver1ToMake <- TotalNew
            }

            # Max random variation (1000x smaller than the smallest value)
            RandValPredictorVals <- colMins(as.matrix(abs(train3[, !names(train3) == "Abundance"])))/100
            RandValOutput <- min(abs(train3$Abundance[train3$Abundance > 0]))/100
            RandGMMVals <- NULL
            RandAbundVals <- NULL

            # Fake zero's
            InSilicoBelow1 <- NULL
            for (j in 1:round(NumberOfBelow1ToMake*1)){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSamples <- round(runif(2, min = 1, max = dim(Below1)[1]))
              Sample1 <- Below1[SelectedSamples[1],]
              Sample2 <- Below1[SelectedSamples[2],]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoBelow1 <- rbind.data.frame(InSilicoBelow1, New)
            }

            # Fake abundant using only abundant samples
            InSilicoOver1H <- NULL
            Over1High <- Over1[mean(Over1$Abundance) < Over1$Abundance,]
            for (j in 1:round(NumberOfOver1ToMake*(1))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample1 <- Over1High[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample2 <- Over1High[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver1H <- rbind.data.frame(InSilicoOver1H, New)
            }

            # Fake abundant using only abundant samples
            InSilicoOver1 <- NULL
            for (j in 1:round(NumberOfOver1ToMake*(1/2))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
              Sample1 <- Over1[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample2 <- Over1High[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver1 <- rbind.data.frame(InSilicoOver1, New)
            }

            # Fake samples mixed between low and high abundances
            InSilicoOver2 <- NULL
            for (j in 1:round(NumberOfOver1ToMake*(1/2))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
              Sample1 <- Over1[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Below1)[1]))
              Sample2 <- Below1[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver2 <- rbind.data.frame(InSilicoOver2, New)
            }

            # Combine the in sillico samples with the original data
            train3 <- cbind.data.frame("Original", train3)
            colnames(train3)[1] <- "Group"
            InSilicoBelow1 <- cbind.data.frame("InSilicoBelow1", InSilicoBelow1)
            colnames(InSilicoBelow1)[1] <- "Group"
            InSilicoOver1H <- cbind.data.frame("InSilicoOver1H", InSilicoOver1H)
            colnames(InSilicoOver1H)[1] <- "Group"
            InSilicoOver1 <- cbind.data.frame("InSilicoOver1", InSilicoOver1)
            colnames(InSilicoOver1)[1] <- "Group"
            InSilicoOver2 <- cbind.data.frame("InSilicoOver2", InSilicoOver2)
            colnames(InSilicoOver2)[1] <- "Group"
            train3 <- rbind.data.frame(train3, InSilicoBelow1, InSilicoOver1H, InSilicoOver1, InSilicoOver2)

            # Make an extra dataframe in the column with two classes: present and absent
            train3$Presence[train3$Abundance > 0.01] <- "Present"
            train3$Presence[train3$Abundance <= 0.01] <- "Absent"
            train3$Presence <- as.factor(train3$Presence)
            test3$Presence[test3$Abundance > 0.01] <- "Present"
            test3$Presence[test3$Abundance <= 0.01] <- "Absent"
            test3$Presence <- as.factor(test3$Presence)

            # Save the full dataframes to reload before the regression
            train3full <- train3
            test3full <- test3

            # Feature selection step
            train3Original <- train3[train3$Group == "Original",]
            train3Original <- train3Original[colnames(train3Original) != "Group"]
            train3Original <- train3Original[colnames(train3Original) != "Abundance"]
            # # Balance
            if(!summary(train3Original$Presence)[1] == summary(train3Original$Presence)[2]){train3Original <- RandOverClassif(Presence ~ ., dat = train3Original, C.perc = "balance")}
            # define the control using a random forest selection function
            control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
            # run the RFE algorithm
            results <- rfe(x = train3Original[,!names(train3Original) == "Presence"], y = train3Original$Presence, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Presence"])[2], by = 2), rfeControl = control, metric = "Accuracy")
            # plot the results
            plot(results, type = c("g", "o"))
            # Make selection
            rfeout <- results$results
            AbsoluteBest <- pickSizeBest(rfeout, metric = "Accuracy", maximize = TRUE)
            Within1Perc <- pickSizeTolerance(rfeout, metric = "Accuracy",  tol = 0.5, maximize = TRUE)
            if(results$results$Accuracy[results$results$Variables == AbsoluteBest] == 1){Within1Perc <- AbsoluteBest}
            if(Within1Perc == 1){Within1Perc <- AbsoluteBest}
            Keep <- results$optVariables[1:Within1Perc]
            KeepClassifier <- Keep
            # list the chosen features
            train3 <- train3[c("Group", Keep, "Abundance", "Presence")]
            test3 <- test3[c(Keep, "Abundance", "Presence")]

            # Make over 1 uniform
            Train3Over <- train3[train3$Abundance >= 0.01,]
            Train3Below <- train3[train3$Abundance < 0.01,]
            RangeAbundances <- range(Train3Over$Abundance)
            BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
            CutAbundances <- cut(Train3Over$Abundance, BreaksAbundances, right = FALSE)
            FrequencyAbundances <- table(CutAbundances)
            CutOff <- round(median(FrequencyAbundances))
            Subsampled <- NULL
            for (k in 1:length(FrequencyAbundances)){
              # Get samples in the kth interval
              Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
              Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
              SelectedData <- Train3Over[Train3Over$Abundance >= Lower & Train3Over$Abundance < Upper,]
              # Subsample if there are more than "cutoff"
              if (dim(SelectedData)[1] > CutOff){
                  SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                } else {
                  SelectedData <- SelectedData
                }
                # Store subsampled data
                Subsampled <- rbind(Subsampled, SelectedData)
              }
            Train3Over <- Subsampled
            # Combine with the low abundant samples
            train3 <- rbind.data.frame(Train3Over, Train3Below)

            # Temporarily remove the abundance column
            train3 <- train3[colnames(train3) != "Abundance"]
            test3 <- test3[colnames(test3) != "Abundance"]

            # Remove the "Group"-column
            train3 <- train3[colnames(train3) != "Group"]
            test3 <- test3[colnames(test3) != "Group"]

            # Balance the classes
            print(summary(train3$Presence))
            if(!summary(train3$Presence)[1] == summary(train3$Presence)[2]){train3 <- RandUnderClassif(Presence ~ ., dat = train3, C.perc = "balance", repl = FALSE)}
            print(summary(train3$Presence))

            ### Caret list
            FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Presence, k = 3, times = 1), classProbs = TRUE)

                # Create tuning grid for the RF
                    # Tune RF
                    if (dim(train3)[2]-1 > 5) {
                      mtryoptions <- seq(1, round(dim(train3[,!names(train3) == "Presence"])[2]/5), by = 1)
                    } else {
                      mtryoptions <- seq(1, dim(train3)[2]-1, by = 1)
                    }
                    tunegridRF <- expand.grid(.mtry = mtryoptions)
                    # Tune SVMPoly
                    C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                    degree <- c(1, 2, 3)
                    scale <- c(1, 2)
                    tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)

                # Train models
                model_listClassifier <- caretList(Presence ~ .,
                                        data = train3,
                                        trControl = FitControl,
                                        tuneList = list(RF = caretModelSpec(method = "rf", tuneGrid = tunegridRF, ntree = 500)))

              # Get predictions
              if(dim(test3)[2] == 2){
                testset <- as.data.frame(test3[,!names(test3) == "Presence"])
                colnames(testset) <- colnames(test3[1])
              } else {
                testset <- as.data.frame(test3[,!names(test3) == "Presence"])
              }
              ens_preds <- predict(model_listClassifier$RF, newdata = testset, type = "raw")
              ens_preds <- cbind.data.frame(ens_preds, test3$Presence)
              colnames(ens_preds) <- c("Predicted", "Real")
              rownames(ens_preds) <- rownames(test3)
              PredRFC <- ens_preds

              # Compute and save prediction probabilities
              ClassProb <- predict(model_listClassifier$RF, newdata = testset, type = "prob")
              ClassificationProbabilities <- rbind.data.frame(ClassificationProbabilities, cbind.data.frame(as.numeric(test3$Presence == "Absent"), ClassProb["Absent"]))
              # ROC <- roc(as.numeric(test3$Presence == "Absent"), ClassProbs$Absent)
              # AUC <- auc(ROC)
              # print(AUC[1])
              
              
              # Get feature importances
                  # From the model
                  ImportancesRF <- t(as.data.frame(varImp(model_listClassifier$RF)["importance"]))
                  # Features that were removed
                  RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesRF)]
                  ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                  names(ImportancesRemoved) <- RemovedFeatures
                  #
                  ImportancesClassifier <- cbind.data.frame(ImportancesRF, ImportancesRemoved)
                  ImportancesClassifier <- ImportancesClassifier[,GMMNames]
                  names(ImportancesClassifier) <- paste(names(ImportancesClassifier), "_Class", sep = "")



              ### REGRESSION ###
              # Temporarily remove the abundance column
              train3 <- train3full
              test3 <- test3full

              # Remove "Presence"-column
              train3 <- train3[colnames(train3) != "Presence"]
              test3 <- test3[colnames(test3) != "Presence"]

              # Feature selection step
              train3Original <- train3[train3$Group == "Original",]
              train3Original <- train3Original[colnames(train3Original) != "Group"]
              # more homogeneous distribution
              train3OriginalLower <- train3Original[train3Original$Abundance < 0.01,]
              train3OriginalHigher <- train3Original[train3Original$Abundance >= 0.01,]
              if(dim(train3OriginalLower)[1] > dim(train3OriginalHigher)[1]){
                train3OriginalLower <- train3OriginalLower[sample(nrow(train3OriginalLower), dim(train3OriginalHigher)[1]), ]
              }
              train3Original <- rbind.data.frame(train3OriginalLower, train3OriginalHigher)
              if(dim(train3Original)[1] > 10){
                    # define the control using a random forest selection function
                    control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
                    # run the RFE algorithm
                    results <- rfe(x = train3Original[,!names(train3Original) == "Abundance"], y = train3Original$Abundance, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Abundance"])[2], by = 2), rfeControl = control, metric = "Rsquared")
                    # plot the results
                    plot(results, type = c("g", "o"))
                    # Make selection
                    rfeout <- results$results
                    if(sum(rfeout$Rsquared == 1) == length(rfeout$Rsquared)){
                      Keep <- Keep
                    } else {
                      Within1Perc <- pickSizeTolerance(rfeout, metric = "Rsquared",  tol = 0.5, maximize = TRUE)
                      Keep <- results$optVariables[1:Within1Perc]
                    }
                    # Get the chosen features
                    train3 <- train3[c("Group", Keep, "Abundance")]
                    test3 <- test3[c(Keep, "Abundance")]
              }

              # Remove the group-column
              train3 <- train3[colnames(train3) != "Group"]

              # Reduce imbalance in the dataset
              RangeAbundances <- range(train3$Abundance)
              BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
              CutAbundances <- cut(train3$Abundance, BreaksAbundances, right = FALSE)
              FrequencyAbundances <- table(CutAbundances)
              CutOff <- round(median(FrequencyAbundances))
              Subsampled <- NULL
              for (k in 1:length(FrequencyAbundances)){
                # Get samples in the kth interval
                Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
                Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
                SelectedData <- train3[train3$Abundance >= Lower & train3$Abundance < Upper,]
                # Subsample if there are more than "cutoff"
                if (dim(SelectedData)[1] > CutOff){
                  SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                } else {
                  SelectedData <- SelectedData
                }
                # Store subsampled data
                Subsampled <- rbind(Subsampled, SelectedData)
              }
              train3 <- Subsampled

              # Logit transformation --> ensure predictions are in the 0-1 range
              train3$Abundance[train3$Abundance >= 1] <- 1 - minvalue/10
              train3$Abundance[train3$Abundance <= 0] <- minvalue/10
              train3$Abundance <- boot::logit(train3$Abundance)

              ### Caret list
              FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Abundance, k = 3, times = 1), summaryFunction = mapeexpSummary)
                  # Create tuning grids
                      # Tune SVMPoly
                      C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                      degree <- c(1, 2, 3)
                      scale <- c(1, 2)
                      tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)
                      # Tune gradient boost
                      n.trees <- c(50, 100, 250, 500)
                      interaction.depth <- c(1)
                      shrinkage <- c(0.3, 0.2, 0.1, 0.05, 0.01)
                      n.minobsinnode <- seq(1, 3, by = 1)
                      tunegridGBM <- expand.grid(n.trees = n.trees, interaction.depth = interaction.depth, shrinkage = shrinkage, n.minobsinnode = n.minobsinnode)

                  # Train models
                  model_list <- caretList(Abundance ~ .,
                                        data = train3,
                                        trControl = FitControl,
                                        tuneList = list(SVMPoly = caretModelSpec(method = "svmPoly", tuneGrid = tunegridSVMPoly, metric = "Rsquared"),
                                                        GBM = caretModelSpec(method = "gbm", tuneGrid = tunegridGBM, metric = "Rsquared")))

              # make ensemble
              greedy_ensemble <- caretEnsemble(model_list, trControl = FitControl, metric = "Rsquared")

              # Make predictions
              if(dim(test3)[2] == 2){
                testset <- as.data.frame(test3[,!names(test3) == "Abundance"])
                colnames(testset) <- colnames(test3[1])
              } else {
                testset <- as.data.frame(test3[,!names(test3) == "Abundance"])
              }
              ens_preds <- predict(greedy_ensemble, newdata = testset)
              ens_preds <- cbind.data.frame(ens_preds, test3$Abundance)
              colnames(ens_preds) <- c("Predicted", "Real")
              rownames(ens_preds) <- rownames(test3)

              # Reverse the logit transform
              ens_preds$Predicted <- boot::inv.logit(ens_preds$Predicted)

              # Get feature importances
                  # From the model
                  ImportancesEnsemble <- t(as.data.frame(varImp(greedy_ensemble)["overall"]))
                  # Features that were removed
                  RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesEnsemble)]
                  ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                  names(ImportancesRemoved) <- RemovedFeatures
                  #
                  ImportancesEnsemble <- cbind.data.frame(ImportancesEnsemble, ImportancesRemoved)
                  ImportancesEnsemble <- ImportancesEnsemble[,GMMNames]
                  names(ImportancesEnsemble) <- paste(names(ImportancesEnsemble), "_Reg", sep = "")

              ### Combine predictions from the classifier and regression ###
              Predictions <- as.data.frame(matrix(, nrow = length(test3$Abundance), ncol = 2))
              colnames(Predictions) <- c("Predicted", "Real")
              Predictions$Predicted <- ens_preds$Predicted
              Predictions$Predicted[PredRFC$Predicted == "Absent"] <- 0
              Predictions$Real <- ens_preds$Real
              rownames(Predictions) <- rownames(test3)

              # # Save the predictions
              # AllPredictions <- NULL
              # AllPredictionsReg <- NULL
              AllPredictions <- rbind(AllPredictions, cbind.data.frame(fold, Predictions))
              AllPredictionsReg <- rbind(AllPredictionsReg, cbind.data.frame(fold, ens_preds))
                           
              # Save predictions and calculate performance metrics
                  # combine classifier, regression, total predictions
                  Combined <- cbind.data.frame(TaxonOfInterest, rep, fold, PredRFC, ens_preds$Predicted, Predictions)
                  colnames(Combined) <- c("OTU", "rep", "fold", "PredictedClass", "TrueClass", "Regression", "Combined", "TrueValue")
                  Combined$TrueClass <- as.character(Combined$TrueClass)
                  Combined$PredictedClass <- as.character(Combined$PredictedClass)
                  # For all data
                  REACTOR_PerformancePerFold_ALL_NIS <- rbind(REACTOR_PerformancePerFold_ALL_NIS, cbind.data.frame(TaxonOfInterest, rep, fold, RMSE(100*Combined$Combined, 100*Combined$TrueValue), MAE(100*Combined$Combined, 100*Combined$TrueValue), R2(100*Combined$Combined, 100*Combined$TrueValue), sum(Combined$PredictedClass == Combined$TrueClass)/length(Combined$TrueClass), ImportancesClassifier, ImportancesEnsemble))
                  REACTOR_PredictionsPerFold_ALL_NIS <- rbind(REACTOR_PredictionsPerFold_ALL_NIS, Combined)
              
        }
    
      # Plot all predictions on the testset
        AllPredictions$Predicted <- 100*AllPredictions$Predicted
        AllPredictions$Real <- 100*AllPredictions$Real
        # AllPredictions$Predicted <- AllPredictions$Predicted/100
        # AllPredictions$Real <- AllPredictions$Real/100
        p_pred <- ggplot(AllPredictions, aes(x = Real, y = Predicted, fill = as.factor(fold))) +
                            geom_point(shape = 21, size = 2) +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            ggtitle(TaxonOfInterest) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
        print(p_pred)
        png(paste("Figures/Figuresout/MOCK-", rep, "-", TaxonOfInterest,"-WithInSilicoData.png", sep = ""), width = 8, height = 4, res = 500, units = "in")
        print(p_pred)
        dev.off()


        AllPredictionsReg$Predicted <- 100*AllPredictionsReg$Predicted
        AllPredictionsReg$Real <- 100*AllPredictionsReg$Real
        p_predr <- ggplot(AllPredictionsReg, aes(x = Real, y = Predicted, fill = as.factor(fold))) +
                            geom_point(shape = 21, size = 2) +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            ggtitle(TaxonOfInterest) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
        p_predr

        
        # Calculate AUC
        colnames(ClassificationProbabilities) <- c("True", "Probs")
        ROC_ALL <- roc(ClassificationProbabilities$True, ClassificationProbabilities$Probs)
        AUC_ALL <- print(auc(ROC_ALL)[1])
        
      # Save predictions and calculate performance metics
        REACTOR_PerformanceDataset_ALL_NIS <- rbind(REACTOR_PerformanceDataset_ALL_NIS, cbind.data.frame(TaxonOfInterest, rep, RMSE(AllPredictions$Predicted,AllPredictions$Real), MAE(AllPredictions$Predicted,AllPredictions$Real), R2(AllPredictions$Predicted,AllPredictions$Real), AUC_ALL))
  
      }
      
  }

}

# write.csv(REACTOR_PerformancePerFold_ALL_NIS, "out/REACTOR_PerformancePerFold_ALL_IS_AUC.csv")
# write.csv(REACTOR_PredictionsPerFold_ALL_NIS, "out/REACTOR_PredictionsPerFold_ALL_IS_AUC.csv")
# write.csv(REACTOR_PerformanceDataset_ALL_NIS, "out/REACTOR_PerformanceDataset_ALL_IS_AUC.csv")
```

### Plot 

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Upload results
PredictionsPerFold <- read.csv("Results/REACTOR_PredictionsPerFold_ALL_IS_AUC.csv")
```

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Calculate false positive and false negative rates
Results <- NULL
for (i in unique(PredictionsPerFold$OTU)){
  for (j in unique(PredictionsPerFold$rep)){
    # Select the predictions from this repeat of the selected fold
    SelectedSet <- PredictionsPerFold[PredictionsPerFold$OTU == i & PredictionsPerFold$rep == j,]
    SelectedSet$CombinedClass <- "Absent"
    SelectedSet$CombinedClass[SelectedSet$Combined > 0.01] <- "Present"
    # Accuracy
    Accuracy_Classifier <- sum(SelectedSet$PredictedClass == SelectedSet$TrueClass)/length(SelectedSet$TrueClass)
    Accuracy_Final <- sum(SelectedSet$CombinedClass == SelectedSet$TrueClass)/length(SelectedSet$TrueClass)
    # False positive: Negatives with positive outcome/All negatives 
    NrFalsePositive <- length(SelectedSet$X[SelectedSet$TrueClass == "Absent" & SelectedSet$PredictedClass == "Present"])
    NrTotalTrueAbsent <- length(SelectedSet$X[SelectedSet$TrueClass == "Absent"])
    FalsePositiveRate <- NrFalsePositive/NrTotalTrueAbsent
    # False negative
    NrFalseNegative <- length(SelectedSet$X[SelectedSet$TrueClass == "Present" & SelectedSet$PredictedClass == "Absent"])
    NrTotalTruePresent <- length(SelectedSet$X[SelectedSet$TrueClass == "Present"])
    FalseNegativeRate <- NrFalseNegative/NrTotalTruePresent
    # Save results
    Results <- rbind.data.frame(Results, cbind.data.frame(i, j, Accuracy_Classifier, Accuracy_Final, NrFalsePositive, NrFalseNegative, FalsePositiveRate, FalseNegativeRate))
  }
}
colnames(Results)[1:2] <- c("OTU", "rep")
Results <- Results[complete.cases(Results),]
Results <- melt(Results, id.vars = c("OTU", "rep"))

# Plot model accuracies of the classifier alone
# Sort the dataframe according to average performance
MeanClassifierPerformance <- Results %>% group_by(OTU, variable) %>% summarise_at(.vars = names(.)[4],.funs = c(mean = "mean", sd = "sd"))
Results <- left_join(Results, MeanClassifierPerformance, by = c("OTU", "variable"))
ResultsClassifier <- Results %>% dplyr::filter(variable %in% c("Accuracy_Classifier"))
ResultsClassifier <- left_join(ResultsClassifier, Taxonomy, by = c("OTU"))
ResultsClassifier$Label <- paste(ResultsClassifier$OTU, " (", ResultsClassifier$Genus, ")", sep = "")
ResultsClassifier <- ResultsClassifier[order(-ResultsClassifier$mean),] 
ResultsClassifier$Label <- factor(ResultsClassifier$Label, levels = unique(ResultsClassifier$Label))
# Plot
p_AccuracyReactor <- ResultsClassifier %>% 
                      dplyr::filter(variable %in% c("Accuracy_Classifier")) %>% 
                      ggplot(data = ., aes(x = Label, y = 100*value)) +
                      geom_errorbar(aes(x = Label, ymin = 100*mean, ymax = 100*mean), color = "#91518b", width = 0.8) +
                      geom_point(shape = 21, fill = "#91518b") +
                      geom_hline(yintercept = 50, color = "#5b5b5b") + 
                      # annotate("text", x = 10, y = 55, size = 3, label = c('random guessing'), color = "black") +
                      # scale_x_discrete("", labels = Label) +
                      theme_cowplot() +
                      theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
                      labs(color = "", y = "Accuracy (%)", x = "") +
                      guides(color = FALSE, fill = FALSE) + 
                      scale_y_continuous(limits = c(0, 100))
print(p_AccuracyReactor)
```


```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Plot AUC values
PerformanceDataset <- read.csv("Results/REACTOR_PerformanceDataset_ALL_IS_AUC.csv")
PerformanceDataset <- PerformanceDataset[c("TaxonOfInterest", "AUC_ALL")]
MeanAUC <- PerformanceDataset %>% group_by(TaxonOfInterest) %>% summarise_at(.vars = names(.)[2], .funs = c(mean = "mean", sd = "sd"))
PerformanceDataset <- left_join(PerformanceDataset, MeanAUC, by = c("TaxonOfInterest"))

# Add taxonomy
PerformanceDataset <- left_join(PerformanceDataset, Taxonomy, by = c("TaxonOfInterest" = "OTU"))
PerformanceDataset$Label <- paste(PerformanceDataset$TaxonOfInterest, " (", PerformanceDataset$Genus, ")", sep = "")

# Change order to match regression for plot
PerformanceDataset$Label <- factor(PerformanceDataset$Label, levels = unique(ResultsRegression$Label))
p_AUCReactor <- PerformanceDataset %>% 
              ggplot(data = ., aes(x = Label, y = AUC_ALL)) +
              geom_errorbar(aes(x = Label, ymin = mean, ymax = mean), color = "#91518b", width = 0.8) +
              geom_point(shape = 21, fill = "#91518b") +
              geom_hline(yintercept = 0.5, color = "#5b5b5b") + 
              scale_y_continuous(breaks = seq(0, 1, by = 0.25), limits = c(0, 1)) +
              # annotate("text", x = 10, y = 55, size = 3, label = c('random guessing'), color = "black") +
              # scale_x_discrete("", labels = Label) +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
              labs(color = "", y = "AUC", x = "") +
              guides(color = FALSE, fill = FALSE)
print(p_AUCReactor)
```

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Calculate false positive and false negative rates
Results <- NULL
for (i in unique(PredictionsPerFold$OTU)){
  for (j in unique(PredictionsPerFold$rep)){
    # Select the predictions from this repeat of the selected fold
    SelectedSet <- PredictionsPerFold[PredictionsPerFold$OTU == i & PredictionsPerFold$rep == j,]
    # R2
    R2_Regression <- R2(SelectedSet$Regression, SelectedSet$TrueValue)
    R2_Final <- R2(SelectedSet$Combined, SelectedSet$TrueValue)
    # MAE
    MAE_Regression <- MAE(SelectedSet$Regression, SelectedSet$TrueValue)
    MAE_Final <- MAE(SelectedSet$Combined, SelectedSet$TrueValue)
    # Save results
    Results <- rbind.data.frame(Results, cbind.data.frame(i, j, R2_Regression, R2_Final, MAE_Regression, MAE_Final)) # nMAE_Regression, nMAE_Final, FPBefore, FNBefore, FPAfter, FNAfter, R2_Final_Absolute
  }
}
colnames(Results)[1:2] <- c("OTU", "rep")
Results <- Results[complete.cases(Results),]
Results <- melt(Results, id.vars = c("OTU", "rep"))
Results2 <- Results

# Sort the dataframe according to average performance
MeanRegressionPerformance <- Results %>% group_by(OTU, variable) %>% summarise_at(.vars = names(.)[4], .funs = c(mean = "mean", sd = "sd"))

Results <- left_join(Results, MeanRegressionPerformance, by = c("OTU", "variable"))
ResultsRegression <- Results %>% dplyr::filter(variable %in% c("R2_Final", "R2_Regression"))
ResultsRegression <- left_join(ResultsRegression, Taxonomy, by = c("OTU"))
ResultsRegression$Label <- paste(ResultsRegression$OTU, " (", ResultsRegression$Genus, ")", sep = "")
ResultsRegression <- ResultsRegression[order(-ResultsRegression$mean),] 
ResultsRegression$Label <- factor(ResultsRegression$Label, levels = unique(ResultsRegression$Label))

# Plot R2 values
p_R2_REACTOR <- ResultsRegression %>%
              dplyr::filter(variable %in% c("R2_Final")) %>%
              ggplot(data = ., aes(x = Label, y = value, fill = variable)) +
              geom_errorbar(aes(x = Label, ymin = mean, ymax = mean), color = "#91518b", width = 0.8) +
              geom_point(shape = 21, fill = "#91518b") +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
              guides(color = FALSE, fill = FALSE) + 
              labs(color = "", y = expression(paste("R"^"2")), x = "") +
              scale_y_continuous(limits = c(0, 1))
print(p_R2_REACTOR)

# p_R2 <- ResultsRegression %>%
#               dplyr::filter(variable %in% c("R2_Regression", "R2_Final")) %>%
#               ggplot(data = ., aes(x = Label, y = value, fill = variable)) +
#               geom_errorbar(aes(x = Label, ymin = mean, ymax = mean, color = variable), width = 0.8, size = 1) +
#               geom_point(shape = 21) +
#               scale_fill_manual("",values = c("#6c72dd", "#4fb783"), labels = c("Regression alone", "Final model")) +
#               scale_color_manual("",values = c("#6c72dd", "#4fb783")) +
#               theme_cowplot() +
#               theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 1.5), "cm"), legend.position = "top", legend.justification = "center", legend.text = element_text(size = 12)) +
#               guides(color = FALSE, fill = guide_legend(override.aes = list(size = 3))) + 
#               labs(color = "", y = expression(paste("R"^"2")), x = "") +
#               scale_y_continuous(limits = c(0, 1))
# p_R2

# Min, max and mean
min(ResultsRegression$mean[ResultsRegression$variable == "R2_Regression"])
max(ResultsRegression$mean[ResultsRegression$variable == "R2_Regression"])
mean(ResultsRegression$mean[ResultsRegression$variable == "R2_Regression"])
min(ResultsRegression$mean[ResultsRegression$variable == "R2_Final"])
max(ResultsRegression$mean[ResultsRegression$variable == "R2_Final"])
mean(ResultsRegression$mean[ResultsRegression$variable == "R2_Final"])
sd(ResultsRegression$mean[ResultsRegression$variable == "R2_Final"])

# Plot MAE values
MeanRegressionPerformanceMAE <- Results2 %>% group_by(OTU, variable) %>% summarise_at(.vars = names(.)[4], .funs = c(mean = "mean", sd = "sd"))
MeanRegressionPerformanceMAE <- left_join(Results2, MeanRegressionPerformanceMAE, by = c("OTU", "variable"))
MeanRegressionPerformanceMAE <- MeanRegressionPerformanceMAE %>% dplyr::filter(variable %in% c("MAE_Final", "MAE_Regression", "nMAE_Final", "nMAE_Regression"))
MeanRegressionPerformanceMAE <- left_join(MeanRegressionPerformanceMAE, Taxonomy, by = c("OTU"))
MeanRegressionPerformanceMAE$Label <- paste(MeanRegressionPerformanceMAE$OTU, " (", MeanRegressionPerformanceMAE$Genus, ")", sep = "")
MeanRegressionPerformanceMAE$Label <- factor(MeanRegressionPerformanceMAE$Label, levels =  levels(ResultsRegression$Label))

p_MAE <- MeanRegressionPerformanceMAE %>%
              dplyr::filter(variable %in% c("MAE_Final", "MAE_Regression")) %>%
              ggplot(data = ., aes(x = Label, y = 100*value, fill = variable)) +
              geom_errorbar(aes(x = Label, ymin = 100*mean, ymax = 100*mean, color = variable), width = 0.8, size = 1) +
              geom_point(shape = 21) +
              scale_fill_manual("", values = c("#6c72dd", "#4fb783"), labels = c("Regression alone", "Final model")) +
              scale_color_manual("", values = c("#6c72dd", "#4fb783")) +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm"), legend.position = "none", legend.justification = "center") +
              guides(color = FALSE, fill = guide_legend(override.aes = list(size = 3))) + 
              labs(color = "", y = "MAE", x = "")
print(p_MAE)
```

# Mock community (validation 1)

## Upload and process FCM data

```{r Mock_LoadFCM, message = FALSE, warning = FALSE}
# Load the FCS files of the Influx
Datapath <- c("./Data/Mock/FCM/")
fcsfiles <- list.files(path = Datapath, recursive = TRUE, pattern = ".fcs", full.names = TRUE)
flowData <- flowCore::read.flowSet(files = fcsfiles, pattern = ".fcs")

# Remove all variables that are no longer needed
remove(Datapath, fcsfiles)
```

```{r Mock_transform, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Select phenotypic features of interest and transform parameters
flowData_transformed <- flowCore::transform(flowData,
                                      `PMT 1` = log10(`PMT 1`),
                                      `PMT 2` = log10(`PMT 2`), 
                                      `PMT 3` = log10(`PMT 3`),
                                      `PMT 4` = log10(`PMT 4`), 
                                      `PMT 5` = log10(`PMT 5`),
                                      `PMT 6` = log10(`PMT 6`), 
                                      `PMT 7` = log10(`PMT 7`),
                                      `PMT 8` = log10(`PMT 8`), 
                                      `PMT 9` = log10(`PMT 9`),
                                      `PMT 10` = log10(`PMT 10`),
                                      `PMT 11` = log10(`PMT 11`), 
                                      `PMT 12` = log10(`PMT 12`),
                                      `PMT 13` = log10(`PMT 13`), 
                                      `PMT 14` = log10(`PMT 14`))

# Remove all variables that are no longer needed
remove(flowData)
```

```{r Mock_ApplyGating, echo = TRUE, dpi = 500, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = TRUE, results = "hide"}
# Plot the pure cultures
flowData_transformed2 <- flowData_transformed

sqrcut1 <- matrix(c(0.8, 0.2, 0.7, 1.8, 2.8, 3.5, 2.85, 3.3, 3.7, 2.5,
                    0.4, 0.9, 2.2, 2.3, 3.2, 3.2, 2.35, 2.35, 1.9, 0.4),
                  ncol = 2,
                  nrow = 10)
colnames(sqrcut1) <- c("PMT 1", "PMT 9")
polyGate <- polygonGate(.gate = sqrcut1, filterId = "Cells")
flowData_transformed2 <- Subset(flowData_transformed2, polyGate)
flowData_transformed2 <- FCS_resample(flowData_transformed2, sample = 50000)

# p_Ppolymyxa <- xyplot(`PMT 9` ~ `PMT 1`, 
#                data = flowData_transformed2[6],
#                scales = list(y = list(limits = c(0.1,4.1)),
#                              x = list(limits = c(0.1,3.9))),
#                main = expression(paste(italic("P. polymyxa"))),
#                axis = axis.default,
#                xlab = list(label = "SSC"),
#                ylab = list(label = "FL1"),
#                strip = FALSE,
#                nbin = 125,
#                par.strip.text = list(col = "black", font = 0, cex = 0),
#                smooth = FALSE)
# print(p_Ppolymyxa)
# 
# #
# DataFCM <- as.data.frame(exprs(flowData_transformed2[[6]]))
# p_Ppolymyxa <- ggplot(data = DataFCM, aes(x = `PMT 1`, y = `PMT 9`) ) +
#                     geom_bin2d(bins = 200) +
#                     scale_fill_distiller(palette = 'YlGnBu', direction = -1) +
#                     labs(x = "FSC", y = "FL1", color = "Importance") +
#                     # ggtitle(expression(paste(italic("S. rhizophila"), " - Measured"))) + 
#                     theme_cowplot() +
#                     theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "none") 
# print(p_Ppolymyxa)
# 
# p_Srhizophila <- xyplot(`PMT 9` ~ `PMT 1`, 
#                data = flowData_transformed2[2],
#                scales = list(y = list(limits = c(0.1,4.1)),
#                              x = list(limits = c(0.1,3.9))),
#                main = expression(paste(italic("S. rhizophila"))),
#                axis = axis.default,
#                xlab = list(label = "SSC"),
#                ylab = list(label = "FL1"),
#                strip = FALSE,
#                nbin = 125,
#                par.strip.text = list(col = "black", font = 0, cex = 0),
#                smooth = FALSE)
# print(p_Srhizophila)
# 
# #
# DataFCM <- as.data.frame(exprs(flowData_transformed2[[2]]))
# p_Srhizophila <- ggplot(data = DataFCM, aes(x = `PMT 1`, y = `PMT 9`) ) +
#                     geom_bin2d(bins = 200) +
#                     scale_fill_distiller(palette = 'YlGnBu', direction = -1) +
#                     labs(x = "FSC", y = "FL1", color = "Importance") +
#                     # ggtitle(expression(paste(italic("S. rhizophila"), " - Measured"))) + 
#                     theme_cowplot() +
#                     theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "none") 
# print(p_Srhizophila)
# 
# 
# p_Krhizophila <- xyplot(`PMT 9` ~ `PMT 1`, 
#                data = flowData_transformed2[1],
#                scales = list(y = list(limits = c(0.1,4.1)),
#                              x = list(limits = c(0.1,3.9))),
#                main = expression(paste(italic("K. rhizophila"))),
#                axis = axis.default,
#                xlab = list(label = "SSC"),
#                ylab = list(label = "FL1"),
#                strip = FALSE,
#                nbin = 125,
#                par.strip.text = list(col = "black", font = 0, cex = 0),
#                smooth = FALSE)
# print(p_Krhizophila)
# 
# #
# DataFCM <- as.data.frame(exprs(flowData_transformed2[[1]]))
# p_Krhizophila <- ggplot(data = DataFCM, aes(x = `PMT 1`, y = `PMT 9`) ) +
#                     geom_bin2d(bins = 200) +
#                     scale_fill_distiller(palette = 'YlGnBu', direction = -1) +
#                     labs(x = "FSC", y = "FL1", color = "Importance") +
#                     # ggtitle(expression(paste(italic("S. rhizophila"), " - Measured"))) + 
#                     theme_cowplot() +
#                     theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "none") 
# print(p_Krhizophila)
```

```{r Mock_Gatecheck, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Create a PolygonGate for denoising the dataset
sqrcut1 <- matrix(c(0.8, 0.4, 0.7, 1.8, 2.6, 3.3, 2.85, 3.1, 3.4, 2.2,
                    0.65, 0.9, 1.8, 2.3, 2.9, 2.9, 2.35, 2.35, 1.9, 0.7),
                     ncol = 2,
                     nrow = 10)

colnames(sqrcut1) <- c("PMT 1", "PMT 9")
polyGate <- polygonGate(.gate = sqrcut1, filterId = "Cells")
# Gating quality check
for (i in base::sample(1:length(flowData_transformed), size = 5)) {
  print(xyplot(`PMT 9` ~ `PMT 1`, data = flowData_transformed[i],
              filter = polyGate,
              scales = list(y = list(limits = c(0,4.1)),
                            x = list(limits = c(0,3.9))),
              axis = axis.default,
              nbin = 125,
              par.strip.text = list(col = "black", font = 3, cex = 0.75),
              smooth = FALSE))
}
# Remove variables that are no longer needed
remove(sqrcut1, i)
```

```{r Mock_ApplyGating, echo = TRUE, dpi = 500, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = TRUE, results = "hide"}
# Apply gate on samples
flowData_transformed <- Subset(flowData_transformed, polyGate)
```

```{r Mock_NormaliseDataOnFL1, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
summary <- fsApply(x = flowData_transformed, FUN = function(x) apply(x, 2, max), use.exprs = TRUE)
maxval <- max(summary[,"PMT 9"])
mytrans <- function(x) x/maxval
flowData_transformed <- transform(flowData_transformed,
                                  `PMT 1` = mytrans(`PMT 1`),
                                  `PMT 9` = mytrans(`PMT 9`))
remove(mytrans, summary, maxval) # not needed further
```

```{r Mock_ApplyGating, echo = TRUE, dpi = 500, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = TRUE, results = "hide"}
#
flowData_transformedSub <- FCS_resample(flowData_transformed, sample = 30000, replace = TRUE)


DataFCM <- as.data.frame(exprs(flowData_transformedSub[[2]]))
p_Srhizophila <- ggplot(data = DataFCM, aes(x = `PMT 1`, y = `PMT 9`) ) +
                  geom_bin2d(bins = 200) +
                  scale_fill_distiller(palette = 'YlGnBu', direction = -1) +
                  labs(x = "Forward scatter", y = "DAPI fluorescence", color = "Importance") +
                  scale_x_continuous(limits = c(0, 1.2), expand = c(0, 0)) +
                  scale_y_continuous(limits = c(0.2, 1), expand = c(0, 0)) + 
                  theme_cowplot() +
                  theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "none")
print(p_Srhizophila)


DataFCM <- as.data.frame(exprs(flowData_transformedSub[[6]]))
p_Ppolymyxa <- ggplot(data = DataFCM, aes(x = `PMT 1`, y = `PMT 9`) ) +
                geom_bin2d(bins = 200) +
                scale_fill_distiller(palette = 'YlGnBu', direction = -1) +
                labs(x = "Forward scatter", y = "DAPI fluorescence", color = "Importance") +
                scale_x_continuous(limits = c(0, 1.2), expand = c(0, 0)) +
                scale_y_continuous(limits = c(0.2, 1), expand = c(0, 0)) + 
                theme_cowplot() +
                theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "none")
print(p_Ppolymyxa)


DataFCM <- as.data.frame(exprs(flowData_transformedSub[[1]]))
p_Krhizophila <- ggplot(data = DataFCM, aes(x = `PMT 1`, y = `PMT 9`) ) +
                  geom_bin2d(bins = 200) +
                  scale_fill_distiller(palette = 'YlGnBu', direction = -1) +
                  labs(x = "Forward scatter", y = "DAPI fluorescence", color = "Importance") +
                  scale_x_continuous(limits = c(0, 1.2), expand = c(0, 0)) +
                  scale_y_continuous(limits = c(0.2, 1), expand = c(0, 0)) + 
                  theme_cowplot() +
                  theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "none") 
print(p_Krhizophila)
```

```{r Mock_GenerateGMM, echo = TRUE, dpi = 500, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = FALSE,  results = "hide"}
# Parameters to take into account for the model
# paramGMM <- c("PMT 1", "PMT 9")
# Subsample to lower sample size to make the training faster
# flowData_transformed <- FCS_resample(flowData_transformed, replace = TRUE, sample = 20000)
# fcs_x <- flowData_transformed[, paramGMM]
# fcs_x <- Phenoflow::FCS_pool(fcs_x, stub = "*")
# fcs_x <- fcs_x[, paramGMM] # The FCS_pool makes an extra column called "Original" which we don't need
# Check different number of clusters
# gmm_clust <- Mclust(data = exprs(fcs_x[[1]]), G = seq(from = 1, to = 100, by = 5))
# saveRDS(object = gmm_clust, file = "Data/ValidationSets/Mock/GMMs_Mock_1to100per5.rds")
# # Check different number of clusters
# gmm_clustII <- Mclust(data = exprs(fcs_x[[1]]), G = seq(from = 30, to = 35, by = 1))
# saveRDS(object = gmm_clustII, file = "Results/GMMFits/GMMs_Mockou_30to35per1.rds")
```

```{r Mock_ApplyGMM, echo = TRUE, dpi = 500, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = FALSE,  results = "hide"}
# Upload the GMM
gmm_clust <- readRDS(file = "Results/GMMFits/GMMs_Mockou_30to35per1.rds")

# Plot the BIC values for the different models to see the optimization
NoClusters <- dimnames(gmm_clust$BIC)[[1]]
BICValues <- data.frame(as.matrix(gmm_clust$BIC)[1:length(NoClusters),])
BICValues$NoClusters <- rownames(BICValues)
BICValues <- reshape2::melt(BICValues, id.vars = "NoClusters")
colnames(BICValues) <- c("NoClusters", "ModelType", "BIC")
BICValues$NoClusters <- as.numeric(BICValues$NoClusters)
BICValues <- BICValues[!is.na(BICValues$BIC),] # remove the NA values
BICValues$ModelType <- droplevels(BICValues$ModelType, except = unique(BICValues$ModelType))# remove levels that are not being used
p_bic <- BICValues %>% 
          ggplot(data = ., aes(x = NoClusters, y = BIC)) +
          geom_line(alpha = 1, aes(color = ModelType), show.legend = F) +
          geom_point(shape = 21, size = 3, alpha = 1, aes(fill = ModelType)) +
          labs(x = "Number of clusters", y = "BIC", fill = "Model type") +
          theme_cowplot() +
          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
print(p_bic)


#
# flowData_transformed <- FCS_resample(flowData_transformed, sample = 20000)

# Apply GMM mask to the data
NumberOfClusters <- gmm_clust$G
params_gmm <- colnames(gmm_clust$data)
flowData_transformed <- flowData_transformed[, params_gmm] # subset to the relevant parameters
GMMOut <- data.frame(matrix(nrow = NumberOfClusters+1, ncol = length(flowData_transformed))) # Initialize a df to store the results of the predictions
rownames(GMMOut) <- c(1:NumberOfClusters, "(Other)")
for (i in 1:length(flowData_transformed)){
    RawData <- flowData_transformed[[i]]@exprs
    GMMPred <- predict(gmm_clust, RawData)
    GMMPred <- as.factor(GMMPred$classification)
    Summary <- summary(GMMPred)
    Summary <- Summary[rownames(GMMOut)] # Reorganise to the same order as the df that was initialised above
    GMMOut[,i] <- Summary
}
# Replace the NA values by 0
GMMOut[is.na(GMMOut)] <- 0
rownames(GMMOut) <- c(paste("GMM", 1:NumberOfClusters, sep = ""), "Other")
colnames(GMMOut) <- sampleNames(flowData_transformed)
# Normalise the GMM abundances to sum = 1
GMMOut <- sweep(GMMOut, 2, colSums(GMMOut), `/`)
GMMOut <- t(GMMOut)
GMMOut <- as.data.frame(GMMOut)
GMMOut$Names <- rownames(GMMOut)

# Remove variables that are no longer needed 
remove(p_bic, RawData, Summary, NoClusters, BICValues, i, GMMPred)
```

## Get community compositions from file names

```{r Mock_Compositions, echo = TRUE, dpi = 500, out.width = "800px", out.height = "175px", dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE, eval = FALSE,  results = "hide"}
# Get the community composition
Metadata <- data.frame(do.call(rbind, lapply(strsplit(GMMOut$Names,"_"), rbind)))
Metadata$X3 <- gsub(".fcs", "", Metadata$X3)
Metadata$X1 <- as.numeric(gsub(",", ".", Metadata$X1))
Metadata$X2 <- as.numeric(gsub(",", ".", Metadata$X2))
Metadata$X3 <- as.numeric(gsub(",", ".", Metadata$X3))
Metadata <- Metadata/100 # logit takes fractions
colnames(Metadata) <- c("Ppolymyxa", "Srhizophila", "Krhizophila")
Metadata$Names <- GMMOut$Names
```

## Train and validate

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
MOCK_PerformancePerFold_ALL_NIS <- NULL
MOCK_PredictionsPerFold_ALL_NIS <- NULL
MOCK_PerformanceDataset_ALL_NIS <- NULL

for (i in 1:3){
  
  # Select OTU of interest
  TaxonOfInterest <- colnames(Metadata)[i]
  TaxonAbundances <- Metadata[, c("Names", TaxonOfInterest)]
  colnames(TaxonAbundances) <- c("Names", "Abundance")

  # Combine the features and measured variables
  Dataset <- left_join(GMMOut, TaxonAbundances, by = c("Names" = "Names"))
  rownames(Dataset) <- Dataset$Names
  Dataset <- Dataset[, -which(names(Dataset) %in% c("Names"))]

  # Remove GMM with very low variance (not informative + some models will fail)
  TooLowVariance <- apply(Dataset[colnames(Dataset) != "Abundance"], 2, function(x) length(unique(x))) > (dim(Dataset)[1]/10)
  Dataset <- cbind.data.frame(Dataset[,which(TooLowVariance)], Dataset$Abundance)
  colnames(Dataset)[length(colnames(Dataset))] <- "Abundance"

  if(length(unique(Dataset$Abundance)) > 3){ # Extra check for missing OTUs in a subset of the data

      # Centered log ratio transform
      Dataset <- cbind.data.frame(compositions::clr(Dataset[,!names(Dataset) == "Abundance"]), Dataset$Abundance)
      colnames(Dataset)[dim(Dataset)[2]] <- "Abundance"

      # Save dataset to reload it later
      DatasetFull <- Dataset[order(Dataset$Abundance),]

      # Model
      for (rep in 1:3){
      AllPredictions <- NULL
      AllPredictionsReg <- NULL
      ClassificationProbabilities <- NULL
      # Split data into folds
      NumberOfFolds <- 5
      Set1 <- 1
      Set2 <- 2
      Set3 <- 3
      Set4 <- 4
      Set5 <- 5
      Sets <- c("Set1", "Set2", "Set3", "Set4", "Set5")
      for (k in 1:(floor(dim(Dataset)[1]/NumberOfFolds)-1)){
        # Get indices
        Set1 <- c(Set1, k*NumberOfFolds)
        Set2 <- c(Set2, (k*NumberOfFolds)+1)
        Set3 <- c(Set3, (k*NumberOfFolds)+2)
        Set4 <- c(Set4, (k*NumberOfFolds)+3)
        Set5 <- c(Set5, (k*NumberOfFolds)+4)
      }
      if(max(Set5) < dim(Dataset)[1]){
        NUmberLeft <- dim(Dataset)[1] - max(Set5)
        for (l in 1:NUmberLeft){
          assign(Sets[l], c(get(Sets[l]), max(Set5) + l))
        }
      }
      if(rep %in% c(2,3)){
        NumberOfSwitches <- round(length(Set5)/3)
        for (pos in 1:NumberOfSwitches){
          Set1[rep*pos] <- Set2[rep*pos]
          Set2[rep*pos] <- Set3[rep*pos]
          Set3[rep*pos] <- Set4[rep*pos]
          Set4[rep*pos] <- Set5[rep*pos]
          Set5[rep*pos] <- Set1[rep*pos]
        }
      }
      # If one of the sets had an element less it might have generated NA
      Set1 <- Set1[!is.na(Set1)]
      Set2 <- Set2[!is.na(Set2)]
      Set3 <- Set3[!is.na(Set3)]
      Set4 <- Set4[!is.na(Set4)]
      Set5 <- Set5[!is.na(Set5)]
      # Combine in a list
      Folds <- list(Fold1 = Set1, Fold2 = Set2, Fold3 = Set3, Fold4 = Set4, Fold5 = Set5)
      # Train and evaluate
      for (fold in 1:length(Folds)){
            Dataset <- DatasetFull
            GMMNames <- colnames(Dataset)[!colnames(Dataset) == "Abundance"]

            # Selected fold
            Testindices <- Folds[[fold]]
            train3 <- Dataset[-Testindices, ]
            test3 <- Dataset[Testindices, ]

            # Transformation --> ensure predictions are in the 0-1 range to allow logit transformation later
            minvalue <- min(train3$Abundance[train3$Abundance > 0])

            # Get number of samples with low abundance (i.e. < 0.01) and high abundance (i.e. > 0.01)
            Below1 <- train3[train3$Abundance < 0.01,]
            Over1 <- train3[train3$Abundance >= 0.01,]

            #
            TotalNew <- 500
            NumberOfBelow1 <- dim(Below1)[1]
            NumberOfOver1 <- dim(Over1)[1]
            NumberOfOver1ToMake <- round(NumberOfBelow1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
            NumberOfBelow1ToMake <- round(NumberOfOver1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
            if(NumberOfOver1ToMake < TotalNew/2) NumberOfOver1ToMake <- TotalNew/2
            if(NumberOfBelow1ToMake < TotalNew/2) NumberOfBelow1ToMake <- TotalNew/2
            if(dim(Below1)[1] == 1){
              NumberOfBelow1ToMake <- 0
              NumberOfOver1ToMake <- TotalNew
            }

            # Max random variation (1000x smaller than the smallest value)
            RandValPredictorVals <- colMins(as.matrix(abs(train3[, !names(train3) == "Abundance"])))/100
            RandValOutput <- min(abs(train3$Abundance[train3$Abundance > 0]))/100
            RandGMMVals <- NULL
            RandAbundVals <- NULL

            # Fake zero's
            InSilicoBelow1 <- NULL
            for (j in 1:round(NumberOfBelow1ToMake*1)){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSamples <- round(runif(2, min = 1, max = dim(Below1)[1]))
              Sample1 <- Below1[SelectedSamples[1],]
              Sample2 <- Below1[SelectedSamples[2],]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoBelow1 <- rbind.data.frame(InSilicoBelow1, New)
            }

            # Fake abundant using only abundant samples
            InSilicoOver1H <- NULL
            Over1High <- Over1[mean(Over1$Abundance) < Over1$Abundance,]
            for (j in 1:round(NumberOfOver1ToMake*(1))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample1 <- Over1High[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample2 <- Over1High[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver1H <- rbind.data.frame(InSilicoOver1H, New)
            }

            # Fake abundant using only abundant samples
            InSilicoOver1 <- NULL
            for (j in 1:round(NumberOfOver1ToMake*(1/2))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
              Sample1 <- Over1[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample2 <- Over1High[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver1 <- rbind.data.frame(InSilicoOver1, New)
            }

            # Fake samples mixed between low and high abundances
            InSilicoOver2 <- NULL
            for (j in 1:round(NumberOfOver1ToMake*(1/2))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
              Sample1 <- Over1[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Below1)[1]))
              Sample2 <- Below1[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver2 <- rbind.data.frame(InSilicoOver2, New)
            }

            # Combine the in sillico samples with the original data
            train3 <- cbind.data.frame("Original", train3)
            colnames(train3)[1] <- "Group"
            InSilicoBelow1 <- cbind.data.frame("InSilicoBelow1", InSilicoBelow1)
            colnames(InSilicoBelow1)[1] <- "Group"
            InSilicoOver1H <- cbind.data.frame("InSilicoOver1H", InSilicoOver1H)
            colnames(InSilicoOver1H)[1] <- "Group"
            InSilicoOver1 <- cbind.data.frame("InSilicoOver1", InSilicoOver1)
            colnames(InSilicoOver1)[1] <- "Group"
            InSilicoOver2 <- cbind.data.frame("InSilicoOver2", InSilicoOver2)
            colnames(InSilicoOver2)[1] <- "Group"
            train3 <- rbind.data.frame(train3, InSilicoBelow1, InSilicoOver1H, InSilicoOver1, InSilicoOver2)

            # Make an extra dataframe in the column with two classes: present and absent
            train3$Presence[train3$Abundance > 0.01] <- "Present"
            train3$Presence[train3$Abundance <= 0.01] <- "Absent"
            train3$Presence <- as.factor(train3$Presence)
            test3$Presence[test3$Abundance > 0.01] <- "Present"
            test3$Presence[test3$Abundance <= 0.01] <- "Absent"
            test3$Presence <- as.factor(test3$Presence)

            # Save the full dataframes to reload before the regression
            train3full <- train3
            test3full <- test3

            # Feature selection step
            train3Original <- train3[train3$Group == "Original",]
            train3Original <- train3Original[colnames(train3Original) != "Group"]
            train3Original <- train3Original[colnames(train3Original) != "Abundance"]
            # # Balance
            if(!summary(train3Original$Presence)[1] == summary(train3Original$Presence)[2]){train3Original <- RandOverClassif(Presence ~ ., dat = train3Original, C.perc = "balance")}
            # define the control using a random forest selection function
            control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
            # run the RFE algorithm
            results <- rfe(x = train3Original[,!names(train3Original) == "Presence"], y = train3Original$Presence, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Presence"])[2], by = 2), rfeControl = control, metric = "Accuracy")
            # plot the results
            plot(results, type = c("g", "o"))
            # Make selection
            rfeout <- results$results
            AbsoluteBest <- pickSizeBest(rfeout, metric = "Accuracy", maximize = TRUE)
            Within1Perc <- pickSizeTolerance(rfeout, metric = "Accuracy",  tol = 0.5, maximize = TRUE)
            if(results$results$Accuracy[results$results$Variables == AbsoluteBest] == 1){Within1Perc <- AbsoluteBest}
            if(Within1Perc == 1){Within1Perc <- AbsoluteBest}
            Keep <- results$optVariables[1:Within1Perc]
            KeepClassifier <- Keep
            # list the chosen features
            train3 <- train3[c("Group", Keep, "Abundance", "Presence")]
            test3 <- test3[c(Keep, "Abundance", "Presence")]

            # Make over 1 uniform
            Train3Over <- train3[train3$Abundance >= 0.01,]
            Train3Below <- train3[train3$Abundance < 0.01,]
            RangeAbundances <- range(Train3Over$Abundance)
            BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
            CutAbundances <- cut(Train3Over$Abundance, BreaksAbundances, right = FALSE)
            FrequencyAbundances <- table(CutAbundances)
            CutOff <- round(median(FrequencyAbundances))
            Subsampled <- NULL
            for (k in 1:length(FrequencyAbundances)){
              # Get samples in the kth interval
              Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
              Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
              SelectedData <- Train3Over[Train3Over$Abundance >= Lower & Train3Over$Abundance < Upper,]
              # Subsample if there are more than "cutoff"
              if (dim(SelectedData)[1] > CutOff){
                  SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                } else {
                  SelectedData <- SelectedData
                }
                # Store subsampled data
                Subsampled <- rbind(Subsampled, SelectedData)
              }
            Train3Over <- Subsampled
            # Combine with the low abundant samples
            train3 <- rbind.data.frame(Train3Over, Train3Below)

            # Temporarily remove the abundance column
            train3 <- train3[colnames(train3) != "Abundance"]
            test3 <- test3[colnames(test3) != "Abundance"]

            # Remove the "Group"-column
            train3 <- train3[colnames(train3) != "Group"]
            test3 <- test3[colnames(test3) != "Group"]

            # Balance the classes
            print(summary(train3$Presence))
            if(!summary(train3$Presence)[1] == summary(train3$Presence)[2]){train3 <- RandUnderClassif(Presence ~ ., dat = train3, C.perc = "balance", repl = FALSE)}
            print(summary(train3$Presence))

            ### Caret list
            FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Presence, k = 3, times = 1), classProbs = TRUE)

                # Create tuning grid for the RF
                    # Tune RF
                    if (dim(train3)[2]-1 > 5) {
                      mtryoptions <- seq(1, round(dim(train3[,!names(train3) == "Presence"])[2]/5), by = 1)
                    } else {
                      mtryoptions <- seq(1, dim(train3)[2]-1, by = 1)
                    }
                    tunegridRF <- expand.grid(.mtry = mtryoptions)
                    # Tune SVMPoly
                    C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                    degree <- c(1, 2, 3)
                    scale <- c(1, 2)
                    tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)

                # Train models
                model_listClassifier <- caretList(Presence ~ .,
                                        data = train3,
                                        trControl = FitControl,
                                        tuneList = list(RF = caretModelSpec(method = "rf", tuneGrid = tunegridRF, ntree = 500)))

              # Get predictions
              if(dim(test3)[2] == 2){
                testset <- as.data.frame(test3[,!names(test3) == "Presence"])
                colnames(testset) <- colnames(test3[1])
              } else {
                testset <- as.data.frame(test3[,!names(test3) == "Presence"])
              }
              ens_preds <- predict(model_listClassifier$RF, newdata = testset, type = "raw")
              ens_preds <- cbind.data.frame(ens_preds, test3$Presence)
              colnames(ens_preds) <- c("Predicted", "Real")
              rownames(ens_preds) <- rownames(test3)
              PredRFC <- ens_preds

              # Compute and save prediction probabilities
              ClassProb <- predict(model_listClassifier$RF, newdata = testset, type = "prob")
              ClassificationProbabilities <- rbind.data.frame(ClassificationProbabilities, cbind.data.frame(as.numeric(test3$Presence == "Absent"), ClassProb["Absent"]))
              # ROC <- roc(as.numeric(test3$Presence == "Absent"), ClassProbs$Absent)
              # AUC <- auc(ROC)
              # print(AUC[1])
              
              
              # Get feature importances
                  # From the model
                  ImportancesRF <- t(as.data.frame(varImp(model_listClassifier$RF)["importance"]))
                  # Features that were removed
                  RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesRF)]
                  ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                  names(ImportancesRemoved) <- RemovedFeatures
                  #
                  ImportancesClassifier <- cbind.data.frame(ImportancesRF, ImportancesRemoved)
                  ImportancesClassifier <- ImportancesClassifier[,GMMNames]
                  names(ImportancesClassifier) <- paste(names(ImportancesClassifier), "_Class", sep = "")



              ### REGRESSION ###
              # Temporarily remove the abundance column
              train3 <- train3full
              test3 <- test3full

              # Remove "Presence"-column
              train3 <- train3[colnames(train3) != "Presence"]
              test3 <- test3[colnames(test3) != "Presence"]

              # Feature selection step
              train3Original <- train3[train3$Group == "Original",]
              train3Original <- train3Original[colnames(train3Original) != "Group"]
              # more homogeneous distribution
              train3OriginalLower <- train3Original[train3Original$Abundance < 0.01,]
              train3OriginalHigher <- train3Original[train3Original$Abundance >= 0.01,]
              if(dim(train3OriginalLower)[1] > dim(train3OriginalHigher)[1]){
                train3OriginalLower <- train3OriginalLower[sample(nrow(train3OriginalLower), dim(train3OriginalHigher)[1]), ]
              }
              train3Original <- rbind.data.frame(train3OriginalLower, train3OriginalHigher)
              if(dim(train3Original)[1] > 10){
                    # define the control using a random forest selection function
                    control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
                    # run the RFE algorithm
                    results <- rfe(x = train3Original[,!names(train3Original) == "Abundance"], y = train3Original$Abundance, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Abundance"])[2], by = 2), rfeControl = control, metric = "Rsquared")
                    # plot the results
                    plot(results, type = c("g", "o"))
                    # Make selection
                    rfeout <- results$results
                    if(sum(rfeout$Rsquared == 1) == length(rfeout$Rsquared)){
                      Keep <- Keep
                    } else {
                      Within1Perc <- pickSizeTolerance(rfeout, metric = "Rsquared",  tol = 0.5, maximize = TRUE)
                      Keep <- results$optVariables[1:Within1Perc]
                    }
                    # Get the chosen features
                    train3 <- train3[c("Group", Keep, "Abundance")]
                    test3 <- test3[c(Keep, "Abundance")]
              }

              # Remove the group-column
              train3 <- train3[colnames(train3) != "Group"]

              # Reduce imbalance in the dataset
              RangeAbundances <- range(train3$Abundance)
              BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
              CutAbundances <- cut(train3$Abundance, BreaksAbundances, right = FALSE)
              FrequencyAbundances <- table(CutAbundances)
              CutOff <- round(median(FrequencyAbundances))
              Subsampled <- NULL
              for (k in 1:length(FrequencyAbundances)){
                # Get samples in the kth interval
                Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
                Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
                SelectedData <- train3[train3$Abundance >= Lower & train3$Abundance < Upper,]
                # Subsample if there are more than "cutoff"
                if (dim(SelectedData)[1] > CutOff){
                  SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                } else {
                  SelectedData <- SelectedData
                }
                # Store subsampled data
                Subsampled <- rbind(Subsampled, SelectedData)
              }
              train3 <- Subsampled

              # Logit transformation --> ensure predictions are in the 0-1 range
              train3$Abundance[train3$Abundance >= 1] <- 1 - minvalue/10
              train3$Abundance[train3$Abundance <= 0] <- minvalue/10
              train3$Abundance <- boot::logit(train3$Abundance)

              ### Caret list
              FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Abundance, k = 3, times = 1), summaryFunction = mapeexpSummary)
                  # Create tuning grids
                      # Tune SVMPoly
                      C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                      degree <- c(1, 2, 3)
                      scale <- c(1, 2)
                      tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)
                      # Tune gradient boost
                      n.trees <- c(50, 100, 250, 500)
                      interaction.depth <- c(1)
                      shrinkage <- c(0.3, 0.2, 0.1, 0.05, 0.01)
                      n.minobsinnode <- seq(1, 3, by = 1)
                      tunegridGBM <- expand.grid(n.trees = n.trees, interaction.depth = interaction.depth, shrinkage = shrinkage, n.minobsinnode = n.minobsinnode)

                  # Train models
                  model_list <- caretList(Abundance ~ .,
                                        data = train3,
                                        trControl = FitControl,
                                        tuneList = list(SVMPoly = caretModelSpec(method = "svmPoly", tuneGrid = tunegridSVMPoly, metric = "Rsquared"),
                                                        GBM = caretModelSpec(method = "gbm", tuneGrid = tunegridGBM, metric = "Rsquared")))

              # make ensemble
              greedy_ensemble <- caretEnsemble(model_list, trControl = FitControl, metric = "Rsquared")

              # Make predictions
              if(dim(test3)[2] == 2){
                testset <- as.data.frame(test3[,!names(test3) == "Abundance"])
                colnames(testset) <- colnames(test3[1])
              } else {
                testset <- as.data.frame(test3[,!names(test3) == "Abundance"])
              }
              ens_preds <- predict(greedy_ensemble, newdata = testset)
              ens_preds <- cbind.data.frame(ens_preds, test3$Abundance)
              colnames(ens_preds) <- c("Predicted", "Real")
              rownames(ens_preds) <- rownames(test3)

              # Reverse the logit transform
              ens_preds$Predicted <- boot::inv.logit(ens_preds$Predicted)

              # Get feature importances
                  # From the model
                  ImportancesEnsemble <- t(as.data.frame(varImp(greedy_ensemble)["overall"]))
                  # Features that were removed
                  RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesEnsemble)]
                  ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                  names(ImportancesRemoved) <- RemovedFeatures
                  #
                  ImportancesEnsemble <- cbind.data.frame(ImportancesEnsemble, ImportancesRemoved)
                  ImportancesEnsemble <- ImportancesEnsemble[,GMMNames]
                  names(ImportancesEnsemble) <- paste(names(ImportancesEnsemble), "_Reg", sep = "")

              ### Combine predictions from the classifier and regression ###
              Predictions <- as.data.frame(matrix(, nrow = length(test3$Abundance), ncol = 2))
              colnames(Predictions) <- c("Predicted", "Real")
              Predictions$Predicted <- ens_preds$Predicted
              Predictions$Predicted[PredRFC$Predicted == "Absent"] <- 0
              Predictions$Real <- ens_preds$Real
              rownames(Predictions) <- rownames(test3)

              # # Save the predictions
              # AllPredictions <- NULL
              # AllPredictionsReg <- NULL
              AllPredictions <- rbind(AllPredictions, cbind.data.frame(fold, Predictions))
              AllPredictionsReg <- rbind(AllPredictionsReg, cbind.data.frame(fold, ens_preds))
                           
              # Save predictions and calculate performance metrics
                  # combine classifier, regression, total predictions
                  Combined <- cbind.data.frame(TaxonOfInterest, rep, fold, PredRFC, ens_preds$Predicted, Predictions)
                  colnames(Combined) <- c("OTU", "rep", "fold", "PredictedClass", "TrueClass", "Regression", "Combined", "TrueValue")
                  Combined$TrueClass <- as.character(Combined$TrueClass)
                  Combined$PredictedClass <- as.character(Combined$PredictedClass)
                  # For all data
                  MOCK_PerformancePerFold_ALL_NIS <- rbind(MOCK_PerformancePerFold_ALL_NIS, cbind.data.frame(TaxonOfInterest, rep, fold, RMSE(100*Combined$Combined, 100*Combined$TrueValue), MAE(100*Combined$Combined, 100*Combined$TrueValue), R2(100*Combined$Combined, 100*Combined$TrueValue), sum(Combined$PredictedClass == Combined$TrueClass)/length(Combined$TrueClass), ImportancesClassifier, ImportancesEnsemble))
                  MOCK_PredictionsPerFold_ALL_NIS <- rbind(MOCK_PredictionsPerFold_ALL_NIS, Combined)
              
        }
    
    
      # Plot all predictions on the testset
        AllPredictions$Predicted <- 100*AllPredictions$Predicted
        AllPredictions$Real <- 100*AllPredictions$Real
        # AllPredictions$Predicted <- AllPredictions$Predicted/100
        # AllPredictions$Real <- AllPredictions$Real/100
        p_pred <- ggplot(AllPredictions, aes(x = Real, y = Predicted, fill = as.factor(fold))) +
                            geom_point(shape = 21, size = 2) +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            ggtitle(TaxonOfInterest) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
        print(p_pred)
        png(paste("Figures/Figuresout/MOCK-", rep, "-", TaxonOfInterest,"-WithInSilicoData.png", sep = ""), width = 8, height = 4, res = 500, units = "in")
        print(p_pred)
        dev.off()


        AllPredictionsReg$Predicted <- 100*AllPredictionsReg$Predicted
        AllPredictionsReg$Real <- 100*AllPredictionsReg$Real
        p_predr <- ggplot(AllPredictionsReg, aes(x = Real, y = Predicted, fill = as.factor(fold))) +
                            geom_point(shape = 21, size = 2) +
                            geom_abline(intercept = 0, slope = 1) +
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            ggtitle(TaxonOfInterest) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
        p_predr

       
        # Calculate AUC
        colnames(ClassificationProbabilities) <- c("True", "Probs")
        ROC_ALL <- roc(ClassificationProbabilities$True, ClassificationProbabilities$Probs)
        AUC_ALL <- print(auc(ROC_ALL)[1])
        
      # Save predictions and calculate performance metics
        MOCK_PerformanceDataset_ALL_NIS <- rbind(MOCK_PerformanceDataset_ALL_NIS, cbind.data.frame(TaxonOfInterest, rep, RMSE(AllPredictions$Predicted,AllPredictions$Real), MAE(AllPredictions$Predicted,AllPredictions$Real), R2(AllPredictions$Predicted,AllPredictions$Real), AUC_ALL))
  
      }
      
  }

}
# 
# write.csv(MOCK_PerformancePerFold_ALL_NIS, "Results/MOCK_PerformancePerFold_ALL_IS_AUC.csv")
# write.csv(MOCK_PredictionsPerFold_ALL_NIS, "Results/MOCK_PredictionsPerFold_ALL_IS_AUC.csv")
# write.csv(MOCK_PerformanceDataset_ALL_NIS, "Results/MOCK_PerformanceDataset_ALL_IS_AUC.csv")
```


### Advantage of feature selection

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
PredictionsPerFold <- NULL
MOCK_PerformanceDataset_ALL_NIS <- NULL

for (i in 1:3){
  
  # Select OTU of interest
  TaxonOfInterest <- colnames(Metadata)[i]
  TaxonAbundances <- Metadata[, c("Names", TaxonOfInterest)]
  colnames(TaxonAbundances) <- c("Names", "Abundance")

  # Combine the features and measured variables
  Dataset <- left_join(GMMOut, TaxonAbundances, by = c("Names" = "Names"))
  rownames(Dataset) <- Dataset$Names
  Dataset <- Dataset[, -which(names(Dataset) %in% c("Names"))]

  # Remove GMM with very low variance (not informative + some models will fail)
  TooLowVariance <- apply(Dataset[colnames(Dataset) != "Abundance"], 2, function(x) length(unique(x))) > (dim(Dataset)[1]/10)
  Dataset <- cbind.data.frame(Dataset[,which(TooLowVariance)], Dataset$Abundance)
  colnames(Dataset)[length(colnames(Dataset))] <- "Abundance"

      # Centered log ratio transform
      Dataset <- cbind.data.frame(compositions::clr(Dataset[,!names(Dataset) == "Abundance"]), Dataset$Abundance)
      colnames(Dataset)[dim(Dataset)[2]] <- "Abundance"

      # Save dataset to reload it later
      DatasetFull <- Dataset[order(Dataset$Abundance),]

      # Model
      for (rep in 1:10){
      AllPredictions <- NULL
      AllPredictionsReg <- NULL
      # Split data into folds
      NumberOfFolds <- 5
      Set1 <- 1
      Set2 <- 2
      Set3 <- 3
      Set4 <- 4
      Set5 <- 5
      Sets <- c("Set1", "Set2", "Set3", "Set4", "Set5")
      for (k in 1:(floor(dim(Dataset)[1]/NumberOfFolds)-1)){
        # Get indices
        Set1 <- c(Set1, k*NumberOfFolds)
        Set2 <- c(Set2, (k*NumberOfFolds)+1)
        Set3 <- c(Set3, (k*NumberOfFolds)+2)
        Set4 <- c(Set4, (k*NumberOfFolds)+3)
        Set5 <- c(Set5, (k*NumberOfFolds)+4)
      }
      if(max(Set5) < dim(Dataset)[1]){
        NUmberLeft <- dim(Dataset)[1] - max(Set5)
        for (l in 1:NUmberLeft){
          assign(Sets[l], c(get(Sets[l]), max(Set5) + l))
        }
      }
      if(rep %in% c(2,3)){
        NumberOfSwitches <- round(length(Set5)/3)
        for (pos in 1:NumberOfSwitches){
          Set1[rep*pos] <- Set2[rep*pos] 
          Set2[rep*pos] <- Set3[rep*pos] 
          Set3[rep*pos] <- Set4[rep*pos] 
          Set4[rep*pos] <- Set5[rep*pos] 
          Set5[rep*pos] <- Set1[rep*pos] 
        }
      }
      Folds <- list(Fold1 = Set1, Fold2 = Set2, Fold3 = Set3, Fold4 = Set4, Fold5 = Set5)
      # Train and evaluate
      for (fold in 1:length(Folds)){
            Dataset <- DatasetFull
            GMMNames <- colnames(Dataset)[!colnames(Dataset) == "Abundance"]

            # Selected fold
            Testindices <- Folds[[fold]]
            train3 <- Dataset[-Testindices, ]
            test3 <- Dataset[Testindices, ]

            # Transformation --> ensure predictions are in the 0-1 range to allow logit transformation later
            minvalue <- min(train3$Abundance[train3$Abundance > 0])

            # Get number of samples with low abundance (i.e. < 0.01) and high abundance (i.e. > 0.01)
            Below1 <- train3[train3$Abundance < 0.01,]
            Over1 <- train3[train3$Abundance >= 0.01,]

            #
            TotalNew <- 500
            NumberOfBelow1 <- dim(Below1)[1]
            NumberOfOver1 <- dim(Over1)[1]
            NumberOfOver1ToMake <- round(NumberOfBelow1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
            NumberOfBelow1ToMake <- round(NumberOfOver1/(NumberOfBelow1 + NumberOfOver1)*TotalNew)
            if(NumberOfOver1ToMake < TotalNew/2) NumberOfOver1ToMake <- TotalNew/2
            if(NumberOfBelow1ToMake < TotalNew/2) NumberOfBelow1ToMake <- TotalNew/2
            if(dim(Below1)[1] == 1){
              NumberOfBelow1ToMake <- 0
              NumberOfOver1ToMake <- TotalNew
            }

            # Max random variation (1000x smaller than the smallest value)
            RandValPredictorVals <- colMins(as.matrix(abs(train3[, !names(train3) == "Abundance"])))/100
            RandValOutput <- min(abs(train3$Abundance[train3$Abundance > 0]))/100
            RandGMMVals <- NULL
            RandAbundVals <- NULL

            # Fake zero's
            InSilicoBelow1 <- NULL
            for (j in 1:round(NumberOfBelow1ToMake*1)){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSamples <- round(runif(2, min = 1, max = dim(Below1)[1]))
              Sample1 <- Below1[SelectedSamples[1],]
              Sample2 <- Below1[SelectedSamples[2],]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoBelow1 <- rbind.data.frame(InSilicoBelow1, New)
            }

            # Fake abundant using only abundant samples
            InSilicoOver1H <- NULL
            Over1High <- Over1[mean(Over1$Abundance) < Over1$Abundance,]
            for (j in 1:round(NumberOfOver1ToMake*(1))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample1 <- Over1High[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample2 <- Over1High[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver1H <- rbind.data.frame(InSilicoOver1H, New)
            }

            # Fake abundant using only abundant samples
            InSilicoOver1 <- NULL
            for (j in 1:round(NumberOfOver1ToMake*(1/2))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
              Sample1 <- Over1[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Over1High)[1]))
              Sample2 <- Over1High[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver1 <- rbind.data.frame(InSilicoOver1, New)
            }

            # Fake samples mixed between low and high abundances
            InSilicoOver2 <- NULL
            for (j in 1:round(NumberOfOver1ToMake*(1/2))){
              for(k in 1:length(RandValPredictorVals)) RandGMMVals[k] <- runif(1, min = -RandValPredictorVals[k], max = RandValPredictorVals[k])
              RandAbundVals <- runif(1, min = -RandValOutput, max = RandValOutput)
              # Select random samples
              SelectedSample1 <- round(runif(1, min = 1, max = dim(Over1)[1]))
              Sample1 <- Over1[SelectedSample1,]
              SelectedSample2 <- round(runif(1, min = 1, max = dim(Below1)[1]))
              Sample2 <- Below1[SelectedSample2,]
              # Random mixing proportions
              MixProps <- runif(1, min = 0, max = 1)
              # Mix
              New <- MixProps*Sample1 + (1-MixProps)*Sample2
              New <- New + c(RandGMMVals, RandAbundVals)
              # Save
              InSilicoOver2 <- rbind.data.frame(InSilicoOver2, New)
            }

            # Combine the in sillico samples with the original data
            train3 <- cbind.data.frame("Original", train3)
            colnames(train3)[1] <- "Group"
            InSilicoBelow1 <- cbind.data.frame("InSilicoBelow1", InSilicoBelow1)
            colnames(InSilicoBelow1)[1] <- "Group"
            InSilicoOver1H <- cbind.data.frame("InSilicoOver1H", InSilicoOver1H)
            colnames(InSilicoOver1H)[1] <- "Group"
            InSilicoOver1 <- cbind.data.frame("InSilicoOver1", InSilicoOver1)
            colnames(InSilicoOver1)[1] <- "Group"
            InSilicoOver2 <- cbind.data.frame("InSilicoOver2", InSilicoOver2)
            colnames(InSilicoOver2)[1] <- "Group"
            train3 <- rbind.data.frame(train3, InSilicoBelow1, InSilicoOver1H, InSilicoOver1, InSilicoOver2)

            # Make an extra dataframe in the column with two classes: present and absent
            train3$Presence[train3$Abundance > 0.01] <- "Present"
            train3$Presence[train3$Abundance <= 0.01] <- "Absent"
            train3$Presence <- as.factor(train3$Presence)
            test3$Presence[test3$Abundance > 0.01] <- "Present"
            test3$Presence[test3$Abundance <= 0.01] <- "Absent"
            test3$Presence <- as.factor(test3$Presence)

            # Save the full dataframes to reload before the regression
            train3full <- train3
            test3full <- test3

            # Feature selection step
            train3Original <- train3[train3$Group == "Original",]
            train3Original <- train3Original[colnames(train3Original) != "Group"]
            train3Original <- train3Original[colnames(train3Original) != "Abundance"]
            # # Balance
            if(!summary(train3Original$Presence)[1] == summary(train3Original$Presence)[2]){train3Original <- RandOverClassif(Presence ~ ., dat = train3Original, C.perc = "balance")}
            # define the control using a random forest selection function
            control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
            # run the RFE algorithm
            results <- rfe(x = train3Original[,!names(train3Original) == "Presence"], y = train3Original$Presence, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Presence"])[2], by = 2), rfeControl = control, metric = "Accuracy")
            # plot the results
            plot(results, type = c("g", "o"))
            # Make selection
            rfeout <- results$results
            AbsoluteBest <- pickSizeBest(rfeout, metric = "Accuracy", maximize = TRUE)
            Within1Perc <- pickSizeTolerance(rfeout, metric = "Accuracy",  tol = 0.5, maximize = TRUE)
            if(results$results$Accuracy[results$results$Variables == AbsoluteBest] == 1){Within1Perc <- AbsoluteBest}
            if(Within1Perc == 1){Within1Perc <- AbsoluteBest}
            Keep <- results$optVariables[1:Within1Perc]
            KeepClassifier <- Keep
            # list the chosen features
            train3FS <- train3[c("Group", Keep, "Abundance", "Presence")]
            test3FS <- test3[c(Keep, "Abundance", "Presence")]

            # Make over 1 uniform
                  # For data without feature selection
                      Train3Over <- train3[train3$Abundance >= 0.01,]
                      Train3Below <- train3[train3$Abundance < 0.01,]
                      RangeAbundances <- range(Train3Over$Abundance)
                      BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
                      CutAbundances <- cut(Train3Over$Abundance, BreaksAbundances, right = FALSE)
                      FrequencyAbundances <- table(CutAbundances)
                      CutOff <- round(median(FrequencyAbundances))
                      Subsampled <- NULL
                      for (k in 1:length(FrequencyAbundances)){
                        # Get samples in the kth interval
                        Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
                        Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
                        SelectedData <- Train3Over[Train3Over$Abundance >= Lower & Train3Over$Abundance < Upper,]
                        # Subsample if there are more than "cutoff"
                        if (dim(SelectedData)[1] > CutOff){
                            SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                          } else {
                            SelectedData <- SelectedData
                          }
                          # Store subsampled data
                          Subsampled <- rbind(Subsampled, SelectedData)
                        }
                      Train3Over <- Subsampled
                      # Combine with the low abundant samples
                      train3 <- rbind.data.frame(Train3Over, Train3Below)
                  # For data with feature selection
                      Train3Over <- train3FS[train3FS$Abundance >= 0.01,]
                      Train3Below <- train3FS[train3FS$Abundance < 0.01,]
                      RangeAbundances <- range(Train3Over$Abundance)
                      BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
                      CutAbundances <- cut(Train3Over$Abundance, BreaksAbundances, right = FALSE)
                      FrequencyAbundances <- table(CutAbundances)
                      CutOff <- round(median(FrequencyAbundances))
                      Subsampled <- NULL
                      for (k in 1:length(FrequencyAbundances)){
                        # Get samples in the kth interval
                        Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
                        Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
                        SelectedData <- Train3Over[Train3Over$Abundance >= Lower & Train3Over$Abundance < Upper,]
                        # Subsample if there are more than "cutoff"
                        if (dim(SelectedData)[1] > CutOff){
                            SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                          } else {
                            SelectedData <- SelectedData
                          }
                          # Store subsampled data
                          Subsampled <- rbind(Subsampled, SelectedData)
                        }
                      Train3Over <- Subsampled
                      # Combine with the low abundant samples
                      train3FS <- rbind.data.frame(Train3Over, Train3Below)

            # Temporarily remove the abundance column
            train3 <- train3[colnames(train3) != "Abundance"]
            train3FS <- train3FS[colnames(train3FS) != "Abundance"]
            test3 <- test3[colnames(test3) != "Abundance"]
            test3FS <- test3FS[colnames(test3FS) != "Abundance"]

            # Remove the "Group"-column
            train3 <- train3[colnames(train3) != "Group"]
            train3FS <- train3FS[colnames(train3FS) != "Group"]
            test3 <- test3[colnames(test3) != "Group"]
            test3FS <- test3FS[colnames(test3FS) != "Group"]

            # Balance the classes
            print(summary(train3$Presence))
            if(!summary(train3$Presence)[1] == summary(train3$Presence)[2]){train3 <- RandUnderClassif(Presence ~ ., dat = train3, C.perc = "balance", repl = FALSE)}
            print(summary(train3$Presence))
            
            print(summary(train3FS$Presence))
            if(!summary(train3FS$Presence)[1] == summary(train3FS$Presence)[2]){train3FS <- RandUnderClassif(Presence ~ ., dat = train3FS, C.perc = "balance", repl = FALSE)}
            print(summary(train3FS$Presence))

            # Train models
            # For data with feature selection
                FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3FS$Presence, k = 3, times = 1), classProbs = TRUE)
                # Create tuning grid for the RF
                    # Tune RF
                    if (dim(train3FS)[2]-1 > 5) {
                      mtryoptions <- seq(1, round(dim(train3FS[,!names(train3FS) == "Presence"])[2]/5), by = 1)
                    } else {
                      mtryoptions <- seq(1, dim(train3FS)[2]-1, by = 1)
                    }
                    tunegridRF <- expand.grid(.mtry = mtryoptions)
                    # Tune SVMPoly
                    C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                    degree <- c(1, 2, 3)
                    scale <- c(1, 2)
                    tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)

                # Train models
                model_listClassifier <- caretList(Presence ~ .,
                                        data = train3FS,
                                        trControl = FitControl,
                                        tuneList = list(RF = caretModelSpec(method = "rf", tuneGrid = tunegridRF, ntree = 500)))

              # Get predictions
              if(dim(test3FS)[2] == 2){
                testset <- as.data.frame(test3FS[,!names(test3FS) == "Presence"])
                colnames(testset) <- colnames(test3FS[1])
              } else {
                testset <- as.data.frame(test3FS[,!names(test3FS) == "Presence"])
              }
              ens_preds <- predict(model_listClassifier$RF, newdata = testset, type = "raw")
              ens_preds <- cbind.data.frame(ens_preds, test3FS$Presence)
              colnames(ens_preds) <- c("Predicted", "Real")
              rownames(ens_preds) <- rownames(test3FS)
              PredRFCFS <- ens_preds
              # sum(PredRFCFS$Predicted == PredRFCFS$Real)/length(PredRFCFS$Predicted)
              
              # Get feature importances
              # From the model
              ImportancesRF <- t(as.data.frame(varImp(model_listClassifier$RF)["importance"]))
              # Features that were removed
              RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesRF)]
              ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
              names(ImportancesRemoved) <- RemovedFeatures
              #
              ImportancesClassifier <- cbind.data.frame(ImportancesRF, ImportancesRemoved)
              ImportancesClassifierFS <- ImportancesClassifier[,GMMNames]
              names(ImportancesClassifierFS) <- paste(names(ImportancesClassifierFS), "_Class", sep = "")
              
            # For data without feature selection
                FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Presence, k = 3, times = 1), classProbs = TRUE)
                    # Create tuning grid for the RF
                        # Tune RF
                        if (dim(train3)[2]-1 > 5) {
                          mtryoptions <- seq(1, round(dim(train3[,!names(train3) == "Presence"])[2]/5), by = 1)
                        } else {
                          mtryoptions <- seq(1, dim(train3)[2]-1, by = 1)
                        }
                        tunegridRF <- expand.grid(.mtry = mtryoptions)
                        # Tune SVMPoly
                        C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                        degree <- c(1, 2, 3)
                        scale <- c(1, 2)
                        tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)
    
                    # Train models
                    model_listClassifier <- caretList(Presence ~ .,
                                            data = train3,
                                            trControl = FitControl,
                                            tuneList = list(RF = caretModelSpec(method = "rf", tuneGrid = tunegridRF, ntree = 500)))
    
                  # Get predictions
                  if(dim(test3)[2] == 2){
                    testset <- as.data.frame(test3[,!names(test3) == "Presence"])
                    colnames(testset) <- colnames(test3[1])
                  } else {
                    testset <- as.data.frame(test3[,!names(test3) == "Presence"])
                  }
                  ens_preds <- predict(model_listClassifier$RF, newdata = testset, type = "raw")
                  ens_preds <- cbind.data.frame(ens_preds, test3$Presence)
                  colnames(ens_preds) <- c("Predicted", "Real")
                  rownames(ens_preds) <- rownames(test3)
                  PredRFC <- ens_preds
                  # sum(PredRFC$Predicted == PredRFC$Real)/length(PredRFC$Predicted)
                  
                  # Get feature importances
                  # From the model
                  ImportancesRF <- t(as.data.frame(varImp(model_listClassifier$RF)["importance"]))
                  # Features that were removed
                  RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesRF)]
                  ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                  names(ImportancesRemoved) <- RemovedFeatures
                  #
                  ImportancesClassifier <- cbind.data.frame(ImportancesRF, ImportancesRemoved)
                  ImportancesClassifier <- ImportancesClassifier[,GMMNames]
                  names(ImportancesClassifier) <- paste(names(ImportancesClassifier), "_Class", sep = "")

              


              ### REGRESSION ###
              # Temporarily remove the abundance column
              train3 <- train3full
              test3 <- test3full

              # Remove "Presence"-column
              train3 <- train3[colnames(train3) != "Presence"]
              test3 <- test3[colnames(test3) != "Presence"]

              # Feature selection step
              train3Original <- train3[train3$Group == "Original",]
              train3Original <- train3Original[colnames(train3Original) != "Group"]
              # more homogeneous distribution
              train3OriginalLower <- train3Original[train3Original$Abundance < 0.01,]
              train3OriginalHigher <- train3Original[train3Original$Abundance >= 0.01,]
              if(dim(train3OriginalLower)[1] > dim(train3OriginalHigher)[1]){
                train3OriginalLower <- train3OriginalLower[sample(nrow(train3OriginalLower), dim(train3OriginalHigher)[1]), ]
              }
              train3Original <- rbind.data.frame(train3OriginalLower, train3OriginalHigher)
              if(dim(train3Original)[1] > 10){
                    # define the control using a random forest selection function
                    control <- rfeControl(functions = rfFuncs, method = "repeatedcv", repeats = 25, number = 5)
                    # run the RFE algorithm
                    results <- rfe(x = train3Original[,!names(train3Original) == "Abundance"], y = train3Original$Abundance, sizes = seq(from = 1, to = dim(train3Original[,!names(train3Original) == "Abundance"])[2], by = 2), rfeControl = control, metric = "Rsquared")
                    # plot the results
                    plot(results, type = c("g", "o"))
                    # Make selection
                    rfeout <- results$results
                    if(sum(rfeout$Rsquared == 1) == length(rfeout$Rsquared)){
                      Keep <- Keep
                    } else {
                      Within1Perc <- pickSizeTolerance(rfeout, metric = "Rsquared",  tol = 0.5, maximize = TRUE)
                      Keep <- results$optVariables[1:Within1Perc]
                    }
                    # Get the chosen features
                    train3FS <- train3[c("Group", Keep, "Abundance")]
                    test3FS <- test3[c(Keep, "Abundance")]
              } else {
                train3FS <- train3
                test3FS <- test3
              }
              # Remove the group-column
              train3 <- train3[colnames(train3) != "Group"]
              train3FS <- train3FS[colnames(train3FS) != "Group"]

              # Reduce imbalance in the dataset
                    # For data with feature selection
                      RangeAbundances <- range(train3FS$Abundance)
                      BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
                      CutAbundances <- cut(train3FS$Abundance, BreaksAbundances, right = FALSE)
                      FrequencyAbundances <- table(CutAbundances)
                      CutOff <- round(median(FrequencyAbundances))
                      Subsampled <- NULL
                      for (k in 1:length(FrequencyAbundances)){
                        # Get samples in the kth interval
                        Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
                        Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
                        SelectedData <- train3FS[train3FS$Abundance >= Lower & train3FS$Abundance < Upper,]
                        # Subsample if there are more than "cutoff"
                        if (dim(SelectedData)[1] > CutOff){
                          SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                        } else {
                          SelectedData <- SelectedData
                        }
                        # Store subsampled data
                        Subsampled <- rbind(Subsampled, SelectedData)
                      }
                      train3FS <- Subsampled
                    
                    # For data without feature selection
                      RangeAbundances <- range(train3$Abundance)
                      BreaksAbundances <- seq(RangeAbundances[1], RangeAbundances[2], by = ((RangeAbundances[2] - RangeAbundances[1])/100))
                      CutAbundances <- cut(train3$Abundance, BreaksAbundances, right = FALSE)
                      FrequencyAbundances <- table(CutAbundances)
                      CutOff <- round(median(FrequencyAbundances))
                      Subsampled <- NULL
                      for (k in 1:length(FrequencyAbundances)){
                        # Get samples in the kth interval
                        Lower <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k-1)
                        Upper <- RangeAbundances[1] + ((RangeAbundances[2] - RangeAbundances[1])/100)*(k)
                        SelectedData <- train3[train3$Abundance >= Lower & train3$Abundance < Upper,]
                        # Subsample if there are more than "cutoff"
                        if (dim(SelectedData)[1] > CutOff){
                          SelectedData <- SelectedData[sample(nrow(SelectedData), CutOff), ]
                        } else {
                          SelectedData <- SelectedData
                        }
                        # Store subsampled data
                        Subsampled <- rbind(Subsampled, SelectedData)
                      }
                      train3 <- Subsampled

              # Logit transformation --> ensure predictions are in the 0-1 range
              train3$Abundance[train3$Abundance >= 1] <- 1 - minvalue/10
              train3$Abundance[train3$Abundance <= 0] <- minvalue/10
              train3$Abundance <- boot::logit(train3$Abundance)
              
              train3FS$Abundance[train3FS$Abundance >= 1] <- 1 - minvalue/10
              train3FS$Abundance[train3FS$Abundance <= 0] <- minvalue/10
              train3FS$Abundance <- boot::logit(train3FS$Abundance)

            # Train models
            # For data with feature selection
              ### Caret list
              FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3FS$Abundance, k = 3, times = 1), summaryFunction = mapeexpSummary)
                  # Create tuning grids
                      # Tune SVMPoly
                      C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                      degree <- c(1, 2, 3)
                      scale <- c(1, 2)
                      tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)
                      # Tune gradient boost
                      n.trees <- c(50, 100, 250, 500)
                      interaction.depth <- c(1)
                      shrinkage <- c(0.3, 0.2, 0.1, 0.05, 0.01)
                      n.minobsinnode <- seq(1, 3, by = 1)
                      tunegridGBM <- expand.grid(n.trees = n.trees, interaction.depth = interaction.depth, shrinkage = shrinkage, n.minobsinnode = n.minobsinnode)

                  # Train models
                  model_list <- caretList(Abundance ~ .,
                                        data = train3FS,
                                        trControl = FitControl,
                                        tuneList = list(SVMPoly = caretModelSpec(method = "svmPoly", tuneGrid = tunegridSVMPoly, metric = "Rsquared"),
                                                        GBM = caretModelSpec(method = "gbm", tuneGrid = tunegridGBM, metric = "Rsquared")))

              # make ensemble
              greedy_ensemble <- caretEnsemble(model_list, trControl = FitControl, metric = "Rsquared")

              # Get feature importances
                  # From the model
                  ImportancesEnsemble <- t(as.data.frame(varImp(greedy_ensemble)["overall"]))
                  # Features that were removed
                  RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesEnsemble)]
                  ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                  names(ImportancesRemoved) <- RemovedFeatures
                  #
                  ImportancesEnsemble <- cbind.data.frame(ImportancesEnsemble, ImportancesRemoved)
                  ImportancesEnsembleFS <- ImportancesEnsemble[,GMMNames]
                  names(ImportancesEnsembleFS) <- paste(names(ImportancesEnsembleFS), "_Reg", sep = "")
              
              # Make predictions
              if(dim(test3FS)[2] == 2){
                testset <- as.data.frame(test3FS[,!names(test3FS) == "Abundance"])
                colnames(testset) <- colnames(test3FS[1])
              } else {
                testset <- as.data.frame(test3FS[,!names(test3FS) == "Abundance"])
              }
              ens_preds <- predict(greedy_ensemble, newdata = testset)
              ens_preds <- cbind.data.frame(ens_preds, test3FS$Abundance)
              colnames(ens_preds) <- c("Predicted", "Real")
              rownames(ens_preds) <- rownames(test3)

              # Reverse the logit transform
              ens_preds$Predicted <- boot::inv.logit(ens_preds$Predicted)
              
              ### Combine predictions from the classifier and regression ###
              Predictions <- as.data.frame(matrix(, nrow = length(test3FS$Abundance), ncol = 2))
              colnames(Predictions) <- c("Predicted", "Real")
              Predictions$Predicted <- ens_preds$Predicted
              Predictions$Predicted[PredRFCFS$Predicted == "Absent"] <- 0
              Predictions$Real <- ens_preds$Real
              rownames(Predictions) <- rownames(test3FS)
              PredictionsFS <- Predictions
              
            # For data with feature selection  
                    ### Caret list
                    FitControl <- trainControl(method = "cv", number = 5, returnResamp = "final", savePredictions = "final", index = createMultiFolds(train3$Abundance, k = 3, times = 1), summaryFunction = mapeexpSummary)
                        # Create tuning grids
                            # Tune SVMPoly
                            C <- c(0.001, 0.01, 0.1, 1, 10, 100)
                            degree <- c(1, 2, 3)
                            scale <- c(1, 2)
                            tunegridSVMPoly <- expand.grid(C = C, degree = degree, scale = scale)
                            # Tune gradient boost
                            n.trees <- c(50, 100, 250, 500)
                            interaction.depth <- c(1)
                            shrinkage <- c(0.3, 0.2, 0.1, 0.05, 0.01)
                            n.minobsinnode <- seq(1, 3, by = 1)
                            tunegridGBM <- expand.grid(n.trees = n.trees, interaction.depth = interaction.depth, shrinkage = shrinkage, n.minobsinnode = n.minobsinnode)
      
                        # Train models
                        model_list <- caretList(Abundance ~ .,
                                              data = train3,
                                              trControl = FitControl,
                                              tuneList = list(SVMPoly = caretModelSpec(method = "svmPoly", tuneGrid = tunegridSVMPoly, metric = "Rsquared"),
                                                              GBM = caretModelSpec(method = "gbm", tuneGrid = tunegridGBM, metric = "Rsquared")))
      
                    # make ensemble
                    greedy_ensemble <- caretEnsemble(model_list, trControl = FitControl, metric = "Rsquared")
                    # Get feature importances
                    # From the model
                    ImportancesEnsemble <- t(as.data.frame(varImp(greedy_ensemble)["overall"]))
                    # Features that were removed
                    RemovedFeatures <- GMMNames[!GMMNames %in% colnames(ImportancesEnsemble)]
                    ImportancesRemoved <- as.data.frame(t(rep(0, length(RemovedFeatures))))
                    names(ImportancesRemoved) <- RemovedFeatures
                    #
                    ImportancesEnsemble <- cbind.data.frame(ImportancesEnsemble, ImportancesRemoved)
                    ImportancesEnsemble <- ImportancesEnsemble[,GMMNames]
                    names(ImportancesEnsemble) <- paste(names(ImportancesEnsemble), "_Reg", sep = "")
  
                    # Make predictions
                    if(dim(test3)[2] == 2){
                      testset <- as.data.frame(test3[,!names(test3) == "Abundance"])
                      colnames(testset) <- colnames(test3[1])
                    } else {
                      testset <- as.data.frame(test3[,!names(test3) == "Abundance"])
                    }
                    ens_preds <- predict(greedy_ensemble, newdata = testset)
                    ens_preds <- cbind.data.frame(ens_preds, test3$Abundance)
                    colnames(ens_preds) <- c("Predicted", "Real")
                    rownames(ens_preds) <- rownames(test3)
      
                    # Reverse the logit transform
                    ens_preds$Predicted <- boot::inv.logit(ens_preds$Predicted)
                    
                    ### Combine predictions from the classifier and regression ###
                    Predictions <- as.data.frame(matrix(, nrow = length(test3$Abundance), ncol = 2))
                    colnames(Predictions) <- c("Predicted", "Real")
                    Predictions$Predicted <- ens_preds$Predicted
                    Predictions$Predicted[PredRFC$Predicted == "Absent"] <- 0
                    Predictions$Real <- ens_preds$Real
                    rownames(Predictions) <- rownames(test3)

              
              
              
              
              # Save the predictions
              NOFS <- cbind.data.frame(fold, "NOFS", rownames(Predictions), Predictions, ImportancesClassifier, ImportancesEnsemble)
              colnames(NOFS)[1:5] <- c("fold", "Cat", "ID", "Predicted", "Real")
              FS <- cbind.data.frame(fold, "FS", rownames(PredictionsFS), PredictionsFS, ImportancesClassifierFS, ImportancesEnsembleFS)
              colnames(FS)[1:5] <- c("fold", "Cat", "ID", "Predicted", "Real")
              Predictions <- rbind.data.frame(NOFS, FS)            
              # AllPredictions <- rbind(AllPredictions, Predictions)
              AllPredictions <- cbind.data.frame(rep, Predictions)
              
              PredictionsPerFold <- rbind.data.frame(PredictionsPerFold, AllPredictions)
        }

      # Plot all predictions on the testset
        AllPredictions$Predicted <- 100*AllPredictions$Predicted
        AllPredictions$Real <- 100*AllPredictions$Real
        # AllPredictions$Predicted <- AllPredictions$Predicted/100
        # AllPredictions$Real <- AllPredictions$Real/100
        p_pred <- ggplot(AllPredictions, aes(x = Real, y = Predicted, fill = Cat)) +
                            geom_point(shape = 21, size = 2) +
                            geom_abline(intercept = 0, slope = 1) +
                            facet_grid(. ~ Cat) + 
                            coord_fixed() +
                            scale_y_continuous(limits = c(0, 100)) +
                            scale_x_continuous(limits = c(0, 100)) +
                            # ggtitle(OTUOfInterest) +
                            labs(x = "True abundance (%)", y = "Predicted abundance (%)") +
                            theme_cowplot() +
                            theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet))
        p_pred
      
        
        # Save performances
        FS <- AllPredictions[AllPredictions$Cat == "FS",]
        NOFS <- AllPredictions[AllPredictions$Cat == "NOFS",]
        
        
      # Save predictions and calculate performance metics
        MOCK_PerformanceDataset_ALL_NIS <- rbind(MOCK_PerformanceDataset_ALL_NIS, cbind.data.frame(TaxonOfInterest, rep, R2(FS$Predicted, FS$Real),R2(NOFS$Predicted, NOFS$Real), MAE(FS$Predicted, FS$Real), MAE(NOFS$Predicted, NOFS$Real), RMSE(FS$Predicted, FS$Real), RMSE(NOFS$Predicted, NOFS$Real)))

  }
}

colnames(MOCK_PerformanceDataset_ALL_NIS) <- c("OTU", "Rep", "R2_FS", "R2_NOFS", "MAE_FS", "MAE_NOFS", "RMSE_FS", "RMSE_NOFS")

# Forgot to include strain
PredictionsPerFold$OTU <- c(rep(colnames(Metadata)[1], dim(PredictionsPerFold)[1]/3), rep(colnames(Metadata)[2], dim(PredictionsPerFold)[1]/3), rep(colnames(Metadata)[3], dim(PredictionsPerFold)[1]/3))

# write.csv(MOCK_PerformanceDataset_ALL_NIS, "Results/MOCK_Performance_FeatureSelection.csv")
# write.csv(PredictionsPerFold, "Results/MOCK_PredictionsPerFold_FeatureSelection.csv")
```

## Plot

### Model performances

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Upload
PredictionsPerFold <- read.csv("Results/MOCK_PredictionsPerFold_ALL_IS_AUC.csv")
# Calculate false positive and false negative rates
# shared.t.ns.rel <- sweep(shared.t.ns, 2, colSums(shared.t.ns), `/`)
# shared.t.ns.rel <- shared.t.ns.rel[NonSorted]
Results <- NULL
for (i in unique(PredictionsPerFold$OTU)){
  for (j in unique(PredictionsPerFold$rep)){
    # Select the predictions from this repeat of the selected fold
    SelectedSet <- PredictionsPerFold[PredictionsPerFold$OTU == i & PredictionsPerFold$rep == j,]
    # R2
    R2_Regression <- R2(SelectedSet$Regression, SelectedSet$TrueValue)
    R2_Final <- R2(SelectedSet$Combined, SelectedSet$TrueValue)
    # MAE
    MAE_Regression <- MAE(SelectedSet$Regression, SelectedSet$TrueValue)
    MAE_Final <- MAE(SelectedSet$Combined, SelectedSet$TrueValue)
    # nMAE_Regression <- MAE(SelectedSet$Regression, SelectedSet$TrueValue)/mean(as.matrix(shared.t.ns.rel[i,]))
    # nMAE_Final <- MAE(SelectedSet$Combined, SelectedSet$TrueValue)/mean(as.matrix(shared.t.ns.rel[i,]))
    # # False positive and negative before imposing classifier
    # FPBefore <- dim(SelectedSet[SelectedSet$TrueClass == "Absent" & SelectedSet$Regression >= 0.01,])[1]
    # FNBefore <- dim(SelectedSet[SelectedSet$TrueClass == "Present" & SelectedSet$Regression < 0.01,])[1]
    # # False positive and negative after imposing classifier
    # FPAfter <- dim(SelectedSet[SelectedSet$TrueClass == "Absent" & SelectedSet$Combined >= 0.01,])[1]
    # FNAfter <- dim(SelectedSet[SelectedSet$TrueClass == "Present" & SelectedSet$Combined < 0.01,])[1]
    # # Add absolute abundances
    # SelectedSet$Index <- as.character(SelectedSet$Index)
    # SelectedSet <- left_join(SelectedSet, Subsetphyseqobj[c("OTU", "Sample", "BacterialDensity")], by = c("OTU" = "OTU", "Index" = "Sample"))
    # SelectedSet$CombinedAbsolute <- SelectedSet$Combined*SelectedSet$BacterialDensity
    # SelectedSet$TrueValueAbsolute <- SelectedSet$TrueValue*SelectedSet$BacterialDensity
    # R2_Final_Absolute <- R2(SelectedSet$CombinedAbsolute, SelectedSet$TrueValueAbsolute)
    # Save results
    Results <- rbind.data.frame(Results, cbind.data.frame(i, j, R2_Regression, R2_Final, MAE_Regression, MAE_Final)) # nMAE_Regression, nMAE_Final, FPBefore, FNBefore, FPAfter, FNAfter, R2_Final_Absolute
  }
}
colnames(Results)[1:2] <- c("OTU", "rep")
Results <- Results[complete.cases(Results),]
Results <- melt(Results, id.vars = c("OTU", "rep"))
Results2 <- Results

# Sort the dataframe according to average performance
MeanRegressionPerformance <- Results %>% group_by(OTU, variable) %>% summarise_at(.vars = names(.)[4], .funs = c(mean = "mean", sd = "sd"))
Results <- left_join(Results, MeanRegressionPerformance, by = c("OTU", "variable"))
ResultsRegression <- Results %>% dplyr::filter(variable %in% c("R2_Final", "R2_Regression"))
ResultsRegression$OTU[ResultsRegression$OTU == "Ppolymyxa"] <- "P. polymyxa"
ResultsRegression$OTU[ResultsRegression$OTU == "Srhizophila"] <- "S. rhizophila"
ResultsRegression$OTU[ResultsRegression$OTU == "Krhizophila"] <- "K. rhizophila"
ResultsRegression <- ResultsRegression[order(-ResultsRegression$mean),] 
ResultsRegression$OTU <- factor(ResultsRegression$OTU, levels = unique(ResultsRegression$OTU))

# Plot R2 values
p_R2_MOCK <- ResultsRegression %>%
              dplyr::filter(variable %in% c("R2_Final")) %>%
              ggplot(data = ., aes(x = OTU, y = value, fill = variable)) +
              geom_errorbar(aes(x = OTU, ymin = mean, ymax = mean), color = "#91518b", width = 0.5) +
              geom_point(shape = 21, fill = "#91518b") +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
              guides(color = FALSE, fill = FALSE) + 
              labs(color = "", y = expression(paste("R"^"2")), x = "") +
              scale_y_continuous(limits = c(0, 1))
print(p_R2_MOCK)

# Min, max and mean
min(ResultsRegression$mean[ResultsRegression$variable == "R2_Regression"])
max(ResultsRegression$mean[ResultsRegression$variable == "R2_Regression"])
mean(ResultsRegression$mean[ResultsRegression$variable == "R2_Regression"])
min(ResultsRegression$mean[ResultsRegression$variable == "R2_Final"])
max(ResultsRegression$mean[ResultsRegression$variable == "R2_Final"])
mean(ResultsRegression$mean[ResultsRegression$variable == "R2_Final"])
sd(ResultsRegression$mean[ResultsRegression$variable == "R2_Final"])

# Plot MAE values
MeanRegressionPerformanceMAE <- Results2 %>% group_by(OTU, variable) %>% summarise_at(.vars = names(.)[4], .funs = c(mean = "mean", sd = "sd"))
MeanRegressionPerformanceMAE <- left_join(Results2, MeanRegressionPerformanceMAE, by = c("OTU", "variable"))
MeanRegressionPerformanceMAE <- MeanRegressionPerformanceMAE %>% dplyr::filter(variable %in% c("MAE_Final", "MAE_Regression", "nMAE_Final", "nMAE_Regression"))
MeanRegressionPerformanceMAE <- left_join(MeanRegressionPerformanceMAE, Taxonomy, by = c("OTU"))
MeanRegressionPerformanceMAE$Label <- paste(MeanRegressionPerformanceMAE$OTU, " (", MeanRegressionPerformanceMAE$Genus, ")", sep = "")
MeanRegressionPerformanceMAE$Label <- factor(MeanRegressionPerformanceMAE$Label, levels =  levels(ResultsRegression$Label))

p_MAE <- MeanRegressionPerformanceMAE %>%
              dplyr::filter(variable %in% c("MAE_Final", "MAE_Regression")) %>%
              ggplot(data = ., aes(x = OTU, y = 100*value, fill = variable)) +
              geom_errorbar(aes(x = Label, ymin = 100*mean, ymax = 100*mean, color = variable), width = 0.5, size = 1) +
              geom_point(shape = 21) +
              scale_fill_manual("", values = c("#6c72dd", "#4fb783"), labels = c("Regression alone", "Final model")) +
              scale_color_manual("", values = c("#6c72dd", "#4fb783")) +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm"), legend.position = "none", legend.justification = "center") +
              guides(color = FALSE, fill = guide_legend(override.aes = list(size = 3))) + 
              labs(color = "", y = "MAE", x = "")
print(p_MAE)
```

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Calculate false positive and false negative rates
Results <- NULL
for (i in unique(PredictionsPerFold$OTU)){
  for (j in unique(PredictionsPerFold$rep)){
    # Select the predictions from this repeat of the selected fold
    SelectedSet <- PredictionsPerFold[PredictionsPerFold$OTU == i & PredictionsPerFold$rep == j,]
    SelectedSet$CombinedClass <- "Absent"
    SelectedSet$CombinedClass[SelectedSet$Combined > 0.01] <- "Present"
    # Accuracy
    Accuracy_Classifier <- sum(SelectedSet$PredictedClass == SelectedSet$TrueClass)/length(SelectedSet$TrueClass)
    Accuracy_Final <- sum(SelectedSet$CombinedClass == SelectedSet$TrueClass)/length(SelectedSet$TrueClass)
    # False positive: Negatives with positive outcome/All negatives 
    NrFalsePositive <- length(SelectedSet$X[SelectedSet$TrueClass == "Absent" & SelectedSet$PredictedClass == "Present"])
    NrTotalTrueAbsent <- length(SelectedSet$X[SelectedSet$TrueClass == "Absent"])
    FalsePositiveRate <- NrFalsePositive/NrTotalTrueAbsent
    # False negative
    NrFalseNegative <- length(SelectedSet$X[SelectedSet$TrueClass == "Present" & SelectedSet$PredictedClass == "Absent"])
    NrTotalTruePresent <- length(SelectedSet$X[SelectedSet$TrueClass == "Present"])
    FalseNegativeRate <- NrFalseNegative/NrTotalTruePresent
    # Save results
    Results <- rbind.data.frame(Results, cbind.data.frame(i, j, Accuracy_Classifier, Accuracy_Final, NrFalsePositive, NrFalseNegative, FalsePositiveRate, FalseNegativeRate))
  }
}
colnames(Results)[1:2] <- c("OTU", "rep")
Results <- Results[complete.cases(Results),]
Results <- melt(Results, id.vars = c("OTU", "rep"))

# Plot model accuracies of the classifier alone
# Sort the dataframe according to average performance
MeanClassifierPerformance <- Results %>% group_by(OTU, variable) %>% summarise_at(.vars = names(.)[4],.funs = c(mean = "mean", sd = "sd"))
Results <- left_join(Results, MeanClassifierPerformance, by = c("OTU", "variable"))
ResultsClassifier <- Results %>% dplyr::filter(variable %in% c("Accuracy_Classifier"))
ResultsClassifier <- ResultsClassifier[order(-ResultsClassifier$mean),]
ResultsClassifier$OTU[ResultsClassifier$OTU == "Ppolymyxa"] <- "P. polymyxa"
ResultsClassifier$OTU[ResultsClassifier$OTU == "Srhizophila"] <- "S. rhizophila"
ResultsClassifier$OTU[ResultsClassifier$OTU == "Krhizophila"] <- "K. rhizophila"
ResultsClassifier$OTU <- factor(ResultsClassifier$OTU, levels = unique(ResultsClassifier$OTU))

# Plot
p_AccuracyMock <- ResultsClassifier %>% 
                      dplyr::filter(variable %in% c("Accuracy_Classifier")) %>% 
                      ggplot(data = ., aes(x = OTU, y = 100*value)) +
                      geom_errorbar(aes(x = OTU, ymin = 100*mean, ymax = 100*mean), color = "#91518b", width = 0.5) +
                      geom_point(shape = 21, fill = "#91518b") +
                      geom_hline(yintercept = 50, color = "#5b5b5b") + 
                      # annotate("text", x = 10, y = 55, size = 3, label = c('random guessing'), color = "black") +
                      # scale_x_discrete("", labels = Label) +
                      theme_cowplot() +
                      theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
                      labs(color = "", y = "Accuracy (%)", x = "") +
                      guides(color = FALSE, fill = FALSE) + 
                      scale_y_continuous(limits = c(0, 100))
print(p_AccuracyMock)
```

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Plot AUC values
PerformanceDataset <- read.csv("Results/MOCK_PerformanceDataset_ALL_IS_AUC.csv")
PerformanceDataset <- PerformanceDataset[c("TaxonOfInterest", "AUC_ALL")]
MeanAUC <- PerformanceDataset %>% group_by(TaxonOfInterest) %>% summarise_at(.vars = names(.)[2], .funs = c(mean = "mean", sd = "sd"))
PerformanceDataset <- left_join(PerformanceDataset, MeanAUC, by = c("TaxonOfInterest"))

PerformanceDataset$TaxonOfInterest[PerformanceDataset$TaxonOfInterest == "Ppolymyxa"] <- "P. polymyxa" 
PerformanceDataset$TaxonOfInterest[PerformanceDataset$TaxonOfInterest == "Srhizophila"] <- "S. rhizophila" 
PerformanceDataset$TaxonOfInterest[PerformanceDataset$TaxonOfInterest == "Krhizophila"] <- "K. rhizophila" 

# Change order to match regression for plot
PerformanceDataset$TaxonOfInterest <- factor(PerformanceDataset$TaxonOfInterest, levels = unique(ResultsRegression$OTU))
p_AUCMock <- PerformanceDataset %>% 
              ggplot(data = ., aes(x = TaxonOfInterest, y = AUC_ALL)) +
              geom_errorbar(aes(x = TaxonOfInterest, ymin = mean, ymax = mean), color = "#91518b", width = 0.5) +
              geom_point(shape = 21, fill = "#91518b") +
              geom_hline(yintercept = 0.5, color = "#5b5b5b") + 
              scale_y_continuous(breaks = seq(0, 1, by = 0.25), limits = c(0, 1)) +
              # annotate("text", x = 10, y = 55, size = 3, label = c('random guessing'), color = "black") +
              # scale_x_discrete("", labels = Label) +
              theme_cowplot() +
              theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), axis.text.x = element_text(angle = 65, hjust = 1), plot.margin = unit(c(0.2, 0.2, 0.2, 2), "cm")) +
              labs(color = "", y = "AUC", x = "") +
              guides(color = FALSE, fill = FALSE)
print(p_AUCMock)
```

```{r RidgeRegression, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
g1 <- plot_grid(p_AUCMock, p_R2_MOCK, p_AUCReactor, p_R2_REACTOR, labels = c("A", "B", "C", "D"), ncol = 2, nrow = 2, scale = 1, rel_heights = c(0.6, 1))
g1
ggsave(file = "Figures/VALIDATION-CombinedPerformances.png", width = 10, height = 10, dpi = 300, units = "in", g1)
```

### Location of the GMMs

```{r PlotFeatures_RandomForest, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Upload results
PerformancePerFold <- read.csv("Results/MOCK_PerformancePerFold_ALL_IS_AUC.csv") 
# Change columnames
colnames(PerformancePerFold)[1:8] <- c("X", "OTU", "rep", "fold", "RMSE", "MAE", "r2", "Classif")


# Feature importances classifier
ImporancesClassifier <- cbind.data.frame(PerformancePerFold$OTU, PerformancePerFold[, grepl("_Class", names(PerformancePerFold))])
colnames(ImporancesClassifier)[1] <- "OTU"
MeanImporancesClassifier <- ImporancesClassifier %>%
                            group_by(OTU) %>%
                            summarise(across(everything(), list(mean)))
Taxa <- MeanImporancesClassifier$OTU
MeanImporancesClassifier <- t(MeanImporancesClassifier[!colnames(MeanImporancesClassifier) == "OTU"])
colnames(MeanImporancesClassifier) <- paste("Class_", Taxa, sep = "")
MeanImporancesClassifier <- as.data.frame(MeanImporancesClassifier)
MeanImporancesClassifier$GMM <- gsub("_Class_1", "", rownames(MeanImporancesClassifier))
# Add a column with TRUE FALSE to evaluate which GMMs are included in the model
MeanImporancesClassifier <- cbind.data.frame(MeanImporancesClassifier, MeanImporancesClassifier[colnames(MeanImporancesClassifier)[!colnames(MeanImporancesClassifier) == "GMM"]] > 0)
colnames(MeanImporancesClassifier)[5:7] <- paste(colnames(MeanImporancesClassifier)[5:7], "_LOGIC", sep = "")

# Feature importances regression
ImporancesRegression <- cbind.data.frame(PerformancePerFold$OTU, PerformancePerFold[, grepl("_Reg", names(PerformancePerFold))])
colnames(ImporancesRegression)[1] <- "OTU"
MeanImporancesRegression <- ImporancesRegression %>%
                            group_by(OTU) %>%
                            summarise(across(everything(), list(mean)))
Taxa <- MeanImporancesRegression$OTU
MeanImporancesRegression <- t(MeanImporancesRegression[!colnames(MeanImporancesRegression) == "OTU"])
colnames(MeanImporancesRegression) <- paste("Reg_", Taxa, sep = "")
MeanImporancesRegression <- as.data.frame(MeanImporancesRegression)
MeanImporancesRegression$GMM <- gsub("_Reg_1", "", rownames(MeanImporancesRegression))
# Add a column with TRUE FALSE to evaluate which GMMs are included in the model
MeanImporancesRegression <- cbind.data.frame(MeanImporancesRegression, MeanImporancesRegression[colnames(MeanImporancesRegression)[!colnames(MeanImporancesRegression) == "GMM"]] > 0)
colnames(MeanImporancesRegression)[5:7] <- paste(colnames(MeanImporancesRegression)[5:7], "_LOGIC", sep = "")

# Make a pooled sample and add the corresponding GMM identities per cell
Pooled <- FCS_pool(flowData_transformed, stub = "100") # pure cultures
PooledSubsampled <- FCS_resample(Pooled, replace = TRUE, sample = 20000)
PooledSubsampled <- PooledSubsampled[, params_gmm]
grid <- PooledSubsampled[[1]]@exprs
pred <- predict(gmm_clust, grid)
grid <- cbind.data.frame(grid, paste("GMM", pred$classification, sep = ""))
colnames(grid)[length(params_gmm)+1] <- "Classification"
# Add the importances to each of the cells according to the GMM to which they belong
grid <- left_join(grid, MeanImporancesClassifier, by = c("Classification" = "GMM"))
grid <- left_join(grid, MeanImporancesRegression, by = c("Classification" = "GMM"))

# Plot for classifier
        # P polymyxa
        p_Class_Ppolymyxa <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Class_Ppolymyxa)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Class_Ppolymyxa)), direction = 1) +
                          labs(x = "Forward scatter", y = "DAPI fluorescence", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Class_Ppolymyxa)


        # S rhizophilia
        p_Class_Srhizophila <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Class_Srhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Class_Srhizophila)), direction = 1) +
                          labs(x = "Forward scatter", y = "DAPI fluorescence", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Class_Srhizophila)
        

        # K rhizophilia
        p_Class_Krhizophila <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Class_Krhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Class_Krhizophila)), direction = 1) +
                          labs(x = "Forward scatter", y = "DAPI fluorescence", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Class_Krhizophila)


# Plot for regression
        p_Reg_Ppolymyxa <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Reg_Ppolymyxa)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Reg_Ppolymyxa)), direction = 1) +
                          labs(x = "Forward scatter", y = "DAPI fluorescence", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Reg_Ppolymyxa)

        p_Reg_Srhizophila <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Reg_Srhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Reg_Srhizophila)), direction = 1) +
                          labs(x = "Forward scatter", y = "DAPI fluorescence", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Reg_Srhizophila)
        
        p_Reg_Krhizophila <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Reg_Krhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Reg_Krhizophila)), direction = 1) +
                          labs(x = "Forward scatter", y = "DAPI fluorescence", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Reg_Krhizophila)
```

```{r LoadLibraries, message = FALSE, warning = FALSE}
p_PureCultures <- plot_grid(p_Ppolymyxa, p_Srhizophila, p_Krhizophila, labels = c("A", "B", "C"), ncol = 3, nrow = 1, scale = 0.9)
p_Class <- plot_grid(p_Class_Ppolymyxa, p_Class_Srhizophila, p_Class_Krhizophila, labels = c("D", "E", "F"), ncol = 3, nrow = 1, scale = 0.9)
p_Reg <- plot_grid(p_Reg_Ppolymyxa, p_Reg_Srhizophila, p_Reg_Krhizophila, labels = c("G", "H", "I"), ncol = 3, nrow = 1, scale = 0.9)
CombinedFeatureImporances <- plot_grid(p_PureCultures, p_Class, p_Reg,  rel_heights = c(0.8, 1, 1), nrow = 3, scale = 1)
# CombinedFeatureImporances
ggsave(file = "Figures/MOCK-CombinedFeatureImporances.png", width = 14, height = 13, dpi = 500, units = "in", CombinedFeatureImporances)
```

### Advantage of feature selection

```{r PlotFeatures_RandomForest, echo = FALSE, dpi = 500, fig.width = 12, fig.height = 8, dev = c("png"), message = FALSE, warning = FALSE, cache = TRUE}
# Upload results
PerformancePerFoldAll <- read.csv("Results/MOCK_PredictionsPerFold_FeatureSelection.csv") 
PerformancePerFold <- PerformancePerFoldAll[PerformancePerFoldAll$Cat == "NOFS",]

# Feature importances classifier
ImporancesClassifier <- cbind.data.frame(PerformancePerFold$OTU, PerformancePerFold[, grepl("_Class", names(PerformancePerFold))])
colnames(ImporancesClassifier)[1] <- "OTU"
MeanImporancesClassifier <- ImporancesClassifier %>%
                            group_by(OTU) %>%
                            summarise(across(everything(), list(mean)))
Taxa <- MeanImporancesClassifier$OTU
MeanImporancesClassifier <- t(MeanImporancesClassifier[!colnames(MeanImporancesClassifier) == "OTU"])
colnames(MeanImporancesClassifier) <- paste("Class_", Taxa, sep = "")
MeanImporancesClassifier <- as.data.frame(MeanImporancesClassifier)
MeanImporancesClassifier$GMM <- gsub("_Class_1", "", rownames(MeanImporancesClassifier))
# Add a column with TRUE FALSE to evaluate which GMMs are included in the model
MeanImporancesClassifier <- cbind.data.frame(MeanImporancesClassifier, MeanImporancesClassifier[colnames(MeanImporancesClassifier)[!colnames(MeanImporancesClassifier) == "GMM"]] > 0)
colnames(MeanImporancesClassifier)[5:7] <- paste(colnames(MeanImporancesClassifier)[5:7], "_LOGIC", sep = "")

# Feature importances regression
ImporancesRegression <- cbind.data.frame(PerformancePerFold$OTU, PerformancePerFold[, grepl("_Reg", names(PerformancePerFold))])
colnames(ImporancesRegression)[1] <- "OTU"
MeanImporancesRegression <- ImporancesRegression %>%
                            group_by(OTU) %>%
                            summarise(across(everything(), list(mean)))
Taxa <- MeanImporancesRegression$OTU
MeanImporancesRegression <- t(MeanImporancesRegression[!colnames(MeanImporancesRegression) == "OTU"])
colnames(MeanImporancesRegression) <- paste("Reg_", Taxa, sep = "")
MeanImporancesRegression <- as.data.frame(MeanImporancesRegression)
MeanImporancesRegression$GMM <- gsub("_Reg_1", "", rownames(MeanImporancesRegression))
# Add a column with TRUE FALSE to evaluate which GMMs are included in the model
MeanImporancesRegression <- cbind.data.frame(MeanImporancesRegression, MeanImporancesRegression[colnames(MeanImporancesRegression)[!colnames(MeanImporancesRegression) == "GMM"]] > 0)
colnames(MeanImporancesRegression)[5:7] <- paste(colnames(MeanImporancesRegression)[5:7], "_LOGIC", sep = "")

# Make a pooled sample and add the corresponding GMM identities per cell
Pooled <- FCS_pool(flowData_transformed, stub = "100") # pure cultures
PooledSubsampled <- FCS_resample(Pooled, replace = TRUE, sample = 20000)
PooledSubsampled <- PooledSubsampled[, params_gmm]
grid <- PooledSubsampled[[1]]@exprs
pred <- predict(gmm_clust, grid)
grid <- cbind.data.frame(grid, paste("GMM", pred$classification, sep = ""))
colnames(grid)[length(params_gmm)+1] <- "Classification"
# Add the importances to each of the cells according to the GMM to which they belong
grid <- left_join(grid, MeanImporancesClassifier, by = c("Classification" = "GMM"))
grid <- left_join(grid, MeanImporancesRegression, by = c("Classification" = "GMM"))

# Plot for classifier
        # P polymyxa
        p_Class_Ppolymyxa_NOFS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Class_Ppolymyxa)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Class_Ppolymyxa)), direction = 1) +
                          labs(x = "FSC", y = "FL1", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Class_Ppolymyxa_NOFS)


        # S rhizophilia
        p_Class_Srhizophila_NOFS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Class_Srhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Class_Srhizophila)), direction = 1) +
                          labs(x = "FSC", y = "FL1", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Class_Srhizophila_NOFS)
        

        # K rhizophilia
        p_Class_Krhizophila_NOFS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Class_Krhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Class_Krhizophila)), direction = 1) +
                          labs(x = "FSC", y = "FL1", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Class_Krhizophila_NOFS)


# Plot for regression
        p_Reg_Ppolymyxa_NOFS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Reg_Ppolymyxa)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Reg_Ppolymyxa)), direction = 1) +
                          labs(x = "FSC", y = "FL1", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Reg_Ppolymyxa_NOFS)

        p_Reg_Srhizophila_NOFS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Reg_Srhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Reg_Srhizophila)), direction = 1) +
                          labs(x = "FSC", y = "FL1", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Reg_Srhizophila_NOFS)
        
        p_Reg_Krhizophila_NOFS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Reg_Krhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Reg_Krhizophila)), direction = 1) +
                          labs(x = "FSC", y = "FL1", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Reg_Krhizophila_NOFS)
        # Calulate average regression and classification for Srhizophilla
        grid$Average_Srhizophila <- rowMeans(grid[c("Class_Srhizophila", "Reg_Srhizophila")])
        p_Srhizophila_NOFS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Average_Srhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Average_Srhizophila)), direction = 1) +
                          labs(x = "Forward scatter", y = "DAPI fluorescence", color = "Importance") +
                          # ggtitle(expression(paste(italic("S. rhizophila"), " - Cluster importances no feature selection"))) + 
                          scale_x_continuous(limits = c(0, 1.2), expand = c(0, 0)) +
                          scale_y_continuous(limits = c(0.2, 1), expand = c(0, 0)) + 
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1)) 
        print(p_Srhizophila_NOFS)

        


PerformancePerFold <- PerformancePerFoldAll[PerformancePerFoldAll$Cat == "FS",]

# Feature importances classifier
ImporancesClassifier <- cbind.data.frame(PerformancePerFold$OTU, PerformancePerFold[, grepl("_Class", names(PerformancePerFold))])
colnames(ImporancesClassifier)[1] <- "OTU"
MeanImporancesClassifier <- ImporancesClassifier %>%
                            group_by(OTU) %>%
                            summarise(across(everything(), list(mean)))
Taxa <- MeanImporancesClassifier$OTU
MeanImporancesClassifier <- t(MeanImporancesClassifier[!colnames(MeanImporancesClassifier) == "OTU"])
colnames(MeanImporancesClassifier) <- paste("Class_", Taxa, sep = "")
MeanImporancesClassifier <- as.data.frame(MeanImporancesClassifier)
MeanImporancesClassifier$GMM <- gsub("_Class_1", "", rownames(MeanImporancesClassifier))
# Add a column with TRUE FALSE to evaluate which GMMs are included in the model
MeanImporancesClassifier <- cbind.data.frame(MeanImporancesClassifier, MeanImporancesClassifier[colnames(MeanImporancesClassifier)[!colnames(MeanImporancesClassifier) == "GMM"]] > 0)
colnames(MeanImporancesClassifier)[5:7] <- paste(colnames(MeanImporancesClassifier)[5:7], "_LOGIC", sep = "")

# Feature importances regression
ImporancesRegression <- cbind.data.frame(PerformancePerFold$OTU, PerformancePerFold[, grepl("_Reg", names(PerformancePerFold))])
colnames(ImporancesRegression)[1] <- "OTU"
MeanImporancesRegression <- ImporancesRegression %>%
                            group_by(OTU) %>%
                            summarise(across(everything(), list(mean)))
Taxa <- MeanImporancesRegression$OTU
MeanImporancesRegression <- t(MeanImporancesRegression[!colnames(MeanImporancesRegression) == "OTU"])
colnames(MeanImporancesRegression) <- paste("Reg_", Taxa, sep = "")
MeanImporancesRegression <- as.data.frame(MeanImporancesRegression)
MeanImporancesRegression$GMM <- gsub("_Reg_1", "", rownames(MeanImporancesRegression))
# Add a column with TRUE FALSE to evaluate which GMMs are included in the model
MeanImporancesRegression <- cbind.data.frame(MeanImporancesRegression, MeanImporancesRegression[colnames(MeanImporancesRegression)[!colnames(MeanImporancesRegression) == "GMM"]] > 0)
colnames(MeanImporancesRegression)[5:7] <- paste(colnames(MeanImporancesRegression)[5:7], "_LOGIC", sep = "")

# Make a pooled sample and add the corresponding GMM identities per cell
Pooled <- FCS_pool(flowData_transformed, stub = "100") # pure cultures
PooledSubsampled <- FCS_resample(Pooled, replace = TRUE, sample = 20000)
PooledSubsampled <- PooledSubsampled[, params_gmm]
grid <- PooledSubsampled[[1]]@exprs
pred <- predict(gmm_clust, grid)
grid <- cbind.data.frame(grid, paste("GMM", pred$classification, sep = ""))
colnames(grid)[length(params_gmm)+1] <- "Classification"
# Add the importances to each of the cells according to the GMM to which they belong
grid <- left_join(grid, MeanImporancesClassifier, by = c("Classification" = "GMM"))
grid <- left_join(grid, MeanImporancesRegression, by = c("Classification" = "GMM"))

# Plot for classifier
        # P polymyxa
        p_Class_Ppolymyxa_FS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Class_Ppolymyxa)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Class_Ppolymyxa)), direction = 1) +
                          labs(x = "FSC", y = "FL1", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Class_Ppolymyxa_FS)


        # S rhizophilia
        p_Class_Srhizophila_FS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Class_Srhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Class_Srhizophila)), direction = 1) +
                          labs(x = "FSC", y = "FL1", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Class_Srhizophila_FS)
        

        # K rhizophilia
        p_Class_Krhizophila_FS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Class_Krhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Class_Krhizophila)), direction = 1) +
                          labs(x = "FSC", y = "FL1", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Class_Krhizophila_FS)


# Plot for regression
        p_Reg_Ppolymyxa_FS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Reg_Ppolymyxa)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Reg_Ppolymyxa)), direction = 1) +
                          labs(x = "FSC", y = "FL1", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Reg_Ppolymyxa_FS)

        p_Reg_Srhizophila_FS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Reg_Srhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Reg_Srhizophila)), direction = 1) +
                          labs(x = "FSC", y = "FL1", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Reg_Srhizophila_FS)
        
        p_Reg_Krhizophila_FS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Reg_Krhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Reg_Krhizophila)), direction = 1) +
                          labs(x = "FSC", y = "FL1", color = "Importance") +
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1), legend.position = "bottom") 
        print(p_Reg_Krhizophila_FS)        
        
        # Calulate average regression and classification for Srhizophilla
        grid$Average_Srhizophila <- rowMeans(grid[c("Class_Srhizophila", "Reg_Srhizophila")])
        p_Srhizophila_FS <- ggplot(grid, aes(x = `PMT 1`, y = `PMT 9`))+
                          geom_point(shape = 16, size = 0.9, alpha = 1, aes(color = Average_Srhizophila)) +
                          scale_color_distiller(palette = 'BuPu', limit = c(0, max(grid$Average_Srhizophila)), direction = 1) +
                          labs(x = "Forward scatter", y = "DAPI fluorescence", color = "Importance") +
                          scale_x_continuous(limits = c(0, 1.2), expand = c(0, 0)) +
                          scale_y_continuous(limits = c(0.2, 1), expand = c(0, 0)) + 
                          theme_cowplot() +
                          theme(panel.grid.major = element_line(size = 0.3, linetype = 'solid', colour = ColorBlocksFacet), strip.background = element_rect(color = ColorBlocksFacet, fill = ColorBlocksFacet, size = 1)) 
        print(p_Srhizophila_FS)
        
        
```

```{r LoadLibraries, message = FALSE, warning = FALSE}
CombinedFeatureImporancesFeatureSelectionTestII <- plot_grid(p_Srhizophila, p_Srhizophila_NOFS, p_Srhizophila_FS, rel_widths = c(0.9, 1.3, 1.3), labels = c("A", "B", "C"), align = "h", ncol = 3, nrow = 1, scale = 1)
CombinedFeatureImporancesFeatureSelectionTestII

ggsave(file = "Figures/MOCK-CombinedFeatureImporancesFeatureSelection.png", width = 12, height = 3.5, dpi = 500, units = "in", CombinedFeatureImporancesFeatureSelectionTestII)
```


